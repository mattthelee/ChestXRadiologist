{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image     \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Accuracy is good but no better than guess all one class. Think this could be solved by addressing class imbalance\n",
    "- Accuracy is only good if we take the binary crossentropy and not the full label accuracy. Will need to speak to the lecturer about how to measure performance for this type of multilabel data. -> suggested splitting into sublabels and report average accuracy of models vs each of the different single label classification tasks. \n",
    "\n",
    "# TODO\n",
    "- Need to balance the classes before passing them into the model. I.e. we need to take in more data to get a 50 50 split between having a disease and not, then run through the model. This should be possible as currently we're only processing 1% of the data. 10% is without any disease so that;s 20k. We then use another 20k with a disease. \n",
    "- Also need to add the gender and age into the x train so the model can use this information as well as the image. \n",
    "- May want to pass the data into a high res image generator or use the high res images, which would require using the GPU servers\n",
    "- To allow a more complex model to learn quickly on the gpu servers, may want to try using transfer learning from an existing model\n",
    "\n",
    "# Done\n",
    "- Need to change all the unknowns into positives as evidenced by the success of u-ones model on this paper: https://arxiv.org/pdf/1901.07031.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('CheXpert-v1.0-small/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove anomalous dataline\n",
    "trainDf = trainDf[trainDf.Sex != 'Unknown']\n",
    "# Drop this column as it has many more classifications than lit suggests and shouldn't matter greatly for a CNN\n",
    "# TODO try with and without this column\n",
    "#trainDf = trainDf.drop('AP/PA', 1)\n",
    "\n",
    "def pathToID(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[2][7:]\n",
    "\n",
    "def pathToStudy(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[3][5:]\n",
    "\n",
    "# Convert all labels to a series of one-hot encoded labels. \n",
    "# -1 is uncertain, 0 is negative, 1 is positive, nans are no mention of the disease in the text\n",
    "trainDf = trainDf.fillna(0)\n",
    "# N.B. this is replacing unknowns with true as per u-ones model here: https://arxiv.org/pdf/1901.07031.pdf\n",
    "# This is essentialyl saying that if we're not sure of disease we say they have it. \n",
    "# Just to be on the safeside and have better recall as we care more about recall than precision\n",
    "trainDf = trainDf.replace(-1,1) \n",
    "\n",
    "\n",
    "# Onehot encode the sex and the xray orientation\n",
    "trainDf = trainDf.replace('Male',1)\n",
    "trainDf = trainDf.replace('Female',0)\n",
    "trainDf = trainDf.replace('Frontal',1)\n",
    "trainDf = trainDf.replace('Lateral',0)\n",
    "\n",
    "trainDf =trainDf.rename(index=str, columns={\"Sex\": \"Male?\",'Frontal/Lateral' :'Frontal1/Lateral0'})\n",
    "\n",
    "\n",
    "#trainDf.insert(0,'Path', trainDf['Path'])\n",
    "trainDf['Study'] = trainDf.Path.apply(pathToStudy)\n",
    "trainDf['Patient ID'] = trainDf.Path.apply(pathToID)\n",
    "\n",
    "# Rearrange Columns\n",
    "cols = ['Patient ID', 'Study', 'Path', 'Age', 'Male?', 'Frontal1/Lateral0', 'AP/PA','No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "trainDf = trainDf[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbf156961d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows age distribution of the data set. There are 3 0-olds and 7579 90 year olds. \n",
    "# Implies that over nineties were grouped together\n",
    "ages = trainDf['Age'].value_counts()\n",
    "plt.scatter(ages.keys(),ages.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbf13127358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender = trainDf['Male?'].value_counts()\n",
    "plt.scatter(gender.keys(),gender.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    201033\n",
      "1.0     22380\n",
      "Name: No Finding, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many people have no disease?\n",
    "no_finding = trainDf['No Finding'].value_counts()\n",
    "print(no_finding)\n",
    "\n",
    "# Plot pie chart to show how much of the data is labelled with each character\n",
    "values = no_finding.values\n",
    "labels = ['Disease present','All Clear']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Data Proportions', size=20)\n",
    "plt.pie(values, labels=labels, # explode=explode,\n",
    "        autopct='%1.1f%%', shadow=False, startangle=45)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Study</th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>Male?</th>\n",
       "      <th>Frontal1/Lateral0</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>...</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00006</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00007</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study1/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00007</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study2/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00008</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00008</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study2/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00011</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study1/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00011</td>\n",
       "      <td>5</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study5/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00011</td>\n",
       "      <td>7</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study7/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00011</td>\n",
       "      <td>4</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study4/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00011</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study2/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00011</td>\n",
       "      <td>10</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study10...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00011</td>\n",
       "      <td>9</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study9/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00011</td>\n",
       "      <td>11</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study11...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223384</th>\n",
       "      <td>64515</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64515/study1/...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223385</th>\n",
       "      <td>64516</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64516/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223386</th>\n",
       "      <td>64517</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64517/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223387</th>\n",
       "      <td>64518</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64518/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223388</th>\n",
       "      <td>64519</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64519/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223389</th>\n",
       "      <td>64520</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64520/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223390</th>\n",
       "      <td>64521</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64521/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223391</th>\n",
       "      <td>64522</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64522/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223392</th>\n",
       "      <td>64523</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64523/study1/...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223393</th>\n",
       "      <td>64524</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64524/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223394</th>\n",
       "      <td>64525</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64525/study1/...</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223395</th>\n",
       "      <td>64526</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64526/study1/...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223396</th>\n",
       "      <td>64527</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study2/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223397</th>\n",
       "      <td>64527</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study1/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223398</th>\n",
       "      <td>64528</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64528/study1/...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223399</th>\n",
       "      <td>64529</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64529/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223400</th>\n",
       "      <td>64530</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64530/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223401</th>\n",
       "      <td>64531</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64531/study1/...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223402</th>\n",
       "      <td>64532</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64532/study1/...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>64533</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223404</th>\n",
       "      <td>64533</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study2/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>64534</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223406</th>\n",
       "      <td>64535</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64535/study1/...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>64536</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223408</th>\n",
       "      <td>64536</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>64537</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>64537</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223411</th>\n",
       "      <td>64538</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64538/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223412</th>\n",
       "      <td>64539</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64539/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223413</th>\n",
       "      <td>64540</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64540/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223413 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient ID Study                                               Path  \\\n",
       "0           00001     1  CheXpert-v1.0-small/train/patient00001/study1/...   \n",
       "1           00002     2  CheXpert-v1.0-small/train/patient00002/study2/...   \n",
       "2           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "3           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "4           00003     1  CheXpert-v1.0-small/train/patient00003/study1/...   \n",
       "5           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "6           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "7           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "8           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "9           00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "10          00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "11          00006     1  CheXpert-v1.0-small/train/patient00006/study1/...   \n",
       "12          00007     1  CheXpert-v1.0-small/train/patient00007/study1/...   \n",
       "13          00007     2  CheXpert-v1.0-small/train/patient00007/study2/...   \n",
       "14          00008     1  CheXpert-v1.0-small/train/patient00008/study1/...   \n",
       "15          00008     2  CheXpert-v1.0-small/train/patient00008/study2/...   \n",
       "16          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "17          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "18          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "19          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "20          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "21          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "22          00011     1  CheXpert-v1.0-small/train/patient00011/study1/...   \n",
       "23          00011     5  CheXpert-v1.0-small/train/patient00011/study5/...   \n",
       "24          00011     7  CheXpert-v1.0-small/train/patient00011/study7/...   \n",
       "25          00011     4  CheXpert-v1.0-small/train/patient00011/study4/...   \n",
       "26          00011     2  CheXpert-v1.0-small/train/patient00011/study2/...   \n",
       "27          00011    10  CheXpert-v1.0-small/train/patient00011/study10...   \n",
       "28          00011     9  CheXpert-v1.0-small/train/patient00011/study9/...   \n",
       "29          00011    11  CheXpert-v1.0-small/train/patient00011/study11...   \n",
       "...           ...   ...                                                ...   \n",
       "223384      64515     1  CheXpert-v1.0-small/train/patient64515/study1/...   \n",
       "223385      64516     1  CheXpert-v1.0-small/train/patient64516/study1/...   \n",
       "223386      64517     1  CheXpert-v1.0-small/train/patient64517/study1/...   \n",
       "223387      64518     1  CheXpert-v1.0-small/train/patient64518/study1/...   \n",
       "223388      64519     1  CheXpert-v1.0-small/train/patient64519/study1/...   \n",
       "223389      64520     1  CheXpert-v1.0-small/train/patient64520/study1/...   \n",
       "223390      64521     1  CheXpert-v1.0-small/train/patient64521/study1/...   \n",
       "223391      64522     1  CheXpert-v1.0-small/train/patient64522/study1/...   \n",
       "223392      64523     1  CheXpert-v1.0-small/train/patient64523/study1/...   \n",
       "223393      64524     1  CheXpert-v1.0-small/train/patient64524/study1/...   \n",
       "223394      64525     1  CheXpert-v1.0-small/train/patient64525/study1/...   \n",
       "223395      64526     1  CheXpert-v1.0-small/train/patient64526/study1/...   \n",
       "223396      64527     2  CheXpert-v1.0-small/train/patient64527/study2/...   \n",
       "223397      64527     1  CheXpert-v1.0-small/train/patient64527/study1/...   \n",
       "223398      64528     1  CheXpert-v1.0-small/train/patient64528/study1/...   \n",
       "223399      64529     1  CheXpert-v1.0-small/train/patient64529/study1/...   \n",
       "223400      64530     1  CheXpert-v1.0-small/train/patient64530/study1/...   \n",
       "223401      64531     1  CheXpert-v1.0-small/train/patient64531/study1/...   \n",
       "223402      64532     1  CheXpert-v1.0-small/train/patient64532/study1/...   \n",
       "223403      64533     1  CheXpert-v1.0-small/train/patient64533/study1/...   \n",
       "223404      64533     2  CheXpert-v1.0-small/train/patient64533/study2/...   \n",
       "223405      64534     1  CheXpert-v1.0-small/train/patient64534/study1/...   \n",
       "223406      64535     1  CheXpert-v1.0-small/train/patient64535/study1/...   \n",
       "223407      64536     2  CheXpert-v1.0-small/train/patient64536/study2/...   \n",
       "223408      64536     1  CheXpert-v1.0-small/train/patient64536/study1/...   \n",
       "223409      64537     2  CheXpert-v1.0-small/train/patient64537/study2/...   \n",
       "223410      64537     1  CheXpert-v1.0-small/train/patient64537/study1/...   \n",
       "223411      64538     1  CheXpert-v1.0-small/train/patient64538/study1/...   \n",
       "223412      64539     1  CheXpert-v1.0-small/train/patient64539/study1/...   \n",
       "223413      64540     1  CheXpert-v1.0-small/train/patient64540/study1/...   \n",
       "\n",
       "        Age  Male?  Frontal1/Lateral0 AP/PA  No Finding  \\\n",
       "0        68      0                  1    AP         1.0   \n",
       "1        87      0                  1    AP         0.0   \n",
       "2        83      0                  1    AP         0.0   \n",
       "3        83      0                  0     0         0.0   \n",
       "4        41      1                  1    AP         0.0   \n",
       "5        20      0                  1    PA         1.0   \n",
       "6        20      0                  0     0         1.0   \n",
       "7        33      1                  1    PA         1.0   \n",
       "8        33      1                  0     0         1.0   \n",
       "9        33      1                  1    AP         0.0   \n",
       "10       33      1                  1    AP         0.0   \n",
       "11       42      0                  1    AP         1.0   \n",
       "12       69      1                  1    AP         0.0   \n",
       "13       69      1                  1    AP         0.0   \n",
       "14       81      1                  1    AP         0.0   \n",
       "15       81      1                  1    AP         0.0   \n",
       "16       76      1                  1    PA         0.0   \n",
       "17       76      1                  0     0         0.0   \n",
       "18       50      0                  1    PA         1.0   \n",
       "19       50      0                  0     0         1.0   \n",
       "20       22      0                  1    PA         0.0   \n",
       "21       22      0                  0     0         0.0   \n",
       "22       19      0                  1    AP         0.0   \n",
       "23       19      0                  1    AP         0.0   \n",
       "24       19      0                  1    AP         0.0   \n",
       "25       19      0                  1    AP         0.0   \n",
       "26       19      0                  1    AP         0.0   \n",
       "27       19      0                  1    AP         0.0   \n",
       "28       19      0                  1    AP         0.0   \n",
       "29       19      0                  1    AP         0.0   \n",
       "...     ...    ...                ...   ...         ...   \n",
       "223384   25      1                  1    AP         1.0   \n",
       "223385   75      0                  1    AP         1.0   \n",
       "223386   21      1                  1    AP         1.0   \n",
       "223387   68      1                  1    AP         0.0   \n",
       "223388   33      0                  1    AP         1.0   \n",
       "223389   65      0                  1    AP         1.0   \n",
       "223390   63      0                  1    AP         0.0   \n",
       "223391   21      0                  1    AP         1.0   \n",
       "223392   90      0                  1    AP         0.0   \n",
       "223393   61      0                  1    AP         0.0   \n",
       "223394   87      1                  1    AP         0.0   \n",
       "223395   55      1                  1    AP         0.0   \n",
       "223396   85      1                  1    AP         0.0   \n",
       "223397   85      1                  1    AP         0.0   \n",
       "223398   77      1                  1    AP         0.0   \n",
       "223399   81      1                  1    AP         0.0   \n",
       "223400   65      1                  1    AP         0.0   \n",
       "223401   57      0                  1    AP         0.0   \n",
       "223402   52      0                  1    AP         1.0   \n",
       "223403   75      1                  1    AP         0.0   \n",
       "223404   75      1                  1    AP         0.0   \n",
       "223405   63      1                  1    AP         0.0   \n",
       "223406   60      1                  1    AP         0.0   \n",
       "223407   61      0                  1    AP         0.0   \n",
       "223408   61      0                  1    AP         0.0   \n",
       "223409   59      1                  1    AP         0.0   \n",
       "223410   59      1                  1    AP         0.0   \n",
       "223411    0      0                  1    AP         0.0   \n",
       "223412    0      0                  1    AP         0.0   \n",
       "223413    0      0                  1    AP         1.0   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly       ...         \\\n",
       "0                              0.0           0.0       ...          \n",
       "1                              0.0           1.0       ...          \n",
       "2                              0.0           0.0       ...          \n",
       "3                              0.0           0.0       ...          \n",
       "4                              0.0           0.0       ...          \n",
       "5                              0.0           0.0       ...          \n",
       "6                              0.0           0.0       ...          \n",
       "7                              0.0           0.0       ...          \n",
       "8                              0.0           0.0       ...          \n",
       "9                              0.0           0.0       ...          \n",
       "10                             0.0           0.0       ...          \n",
       "11                             0.0           0.0       ...          \n",
       "12                             0.0           1.0       ...          \n",
       "13                             1.0           0.0       ...          \n",
       "14                             0.0           0.0       ...          \n",
       "15                             0.0           0.0       ...          \n",
       "16                             0.0           1.0       ...          \n",
       "17                             0.0           1.0       ...          \n",
       "18                             0.0           0.0       ...          \n",
       "19                             0.0           0.0       ...          \n",
       "20                             0.0           0.0       ...          \n",
       "21                             0.0           0.0       ...          \n",
       "22                             0.0           0.0       ...          \n",
       "23                             0.0           0.0       ...          \n",
       "24                             0.0           0.0       ...          \n",
       "25                             0.0           0.0       ...          \n",
       "26                             0.0           0.0       ...          \n",
       "27                             0.0           0.0       ...          \n",
       "28                             1.0           0.0       ...          \n",
       "29                             0.0           0.0       ...          \n",
       "...                            ...           ...       ...          \n",
       "223384                         0.0           0.0       ...          \n",
       "223385                         0.0           0.0       ...          \n",
       "223386                         0.0           0.0       ...          \n",
       "223387                         0.0           0.0       ...          \n",
       "223388                         0.0           0.0       ...          \n",
       "223389                         0.0           0.0       ...          \n",
       "223390                         0.0           0.0       ...          \n",
       "223391                         0.0           0.0       ...          \n",
       "223392                         0.0           0.0       ...          \n",
       "223393                         0.0           0.0       ...          \n",
       "223394                         0.0           0.0       ...          \n",
       "223395                         0.0           0.0       ...          \n",
       "223396                         0.0           1.0       ...          \n",
       "223397                         0.0           1.0       ...          \n",
       "223398                         1.0           0.0       ...          \n",
       "223399                         0.0           0.0       ...          \n",
       "223400                         0.0           0.0       ...          \n",
       "223401                         0.0           0.0       ...          \n",
       "223402                         0.0           0.0       ...          \n",
       "223403                         0.0           1.0       ...          \n",
       "223404                         0.0           0.0       ...          \n",
       "223405                         0.0           0.0       ...          \n",
       "223406                         0.0           0.0       ...          \n",
       "223407                         0.0           0.0       ...          \n",
       "223408                         0.0           0.0       ...          \n",
       "223409                         0.0           0.0       ...          \n",
       "223410                         0.0           0.0       ...          \n",
       "223411                         0.0           0.0       ...          \n",
       "223412                         0.0           1.0       ...          \n",
       "223413                         0.0           0.0       ...          \n",
       "\n",
       "        Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0               0.0    0.0            0.0        0.0          0.0   \n",
       "1               0.0    1.0            1.0        0.0          1.0   \n",
       "2               0.0    0.0            1.0        0.0          0.0   \n",
       "3               0.0    0.0            1.0        0.0          0.0   \n",
       "4               0.0    1.0            0.0        0.0          0.0   \n",
       "5               0.0    0.0            0.0        0.0          0.0   \n",
       "6               0.0    0.0            0.0        0.0          0.0   \n",
       "7               0.0    0.0            0.0        0.0          0.0   \n",
       "8               0.0    0.0            0.0        0.0          0.0   \n",
       "9               0.0    0.0            0.0        0.0          0.0   \n",
       "10              0.0    0.0            0.0        0.0          0.0   \n",
       "11              0.0    0.0            0.0        0.0          0.0   \n",
       "12              0.0    0.0            0.0        0.0          1.0   \n",
       "13              0.0    0.0            0.0        0.0          1.0   \n",
       "14              0.0    0.0            0.0        0.0          0.0   \n",
       "15              0.0    0.0            0.0        0.0          0.0   \n",
       "16              0.0    0.0            0.0        0.0          1.0   \n",
       "17              0.0    0.0            0.0        0.0          1.0   \n",
       "18              0.0    0.0            0.0        0.0          0.0   \n",
       "19              0.0    0.0            0.0        0.0          0.0   \n",
       "20              0.0    0.0            0.0        0.0          0.0   \n",
       "21              0.0    0.0            0.0        0.0          0.0   \n",
       "22              0.0    0.0            1.0        0.0          0.0   \n",
       "23              0.0    0.0            0.0        0.0          0.0   \n",
       "24              0.0    0.0            0.0        0.0          0.0   \n",
       "25              0.0    0.0            0.0        0.0          1.0   \n",
       "26              0.0    0.0            1.0        0.0          0.0   \n",
       "27              0.0    1.0            0.0        0.0          0.0   \n",
       "28              0.0    0.0            0.0        0.0          0.0   \n",
       "29              0.0    1.0            0.0        0.0          0.0   \n",
       "...             ...    ...            ...        ...          ...   \n",
       "223384          0.0    0.0            0.0        0.0          0.0   \n",
       "223385          0.0    0.0            0.0        0.0          0.0   \n",
       "223386          0.0    0.0            0.0        0.0          0.0   \n",
       "223387          0.0    1.0            0.0        0.0          0.0   \n",
       "223388          0.0    0.0            0.0        0.0          0.0   \n",
       "223389          0.0    0.0            0.0        0.0          0.0   \n",
       "223390          0.0    0.0            0.0        0.0          0.0   \n",
       "223391          0.0    0.0            0.0        0.0          0.0   \n",
       "223392          0.0    0.0            1.0        0.0          0.0   \n",
       "223393          0.0    0.0            0.0        0.0          1.0   \n",
       "223394          0.0    0.0            0.0        0.0          0.0   \n",
       "223395          0.0    0.0            0.0        1.0          1.0   \n",
       "223396          0.0    1.0            0.0        0.0          0.0   \n",
       "223397          0.0    1.0            0.0        0.0          1.0   \n",
       "223398          0.0    0.0            0.0        0.0          0.0   \n",
       "223399          0.0    0.0            0.0        0.0          0.0   \n",
       "223400          0.0    1.0            0.0        0.0          0.0   \n",
       "223401          1.0    0.0            0.0        0.0          1.0   \n",
       "223402          0.0    0.0            0.0        0.0          0.0   \n",
       "223403          0.0    1.0            0.0        0.0          0.0   \n",
       "223404          0.0    0.0            1.0        0.0          1.0   \n",
       "223405          0.0    0.0            0.0        0.0          1.0   \n",
       "223406          0.0    0.0            1.0        0.0          1.0   \n",
       "223407          0.0    1.0            0.0        0.0          0.0   \n",
       "223408          0.0    1.0            0.0        0.0          1.0   \n",
       "223409          0.0    0.0            0.0        0.0          1.0   \n",
       "223410          0.0    0.0            0.0        0.0          1.0   \n",
       "223411          0.0    1.0            0.0        0.0          0.0   \n",
       "223412          0.0    0.0            0.0        1.0          1.0   \n",
       "223413          0.0    0.0            0.0        0.0          0.0   \n",
       "\n",
       "        Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "0                0.0               0.0            0.0       0.0   \n",
       "1                0.0               1.0            0.0       1.0   \n",
       "2                0.0               0.0            0.0       1.0   \n",
       "3                0.0               0.0            0.0       1.0   \n",
       "4                0.0               0.0            0.0       0.0   \n",
       "5                0.0               0.0            0.0       0.0   \n",
       "6                0.0               0.0            0.0       0.0   \n",
       "7                0.0               0.0            0.0       0.0   \n",
       "8                0.0               0.0            0.0       0.0   \n",
       "9                1.0               0.0            0.0       0.0   \n",
       "10               1.0               0.0            0.0       0.0   \n",
       "11               0.0               0.0            0.0       0.0   \n",
       "12               1.0               0.0            0.0       0.0   \n",
       "13               0.0               0.0            0.0       0.0   \n",
       "14               0.0               1.0            0.0       0.0   \n",
       "15               0.0               1.0            0.0       0.0   \n",
       "16               0.0               0.0            0.0       0.0   \n",
       "17               0.0               0.0            0.0       0.0   \n",
       "18               0.0               0.0            0.0       0.0   \n",
       "19               0.0               0.0            0.0       0.0   \n",
       "20               0.0               0.0            0.0       0.0   \n",
       "21               0.0               0.0            0.0       0.0   \n",
       "22               1.0               1.0            0.0       0.0   \n",
       "23               1.0               0.0            0.0       0.0   \n",
       "24               0.0               0.0            0.0       0.0   \n",
       "25               1.0               1.0            0.0       0.0   \n",
       "26               0.0               1.0            0.0       0.0   \n",
       "27               0.0               1.0            0.0       0.0   \n",
       "28               0.0               1.0            0.0       0.0   \n",
       "29               0.0               1.0            0.0       0.0   \n",
       "...              ...               ...            ...       ...   \n",
       "223384           0.0               0.0            0.0       0.0   \n",
       "223385           0.0               0.0            0.0       0.0   \n",
       "223386           0.0               0.0            0.0       0.0   \n",
       "223387           0.0               0.0            0.0       0.0   \n",
       "223388           0.0               0.0            0.0       0.0   \n",
       "223389           0.0               0.0            0.0       0.0   \n",
       "223390           0.0               0.0            0.0       1.0   \n",
       "223391           0.0               0.0            0.0       0.0   \n",
       "223392           0.0               0.0            0.0       0.0   \n",
       "223393           0.0               0.0            0.0       0.0   \n",
       "223394           0.0               1.0            0.0       0.0   \n",
       "223395           0.0               1.0            0.0       1.0   \n",
       "223396           0.0               1.0            0.0       0.0   \n",
       "223397           0.0               1.0            0.0       0.0   \n",
       "223398           0.0               1.0            0.0       0.0   \n",
       "223399           0.0               0.0            0.0       0.0   \n",
       "223400           0.0               0.0            0.0       0.0   \n",
       "223401           1.0               1.0            0.0       0.0   \n",
       "223402           0.0               0.0            0.0       0.0   \n",
       "223403           0.0               1.0            0.0       0.0   \n",
       "223404           0.0               0.0            0.0       0.0   \n",
       "223405           0.0               0.0            0.0       0.0   \n",
       "223406           0.0               0.0            0.0       0.0   \n",
       "223407           0.0               1.0            0.0       0.0   \n",
       "223408           0.0               0.0            0.0       0.0   \n",
       "223409           0.0               1.0            0.0       0.0   \n",
       "223410           0.0               1.0            0.0       0.0   \n",
       "223411           0.0               0.0            0.0       0.0   \n",
       "223412           0.0               0.0            0.0       0.0   \n",
       "223413           0.0               0.0            0.0       0.0   \n",
       "\n",
       "        Support Devices  \n",
       "0                   1.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  \n",
       "6                   0.0  \n",
       "7                   1.0  \n",
       "8                   1.0  \n",
       "9                   0.0  \n",
       "10                  0.0  \n",
       "11                  0.0  \n",
       "12                  1.0  \n",
       "13                  1.0  \n",
       "14                  1.0  \n",
       "15                  1.0  \n",
       "16                  0.0  \n",
       "17                  0.0  \n",
       "18                  0.0  \n",
       "19                  0.0  \n",
       "20                  0.0  \n",
       "21                  0.0  \n",
       "22                  1.0  \n",
       "23                  0.0  \n",
       "24                  1.0  \n",
       "25                  1.0  \n",
       "26                  1.0  \n",
       "27                  1.0  \n",
       "28                  1.0  \n",
       "29                  1.0  \n",
       "...                 ...  \n",
       "223384              0.0  \n",
       "223385              0.0  \n",
       "223386              1.0  \n",
       "223387              0.0  \n",
       "223388              1.0  \n",
       "223389              0.0  \n",
       "223390              0.0  \n",
       "223391              0.0  \n",
       "223392              0.0  \n",
       "223393              1.0  \n",
       "223394              0.0  \n",
       "223395              0.0  \n",
       "223396              1.0  \n",
       "223397              1.0  \n",
       "223398              0.0  \n",
       "223399              0.0  \n",
       "223400              1.0  \n",
       "223401              1.0  \n",
       "223402              1.0  \n",
       "223403              1.0  \n",
       "223404              0.0  \n",
       "223405              0.0  \n",
       "223406              0.0  \n",
       "223407              0.0  \n",
       "223408              1.0  \n",
       "223409              0.0  \n",
       "223410              0.0  \n",
       "223411              0.0  \n",
       "223412              0.0  \n",
       "223413              0.0  \n",
       "\n",
       "[223413 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (1, X, x) and return 3D tensor\n",
    "    return data.reshape(1,inputSize[0],inputSize[1])\n",
    "\n",
    "def paths_to_tensor(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)\n",
    "\n",
    "\n",
    "def path_to_tensor_channel_last_3colour(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (X, x, 3) and return 3D tensor\n",
    "    return np.stack((data,)*3, axis=-1)\n",
    "\n",
    "\n",
    "def paths_to_tensor_channel_last_3colour(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor_channel_last_3colour(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model will be targetting Enlarged Cardiomediastinum column\n"
     ]
    }
   ],
   "source": [
    "inputSize = (224,224)\n",
    "\n",
    "sample_size =20000 # 30k is the memory limit for the server\n",
    "targetColumn = [8]\n",
    "colName = trainDf.columns.tolist()[targetColumn[0]]\n",
    "print(f\"This model will be targetting {colName} column\")\n",
    "\n",
    "\n",
    "# Create balanced dataset with 50% pos examples and 50% neg examples, only take scans from the front\n",
    "pos = trainDf[(trainDf[colName] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "neg = trainDf[(trainDf['No Finding'] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "posSample = pos.sample(int(sample_size/2))\n",
    "negSample = neg.sample(int(sample_size/2))\n",
    "sample = pd.concat([posSample,negSample])\n",
    "\n",
    "x_train_paths, x_val_paths, y_train, y_val = train_test_split(sample.Path, sample[colName], stratify=sample[colName], random_state =2)\n",
    "\n",
    "\n",
    "\n",
    "# The 3 channel option is required for the denseNet and other transfer learning models\n",
    "# Single channel can be used on our models\n",
    "\n",
    "#x_train = paths_to_tensor(x_train_paths,inputSize)#.astype('float32')/255\n",
    "x_train3Channel = paths_to_tensor_channel_last_3colour(x_train_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_train = trainDf.iloc[:training_no,targetColumn] # to do all labels: trainDf.iloc[:training_no,8:]\n",
    "#x_val = paths_to_tensor(x_val_paths,inputSize)#.astype('float32')/255\n",
    "x_val3Channel = paths_to_tensor_channel_last_3colour(x_val_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_val = trainDf.iloc[training_no:training_no+val_no,targetColumn]\n",
    "\n",
    "# Deleting dataframes in order to save memory and avoid OOM errors. \n",
    "del trainDf\n",
    "del posSample\n",
    "del negSample\n",
    "del x_train_paths\n",
    "del x_val_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(y_val))\\nprint(x_train[0].shape)\\nplt.imshow(x_train[0][0], interpolation='nearest')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(len(y_val))\n",
    "print(x_train[0].shape)\n",
    "plt.imshow(x_train[0][0], interpolation='nearest')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\\nmodel.add(Conv2D(32, (3,3)))\\nmodel.add(Conv2D(16, (3,3)))\\n\\nmodel.add(Flatten())\\n#model.add(Dropout(0.2))\\n#model.add(Dense(32,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n#model.add(Dense(16,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n\\n\\n\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\nmodel.summary()\\nweightsFilePath=\"weights.best.hdf5\"\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(32,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(16,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "weightsFilePath=\"weights.best.hdf5\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncheckpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\\n\\nhistory = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\\nmodel.load_weights(weightsFilePath)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "'''\n",
    "checkpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\n",
    "model.load_weights(weightsFilePath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAcc(predictions, truths):\n",
    "    wrongs = 0\n",
    "    for i,prediction in enumerate(predictions):\n",
    "        truth = truths[i]\n",
    "        for j, val in enumerate(prediction):\n",
    "            if val >= 0.5 and truth[j] == 0:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "            if val < 0.5 and truth[j] == 1:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "    total = 41*len(predictions) # len(predictions)\n",
    "    return (total - wrongs) / total, wrongs, total\n",
    "                \n",
    "            \n",
    "#checkAcc(predictions, y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try:\n",
    "- Could try using class weighting to handle class imbalance rather than sampling data to have no class imbalance\n",
    "- Adding in the other data as an input to a fully connected layer. This would allow network to use gender and age in it's predictions.\n",
    "- Try using no finding for the neg samples rather than 0 for the column, that way we don't have it confuse diseases. \n",
    "\n",
    "\n",
    "All of these were tested on the fracture data with 10k samples. \n",
    "## 1st Architecture:\n",
    "Tried using densenet with untrainable layers straighinto 0.3 dropout and 1 unit sigmoid output layer\n",
    "It acheived training acc around 70% and val acc of 56% after 10 epochs but didn't seem to be clearly improving\n",
    "\n",
    "## 2nd architecture\n",
    " Tried an architecture with include_top = False and two layers of 128 units and 0.2 dropouts. \n",
    "however it never got past a training acc of around 0.5. This motivates me to increase the complexity of the model and train more of it. \n",
    "## 3rd Architecture\n",
    "Same as first, but now trying with densenet first 200 layers as untrainable but rest trainable and removing last layer so it has only one class sigmoid rather than 1000 class softmax. This hadn't been possible on my laptop efore due to memm issues but is possible on Johnny's server. By removing the last layer we reduce the number of params by 1million, but allowing trainability means the network takes longer to train as we have ~4million trainable parameters. Achieved 95% training accuracy but only 54% val accuracy. At least this means we're able to get a decent accuracy somewhere, we clearly just need to prevent overfitting. Can't increase much more than 10k dataset, so best to try other ways to prevent overfitting -> dropout layers, or reducing trainable params\n",
    "\n",
    "## 4th Architecture\n",
    "addition of dropout layer before the last dense layer and also set the untrainable to be the first 300 layers rather than 200. reduces trainable params to 2 million. This actually resulted in training accuracy reaching 98% within 4 epochs, which is a bit disappointing/confusing. val acc maxed out at 0.50240Perhaps the trainble layers require more dropout or perhaps i need to furhter reduce the trainable params.Perhaps the difficulty is that it is seeing one of the other diseases, that can look like a fracture, so perhaps the data should be weighted to be 50% fracture, 50% no finding to avoid confusion -> however this is not how the model might be used in future so might not be a valid approach. perhaps it needs a higher weighting of the no-finding to achieve something similar but still training it to distinguish between fracture and other diseases. \n",
    "\n",
    "## 5th Architecture\n",
    "To avoid the overfitting, we reduce the number of trainable layers, so the first 400 layers are untrainable. Results in a mere 575K parameters to train. Reached val accuracy of 57% and trainina accuracy of aroun 80%. \n",
    "\n",
    "## 6th Architecture\n",
    "Changing the target column to be Enlarged Cardiomediastinum as that was found to be easier to detect in previous papers. Doing this also allowed us to increase the number of samples we use to 30K from 10K which should help a lot. Also increased untrainable layers to 420. This reduces trainable parameters to 200K.  If this doesn't work then we would also like to try data augementation I our next architecture to create more data, which will help the model generalise. Results were 80% training accuracy, 51% val accuracy. Therefore it's not working very well. \n",
    "\n",
    "## 7th Architecture\n",
    "Adding data augmentation. This changes the images slightly to increase the number of samples. Changes include slight rotations, slight translations. The images were also constrained to only include the PA angle, this reduced the number of samples to 20000. The training accuracy was 70% and val accuracy maxed out at 51%.\n",
    "\n",
    "## 8th\n",
    "same as 7th but using no finding as the negative case to avoid confusion with other diseases. Seemed very unstable but achieve max val acc of 56% and training acc of 66%. \n",
    "\n",
    "## 9th\n",
    "Tried freezing all the densenet layers. Reduced batch size to 16 to match the checxpert paper. 50k parameters. trainign 70% and val 50%.\n",
    "\n",
    "## 10th\n",
    "After reading: https://arxiv.org/pdf/1711.05225.pdf it turns out our original architecutre was much more similar to their papaer which ad some success. To more closely match theirs, i will change the disease to pneumonia, have all layers trainable and also set batch size to 16 to match their paper. They allow flipping of the image, which i think is invalid so will keep our data augmentation techniques. 7 million parameters. The batch size of 16 means we have a lot of backpropagations but it's much slower as a result. \n",
    "Achieved a training accuracy of 65% and validation accuracy of 72%, which is strange but we can see the val acc is very unstable so perhaps more reasonable to say around 70% if we take the average of the last few. \n",
    "\n",
    "## 11th\n",
    "Same as 10th, but to deal with the instability I increaed the epochs to 100. I will then repeat this architecture for different diseases and see what we get. \n",
    "\n",
    "## 12th \n",
    "11th was going to take 5 hours and we weres till seeing instability after 35 epochs so reduced to 20 epochs to help us understnd the instability. We also tried to run with batchsie 64 to reduce instability we had seen but gpu mem was too small for this so kept it at 16. Note pneumonia scored 76% val acc and 65% training acc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fbc53705d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trnsfer learning model\n",
    "# put into separate cell as getting the dense net takes time \n",
    "# and we often only want to tweak the downstream architecutre \n",
    "denseNet = DenseNet121(input_shape=(224,224,3), include_top=True)\n",
    "denseNet.layers.pop() # remov elast layer which has 1000 class softmax in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50176)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            50177       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,087,681\n",
      "Trainable params: 7,004,033\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thebox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model2Layers = Flatten()(denseNet.layers[-2].output)\n",
    "model2Layers = Dropout(0.3)(model2Layers)\n",
    "model2Layers = Dense(1,activation='sigmoid')(model2Layers)\n",
    "model2 = Model(input=denseNet.layers[0].input, output=model2Layers)\n",
    "for i,layer in enumerate(model2.layers):\n",
    "    # Don't train the first layers to save mem and they wil be picking up low level features anyway. \n",
    "    if i < 428:\n",
    "        #layer.trainable=False\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "weightsFilePath2=\"weights2.best.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/937 [==============================] - 260s 277ms/step - loss: 1.5882 - acc: 0.5512 - val_loss: 1.0314 - val_acc: 0.5290\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52900, saving model to weights2.best.hdf5\n",
      "Epoch 2/20\n",
      "938/937 [==============================] - 248s 265ms/step - loss: 1.2937 - acc: 0.5563 - val_loss: 0.6473 - val_acc: 0.6414\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.52900 to 0.64140, saving model to weights2.best.hdf5\n",
      "Epoch 3/20\n",
      "938/937 [==============================] - 247s 264ms/step - loss: 1.2575 - acc: 0.5864 - val_loss: 3.6690 - val_acc: 0.4418\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.64140\n",
      "Epoch 4/20\n",
      "938/937 [==============================] - 246s 263ms/step - loss: 1.2464 - acc: 0.6048 - val_loss: 2.0837 - val_acc: 0.6002\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.64140\n",
      "Epoch 5/20\n",
      "938/937 [==============================] - 246s 263ms/step - loss: 1.1088 - acc: 0.6210 - val_loss: 1.7791 - val_acc: 0.6048\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.64140\n",
      "Epoch 6/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2694 - acc: 0.5886 - val_loss: 0.6312 - val_acc: 0.6528\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.64140 to 0.65280, saving model to weights2.best.hdf5\n",
      "Epoch 7/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2418 - acc: 0.5984 - val_loss: 0.6193 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.65280 to 0.66480, saving model to weights2.best.hdf5\n",
      "Epoch 8/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2195 - acc: 0.6137 - val_loss: 0.5986 - val_acc: 0.6856\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.66480 to 0.68560, saving model to weights2.best.hdf5\n",
      "Epoch 9/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2033 - acc: 0.6073 - val_loss: 1.1147 - val_acc: 0.6142\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.68560\n",
      "Epoch 10/20\n",
      "938/937 [==============================] - 246s 263ms/step - loss: 1.1529 - acc: 0.6065 - val_loss: 0.9827 - val_acc: 0.6482\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.68560\n",
      "Epoch 11/20\n",
      "938/937 [==============================] - 245s 262ms/step - loss: 1.2352 - acc: 0.6069 - val_loss: 4.7148 - val_acc: 0.5448\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.68560\n",
      "Epoch 12/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2283 - acc: 0.6144 - val_loss: 2.0538 - val_acc: 0.6318\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.68560\n",
      "Epoch 13/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.1876 - acc: 0.6242 - val_loss: 0.6539 - val_acc: 0.5886\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.68560\n",
      "Epoch 14/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.1256 - acc: 0.6313 - val_loss: 0.8146 - val_acc: 0.6618\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.68560\n",
      "Epoch 15/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2953 - acc: 0.6036 - val_loss: 0.6287 - val_acc: 0.6466\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.68560\n",
      "Epoch 16/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2032 - acc: 0.6235 - val_loss: 0.9098 - val_acc: 0.6744\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.68560\n",
      "Epoch 17/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.1917 - acc: 0.6284 - val_loss: 0.6688 - val_acc: 0.6804\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.68560\n",
      "Epoch 18/20\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2351 - acc: 0.6259 - val_loss: 0.8571 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.68560\n",
      "Epoch 19/20\n",
      "938/937 [==============================] - 246s 263ms/step - loss: 1.1168 - acc: 0.6374 - val_loss: 0.6938 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.68560 to 0.68940, saving model to weights2.best.hdf5\n",
      "Epoch 20/20\n",
      "938/937 [==============================] - 245s 262ms/step - loss: 1.1951 - acc: 0.6293 - val_loss: 0.6750 - val_acc: 0.6670\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.68940\n"
     ]
    }
   ],
   "source": [
    "checkpoint2 = ModelCheckpoint(weightsFilePath2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15)\n",
    "#numberimage_gen.fit(x_train3Channel, augment=True)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "#history2 = model2.fit(x_train3Channel,y_train, epochs = 10, batch_size=128,  validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "history2 = model2.fit_generator(image_gen.flow(x_train3Channel, y_train, batch_size=batch_size),steps_per_epoch=len(x_train3Channel) / batch_size,  epochs = epochs, validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "model2.load_weights(weightsFilePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the history of this model\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'])\n",
    "maxValAcc = max(history2.history['val_acc'])\n",
    "trainAcc = history2.history['acc'][history2.history['val_acc'].index(maxValAcc)]\n",
    "plt.savefig(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.png\")\n",
    "model2.save_weights(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.hdf5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6894"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(history2.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
