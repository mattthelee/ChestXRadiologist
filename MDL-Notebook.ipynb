{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image     \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Accuracy is good but no better than guess all one class. Think this could be solved by addressing class imbalance\n",
    "- Accuracy is only good if we take the binary crossentropy and not the full label accuracy. Will need to speak to the lecturer about how to measure performance for this type of multilabel data. -> suggested splitting into sublabels and report average accuracy of models vs each of the different single label classification tasks. \n",
    "\n",
    "# TODO\n",
    "- Need to balance the classes before passing them into the model. I.e. we need to take in more data to get a 50 50 split between having a disease and not, then run through the model. This should be possible as currently we're only processing 1% of the data. 10% is without any disease so that;s 20k. We then use another 20k with a disease. \n",
    "- Also need to add the gender and age into the x train so the model can use this information as well as the image. \n",
    "- May want to pass the data into a high res image generator or use the high res images, which would require using the GPU servers\n",
    "- To allow a more complex model to learn quickly on the gpu servers, may want to try using transfer learning from an existing model\n",
    "\n",
    "# Done\n",
    "- Need to change all the unknowns into positives as evidenced by the success of u-ones model on this paper: https://arxiv.org/pdf/1901.07031.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('CheXpert-v1.0-small/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove anomalous dataline\n",
    "trainDf = trainDf[trainDf.Sex != 'Unknown']\n",
    "# Drop this column as it has many more classifications than lit suggests and shouldn't matter greatly for a CNN\n",
    "# TODO try with and without this column\n",
    "#trainDf = trainDf.drop('AP/PA', 1)\n",
    "\n",
    "def pathToID(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[2][7:]\n",
    "\n",
    "def pathToStudy(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[3][5:]\n",
    "\n",
    "# Convert all labels to a series of one-hot encoded labels. \n",
    "# -1 is uncertain, 0 is negative, 1 is positive, nans are no mention of the disease in the text\n",
    "trainDf = trainDf.fillna(0)\n",
    "# N.B. this is replacing unknowns with true as per u-ones model here: https://arxiv.org/pdf/1901.07031.pdf\n",
    "# This is essentialyl saying that if we're not sure of disease we say they have it. \n",
    "# Just to be on the safeside and have better recall as we care more about recall than precision\n",
    "trainDf = trainDf.replace(-1,1) \n",
    "\n",
    "\n",
    "# Onehot encode the sex and the xray orientation\n",
    "trainDf = trainDf.replace('Male',1)\n",
    "trainDf = trainDf.replace('Female',0)\n",
    "trainDf = trainDf.replace('Frontal',1)\n",
    "trainDf = trainDf.replace('Lateral',0)\n",
    "\n",
    "trainDf =trainDf.rename(index=str, columns={\"Sex\": \"Male?\",'Frontal/Lateral' :'Frontal1/Lateral0'})\n",
    "\n",
    "\n",
    "#trainDf.insert(0,'Path', trainDf['Path'])\n",
    "trainDf['Study'] = trainDf.Path.apply(pathToStudy)\n",
    "trainDf['Patient ID'] = trainDf.Path.apply(pathToID)\n",
    "\n",
    "# Rearrange Columns\n",
    "cols = ['Patient ID', 'Study', 'Path', 'Age', 'Male?', 'Frontal1/Lateral0', 'AP/PA','No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "trainDf = trainDf[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff98efdd208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows age distribution of the data set. There are 3 0-olds and 7579 90 year olds. \n",
    "# Implies that over nineties were grouped together\n",
    "ages = trainDf['Age'].value_counts()\n",
    "plt.scatter(ages.keys(),ages.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff98ca6f390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender = trainDf['Male?'].value_counts()\n",
    "plt.scatter(gender.keys(),gender.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    201033\n",
      "1.0     22380\n",
      "Name: No Finding, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many people have no disease?\n",
    "no_finding = trainDf['No Finding'].value_counts()\n",
    "print(no_finding)\n",
    "\n",
    "# Plot pie chart to show how much of the data is labelled with each character\n",
    "values = no_finding.values\n",
    "labels = ['Disease present','All Clear']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Data Proportions', size=20)\n",
    "plt.pie(values, labels=labels, # explode=explode,\n",
    "        autopct='%1.1f%%', shadow=False, startangle=45)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Study</th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>Male?</th>\n",
       "      <th>Frontal1/Lateral0</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>...</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00006</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00007</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study1/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00007</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study2/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00008</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00008</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study2/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00011</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study1/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00011</td>\n",
       "      <td>5</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study5/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00011</td>\n",
       "      <td>7</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study7/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00011</td>\n",
       "      <td>4</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study4/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00011</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study2/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00011</td>\n",
       "      <td>10</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study10...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00011</td>\n",
       "      <td>9</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study9/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00011</td>\n",
       "      <td>11</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study11...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223384</th>\n",
       "      <td>64515</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64515/study1/...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223385</th>\n",
       "      <td>64516</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64516/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223386</th>\n",
       "      <td>64517</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64517/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223387</th>\n",
       "      <td>64518</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64518/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223388</th>\n",
       "      <td>64519</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64519/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223389</th>\n",
       "      <td>64520</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64520/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223390</th>\n",
       "      <td>64521</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64521/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223391</th>\n",
       "      <td>64522</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64522/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223392</th>\n",
       "      <td>64523</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64523/study1/...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223393</th>\n",
       "      <td>64524</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64524/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223394</th>\n",
       "      <td>64525</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64525/study1/...</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223395</th>\n",
       "      <td>64526</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64526/study1/...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223396</th>\n",
       "      <td>64527</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study2/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223397</th>\n",
       "      <td>64527</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study1/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223398</th>\n",
       "      <td>64528</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64528/study1/...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223399</th>\n",
       "      <td>64529</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64529/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223400</th>\n",
       "      <td>64530</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64530/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223401</th>\n",
       "      <td>64531</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64531/study1/...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223402</th>\n",
       "      <td>64532</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64532/study1/...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>64533</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223404</th>\n",
       "      <td>64533</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study2/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>64534</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223406</th>\n",
       "      <td>64535</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64535/study1/...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>64536</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223408</th>\n",
       "      <td>64536</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>64537</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>64537</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223411</th>\n",
       "      <td>64538</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64538/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223412</th>\n",
       "      <td>64539</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64539/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223413</th>\n",
       "      <td>64540</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64540/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223413 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient ID Study                                               Path  \\\n",
       "0           00001     1  CheXpert-v1.0-small/train/patient00001/study1/...   \n",
       "1           00002     2  CheXpert-v1.0-small/train/patient00002/study2/...   \n",
       "2           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "3           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "4           00003     1  CheXpert-v1.0-small/train/patient00003/study1/...   \n",
       "5           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "6           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "7           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "8           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "9           00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "10          00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "11          00006     1  CheXpert-v1.0-small/train/patient00006/study1/...   \n",
       "12          00007     1  CheXpert-v1.0-small/train/patient00007/study1/...   \n",
       "13          00007     2  CheXpert-v1.0-small/train/patient00007/study2/...   \n",
       "14          00008     1  CheXpert-v1.0-small/train/patient00008/study1/...   \n",
       "15          00008     2  CheXpert-v1.0-small/train/patient00008/study2/...   \n",
       "16          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "17          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "18          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "19          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "20          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "21          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "22          00011     1  CheXpert-v1.0-small/train/patient00011/study1/...   \n",
       "23          00011     5  CheXpert-v1.0-small/train/patient00011/study5/...   \n",
       "24          00011     7  CheXpert-v1.0-small/train/patient00011/study7/...   \n",
       "25          00011     4  CheXpert-v1.0-small/train/patient00011/study4/...   \n",
       "26          00011     2  CheXpert-v1.0-small/train/patient00011/study2/...   \n",
       "27          00011    10  CheXpert-v1.0-small/train/patient00011/study10...   \n",
       "28          00011     9  CheXpert-v1.0-small/train/patient00011/study9/...   \n",
       "29          00011    11  CheXpert-v1.0-small/train/patient00011/study11...   \n",
       "...           ...   ...                                                ...   \n",
       "223384      64515     1  CheXpert-v1.0-small/train/patient64515/study1/...   \n",
       "223385      64516     1  CheXpert-v1.0-small/train/patient64516/study1/...   \n",
       "223386      64517     1  CheXpert-v1.0-small/train/patient64517/study1/...   \n",
       "223387      64518     1  CheXpert-v1.0-small/train/patient64518/study1/...   \n",
       "223388      64519     1  CheXpert-v1.0-small/train/patient64519/study1/...   \n",
       "223389      64520     1  CheXpert-v1.0-small/train/patient64520/study1/...   \n",
       "223390      64521     1  CheXpert-v1.0-small/train/patient64521/study1/...   \n",
       "223391      64522     1  CheXpert-v1.0-small/train/patient64522/study1/...   \n",
       "223392      64523     1  CheXpert-v1.0-small/train/patient64523/study1/...   \n",
       "223393      64524     1  CheXpert-v1.0-small/train/patient64524/study1/...   \n",
       "223394      64525     1  CheXpert-v1.0-small/train/patient64525/study1/...   \n",
       "223395      64526     1  CheXpert-v1.0-small/train/patient64526/study1/...   \n",
       "223396      64527     2  CheXpert-v1.0-small/train/patient64527/study2/...   \n",
       "223397      64527     1  CheXpert-v1.0-small/train/patient64527/study1/...   \n",
       "223398      64528     1  CheXpert-v1.0-small/train/patient64528/study1/...   \n",
       "223399      64529     1  CheXpert-v1.0-small/train/patient64529/study1/...   \n",
       "223400      64530     1  CheXpert-v1.0-small/train/patient64530/study1/...   \n",
       "223401      64531     1  CheXpert-v1.0-small/train/patient64531/study1/...   \n",
       "223402      64532     1  CheXpert-v1.0-small/train/patient64532/study1/...   \n",
       "223403      64533     1  CheXpert-v1.0-small/train/patient64533/study1/...   \n",
       "223404      64533     2  CheXpert-v1.0-small/train/patient64533/study2/...   \n",
       "223405      64534     1  CheXpert-v1.0-small/train/patient64534/study1/...   \n",
       "223406      64535     1  CheXpert-v1.0-small/train/patient64535/study1/...   \n",
       "223407      64536     2  CheXpert-v1.0-small/train/patient64536/study2/...   \n",
       "223408      64536     1  CheXpert-v1.0-small/train/patient64536/study1/...   \n",
       "223409      64537     2  CheXpert-v1.0-small/train/patient64537/study2/...   \n",
       "223410      64537     1  CheXpert-v1.0-small/train/patient64537/study1/...   \n",
       "223411      64538     1  CheXpert-v1.0-small/train/patient64538/study1/...   \n",
       "223412      64539     1  CheXpert-v1.0-small/train/patient64539/study1/...   \n",
       "223413      64540     1  CheXpert-v1.0-small/train/patient64540/study1/...   \n",
       "\n",
       "        Age  Male?  Frontal1/Lateral0 AP/PA  No Finding  \\\n",
       "0        68      0                  1    AP         1.0   \n",
       "1        87      0                  1    AP         0.0   \n",
       "2        83      0                  1    AP         0.0   \n",
       "3        83      0                  0     0         0.0   \n",
       "4        41      1                  1    AP         0.0   \n",
       "5        20      0                  1    PA         1.0   \n",
       "6        20      0                  0     0         1.0   \n",
       "7        33      1                  1    PA         1.0   \n",
       "8        33      1                  0     0         1.0   \n",
       "9        33      1                  1    AP         0.0   \n",
       "10       33      1                  1    AP         0.0   \n",
       "11       42      0                  1    AP         1.0   \n",
       "12       69      1                  1    AP         0.0   \n",
       "13       69      1                  1    AP         0.0   \n",
       "14       81      1                  1    AP         0.0   \n",
       "15       81      1                  1    AP         0.0   \n",
       "16       76      1                  1    PA         0.0   \n",
       "17       76      1                  0     0         0.0   \n",
       "18       50      0                  1    PA         1.0   \n",
       "19       50      0                  0     0         1.0   \n",
       "20       22      0                  1    PA         0.0   \n",
       "21       22      0                  0     0         0.0   \n",
       "22       19      0                  1    AP         0.0   \n",
       "23       19      0                  1    AP         0.0   \n",
       "24       19      0                  1    AP         0.0   \n",
       "25       19      0                  1    AP         0.0   \n",
       "26       19      0                  1    AP         0.0   \n",
       "27       19      0                  1    AP         0.0   \n",
       "28       19      0                  1    AP         0.0   \n",
       "29       19      0                  1    AP         0.0   \n",
       "...     ...    ...                ...   ...         ...   \n",
       "223384   25      1                  1    AP         1.0   \n",
       "223385   75      0                  1    AP         1.0   \n",
       "223386   21      1                  1    AP         1.0   \n",
       "223387   68      1                  1    AP         0.0   \n",
       "223388   33      0                  1    AP         1.0   \n",
       "223389   65      0                  1    AP         1.0   \n",
       "223390   63      0                  1    AP         0.0   \n",
       "223391   21      0                  1    AP         1.0   \n",
       "223392   90      0                  1    AP         0.0   \n",
       "223393   61      0                  1    AP         0.0   \n",
       "223394   87      1                  1    AP         0.0   \n",
       "223395   55      1                  1    AP         0.0   \n",
       "223396   85      1                  1    AP         0.0   \n",
       "223397   85      1                  1    AP         0.0   \n",
       "223398   77      1                  1    AP         0.0   \n",
       "223399   81      1                  1    AP         0.0   \n",
       "223400   65      1                  1    AP         0.0   \n",
       "223401   57      0                  1    AP         0.0   \n",
       "223402   52      0                  1    AP         1.0   \n",
       "223403   75      1                  1    AP         0.0   \n",
       "223404   75      1                  1    AP         0.0   \n",
       "223405   63      1                  1    AP         0.0   \n",
       "223406   60      1                  1    AP         0.0   \n",
       "223407   61      0                  1    AP         0.0   \n",
       "223408   61      0                  1    AP         0.0   \n",
       "223409   59      1                  1    AP         0.0   \n",
       "223410   59      1                  1    AP         0.0   \n",
       "223411    0      0                  1    AP         0.0   \n",
       "223412    0      0                  1    AP         0.0   \n",
       "223413    0      0                  1    AP         1.0   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly       ...         \\\n",
       "0                              0.0           0.0       ...          \n",
       "1                              0.0           1.0       ...          \n",
       "2                              0.0           0.0       ...          \n",
       "3                              0.0           0.0       ...          \n",
       "4                              0.0           0.0       ...          \n",
       "5                              0.0           0.0       ...          \n",
       "6                              0.0           0.0       ...          \n",
       "7                              0.0           0.0       ...          \n",
       "8                              0.0           0.0       ...          \n",
       "9                              0.0           0.0       ...          \n",
       "10                             0.0           0.0       ...          \n",
       "11                             0.0           0.0       ...          \n",
       "12                             0.0           1.0       ...          \n",
       "13                             1.0           0.0       ...          \n",
       "14                             0.0           0.0       ...          \n",
       "15                             0.0           0.0       ...          \n",
       "16                             0.0           1.0       ...          \n",
       "17                             0.0           1.0       ...          \n",
       "18                             0.0           0.0       ...          \n",
       "19                             0.0           0.0       ...          \n",
       "20                             0.0           0.0       ...          \n",
       "21                             0.0           0.0       ...          \n",
       "22                             0.0           0.0       ...          \n",
       "23                             0.0           0.0       ...          \n",
       "24                             0.0           0.0       ...          \n",
       "25                             0.0           0.0       ...          \n",
       "26                             0.0           0.0       ...          \n",
       "27                             0.0           0.0       ...          \n",
       "28                             1.0           0.0       ...          \n",
       "29                             0.0           0.0       ...          \n",
       "...                            ...           ...       ...          \n",
       "223384                         0.0           0.0       ...          \n",
       "223385                         0.0           0.0       ...          \n",
       "223386                         0.0           0.0       ...          \n",
       "223387                         0.0           0.0       ...          \n",
       "223388                         0.0           0.0       ...          \n",
       "223389                         0.0           0.0       ...          \n",
       "223390                         0.0           0.0       ...          \n",
       "223391                         0.0           0.0       ...          \n",
       "223392                         0.0           0.0       ...          \n",
       "223393                         0.0           0.0       ...          \n",
       "223394                         0.0           0.0       ...          \n",
       "223395                         0.0           0.0       ...          \n",
       "223396                         0.0           1.0       ...          \n",
       "223397                         0.0           1.0       ...          \n",
       "223398                         1.0           0.0       ...          \n",
       "223399                         0.0           0.0       ...          \n",
       "223400                         0.0           0.0       ...          \n",
       "223401                         0.0           0.0       ...          \n",
       "223402                         0.0           0.0       ...          \n",
       "223403                         0.0           1.0       ...          \n",
       "223404                         0.0           0.0       ...          \n",
       "223405                         0.0           0.0       ...          \n",
       "223406                         0.0           0.0       ...          \n",
       "223407                         0.0           0.0       ...          \n",
       "223408                         0.0           0.0       ...          \n",
       "223409                         0.0           0.0       ...          \n",
       "223410                         0.0           0.0       ...          \n",
       "223411                         0.0           0.0       ...          \n",
       "223412                         0.0           1.0       ...          \n",
       "223413                         0.0           0.0       ...          \n",
       "\n",
       "        Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0               0.0    0.0            0.0        0.0          0.0   \n",
       "1               0.0    1.0            1.0        0.0          1.0   \n",
       "2               0.0    0.0            1.0        0.0          0.0   \n",
       "3               0.0    0.0            1.0        0.0          0.0   \n",
       "4               0.0    1.0            0.0        0.0          0.0   \n",
       "5               0.0    0.0            0.0        0.0          0.0   \n",
       "6               0.0    0.0            0.0        0.0          0.0   \n",
       "7               0.0    0.0            0.0        0.0          0.0   \n",
       "8               0.0    0.0            0.0        0.0          0.0   \n",
       "9               0.0    0.0            0.0        0.0          0.0   \n",
       "10              0.0    0.0            0.0        0.0          0.0   \n",
       "11              0.0    0.0            0.0        0.0          0.0   \n",
       "12              0.0    0.0            0.0        0.0          1.0   \n",
       "13              0.0    0.0            0.0        0.0          1.0   \n",
       "14              0.0    0.0            0.0        0.0          0.0   \n",
       "15              0.0    0.0            0.0        0.0          0.0   \n",
       "16              0.0    0.0            0.0        0.0          1.0   \n",
       "17              0.0    0.0            0.0        0.0          1.0   \n",
       "18              0.0    0.0            0.0        0.0          0.0   \n",
       "19              0.0    0.0            0.0        0.0          0.0   \n",
       "20              0.0    0.0            0.0        0.0          0.0   \n",
       "21              0.0    0.0            0.0        0.0          0.0   \n",
       "22              0.0    0.0            1.0        0.0          0.0   \n",
       "23              0.0    0.0            0.0        0.0          0.0   \n",
       "24              0.0    0.0            0.0        0.0          0.0   \n",
       "25              0.0    0.0            0.0        0.0          1.0   \n",
       "26              0.0    0.0            1.0        0.0          0.0   \n",
       "27              0.0    1.0            0.0        0.0          0.0   \n",
       "28              0.0    0.0            0.0        0.0          0.0   \n",
       "29              0.0    1.0            0.0        0.0          0.0   \n",
       "...             ...    ...            ...        ...          ...   \n",
       "223384          0.0    0.0            0.0        0.0          0.0   \n",
       "223385          0.0    0.0            0.0        0.0          0.0   \n",
       "223386          0.0    0.0            0.0        0.0          0.0   \n",
       "223387          0.0    1.0            0.0        0.0          0.0   \n",
       "223388          0.0    0.0            0.0        0.0          0.0   \n",
       "223389          0.0    0.0            0.0        0.0          0.0   \n",
       "223390          0.0    0.0            0.0        0.0          0.0   \n",
       "223391          0.0    0.0            0.0        0.0          0.0   \n",
       "223392          0.0    0.0            1.0        0.0          0.0   \n",
       "223393          0.0    0.0            0.0        0.0          1.0   \n",
       "223394          0.0    0.0            0.0        0.0          0.0   \n",
       "223395          0.0    0.0            0.0        1.0          1.0   \n",
       "223396          0.0    1.0            0.0        0.0          0.0   \n",
       "223397          0.0    1.0            0.0        0.0          1.0   \n",
       "223398          0.0    0.0            0.0        0.0          0.0   \n",
       "223399          0.0    0.0            0.0        0.0          0.0   \n",
       "223400          0.0    1.0            0.0        0.0          0.0   \n",
       "223401          1.0    0.0            0.0        0.0          1.0   \n",
       "223402          0.0    0.0            0.0        0.0          0.0   \n",
       "223403          0.0    1.0            0.0        0.0          0.0   \n",
       "223404          0.0    0.0            1.0        0.0          1.0   \n",
       "223405          0.0    0.0            0.0        0.0          1.0   \n",
       "223406          0.0    0.0            1.0        0.0          1.0   \n",
       "223407          0.0    1.0            0.0        0.0          0.0   \n",
       "223408          0.0    1.0            0.0        0.0          1.0   \n",
       "223409          0.0    0.0            0.0        0.0          1.0   \n",
       "223410          0.0    0.0            0.0        0.0          1.0   \n",
       "223411          0.0    1.0            0.0        0.0          0.0   \n",
       "223412          0.0    0.0            0.0        1.0          1.0   \n",
       "223413          0.0    0.0            0.0        0.0          0.0   \n",
       "\n",
       "        Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "0                0.0               0.0            0.0       0.0   \n",
       "1                0.0               1.0            0.0       1.0   \n",
       "2                0.0               0.0            0.0       1.0   \n",
       "3                0.0               0.0            0.0       1.0   \n",
       "4                0.0               0.0            0.0       0.0   \n",
       "5                0.0               0.0            0.0       0.0   \n",
       "6                0.0               0.0            0.0       0.0   \n",
       "7                0.0               0.0            0.0       0.0   \n",
       "8                0.0               0.0            0.0       0.0   \n",
       "9                1.0               0.0            0.0       0.0   \n",
       "10               1.0               0.0            0.0       0.0   \n",
       "11               0.0               0.0            0.0       0.0   \n",
       "12               1.0               0.0            0.0       0.0   \n",
       "13               0.0               0.0            0.0       0.0   \n",
       "14               0.0               1.0            0.0       0.0   \n",
       "15               0.0               1.0            0.0       0.0   \n",
       "16               0.0               0.0            0.0       0.0   \n",
       "17               0.0               0.0            0.0       0.0   \n",
       "18               0.0               0.0            0.0       0.0   \n",
       "19               0.0               0.0            0.0       0.0   \n",
       "20               0.0               0.0            0.0       0.0   \n",
       "21               0.0               0.0            0.0       0.0   \n",
       "22               1.0               1.0            0.0       0.0   \n",
       "23               1.0               0.0            0.0       0.0   \n",
       "24               0.0               0.0            0.0       0.0   \n",
       "25               1.0               1.0            0.0       0.0   \n",
       "26               0.0               1.0            0.0       0.0   \n",
       "27               0.0               1.0            0.0       0.0   \n",
       "28               0.0               1.0            0.0       0.0   \n",
       "29               0.0               1.0            0.0       0.0   \n",
       "...              ...               ...            ...       ...   \n",
       "223384           0.0               0.0            0.0       0.0   \n",
       "223385           0.0               0.0            0.0       0.0   \n",
       "223386           0.0               0.0            0.0       0.0   \n",
       "223387           0.0               0.0            0.0       0.0   \n",
       "223388           0.0               0.0            0.0       0.0   \n",
       "223389           0.0               0.0            0.0       0.0   \n",
       "223390           0.0               0.0            0.0       1.0   \n",
       "223391           0.0               0.0            0.0       0.0   \n",
       "223392           0.0               0.0            0.0       0.0   \n",
       "223393           0.0               0.0            0.0       0.0   \n",
       "223394           0.0               1.0            0.0       0.0   \n",
       "223395           0.0               1.0            0.0       1.0   \n",
       "223396           0.0               1.0            0.0       0.0   \n",
       "223397           0.0               1.0            0.0       0.0   \n",
       "223398           0.0               1.0            0.0       0.0   \n",
       "223399           0.0               0.0            0.0       0.0   \n",
       "223400           0.0               0.0            0.0       0.0   \n",
       "223401           1.0               1.0            0.0       0.0   \n",
       "223402           0.0               0.0            0.0       0.0   \n",
       "223403           0.0               1.0            0.0       0.0   \n",
       "223404           0.0               0.0            0.0       0.0   \n",
       "223405           0.0               0.0            0.0       0.0   \n",
       "223406           0.0               0.0            0.0       0.0   \n",
       "223407           0.0               1.0            0.0       0.0   \n",
       "223408           0.0               0.0            0.0       0.0   \n",
       "223409           0.0               1.0            0.0       0.0   \n",
       "223410           0.0               1.0            0.0       0.0   \n",
       "223411           0.0               0.0            0.0       0.0   \n",
       "223412           0.0               0.0            0.0       0.0   \n",
       "223413           0.0               0.0            0.0       0.0   \n",
       "\n",
       "        Support Devices  \n",
       "0                   1.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  \n",
       "6                   0.0  \n",
       "7                   1.0  \n",
       "8                   1.0  \n",
       "9                   0.0  \n",
       "10                  0.0  \n",
       "11                  0.0  \n",
       "12                  1.0  \n",
       "13                  1.0  \n",
       "14                  1.0  \n",
       "15                  1.0  \n",
       "16                  0.0  \n",
       "17                  0.0  \n",
       "18                  0.0  \n",
       "19                  0.0  \n",
       "20                  0.0  \n",
       "21                  0.0  \n",
       "22                  1.0  \n",
       "23                  0.0  \n",
       "24                  1.0  \n",
       "25                  1.0  \n",
       "26                  1.0  \n",
       "27                  1.0  \n",
       "28                  1.0  \n",
       "29                  1.0  \n",
       "...                 ...  \n",
       "223384              0.0  \n",
       "223385              0.0  \n",
       "223386              1.0  \n",
       "223387              0.0  \n",
       "223388              1.0  \n",
       "223389              0.0  \n",
       "223390              0.0  \n",
       "223391              0.0  \n",
       "223392              0.0  \n",
       "223393              1.0  \n",
       "223394              0.0  \n",
       "223395              0.0  \n",
       "223396              1.0  \n",
       "223397              1.0  \n",
       "223398              0.0  \n",
       "223399              0.0  \n",
       "223400              1.0  \n",
       "223401              1.0  \n",
       "223402              1.0  \n",
       "223403              1.0  \n",
       "223404              0.0  \n",
       "223405              0.0  \n",
       "223406              0.0  \n",
       "223407              0.0  \n",
       "223408              1.0  \n",
       "223409              0.0  \n",
       "223410              0.0  \n",
       "223411              0.0  \n",
       "223412              0.0  \n",
       "223413              0.0  \n",
       "\n",
       "[223413 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (1, X, x) and return 3D tensor\n",
    "    return data.reshape(1,inputSize[0],inputSize[1])\n",
    "\n",
    "def paths_to_tensor(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)\n",
    "\n",
    "\n",
    "def path_to_tensor_channel_last_3colour(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (X, x, 3) and return 3D tensor\n",
    "    return np.stack((data,)*3, axis=-1)\n",
    "\n",
    "\n",
    "def paths_to_tensor_channel_last_3colour(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor_channel_last_3colour(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model will be targetting Pneumonia column\n"
     ]
    }
   ],
   "source": [
    "inputSize = (224,224)\n",
    "\n",
    "sample_size =20000 # 30k is the memory limit for the server\n",
    "targetColumn = [14]\n",
    "colName = trainDf.columns.tolist()[targetColumn[0]]\n",
    "print(f\"This model will be targetting {colName} column\")\n",
    "\n",
    "\n",
    "# Create balanced dataset with 50% pos examples and 50% neg examples, only take scans from the front\n",
    "pos = trainDf[(trainDf[colName] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "neg = trainDf[(trainDf['No Finding'] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "posSample = pos.sample(int(sample_size/2))\n",
    "negSample = neg.sample(int(sample_size/2))\n",
    "sample = pd.concat([posSample,negSample])\n",
    "\n",
    "x_train_paths, x_val_paths, y_train, y_val = train_test_split(sample.Path, sample[colName], stratify=sample[colName], random_state =2)\n",
    "\n",
    "\n",
    "\n",
    "# The 3 channel option is required for the denseNet and other transfer learning models\n",
    "# Single channel can be used on our models\n",
    "\n",
    "#x_train = paths_to_tensor(x_train_paths,inputSize)#.astype('float32')/255\n",
    "x_train3Channel = paths_to_tensor_channel_last_3colour(x_train_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_train = trainDf.iloc[:training_no,targetColumn] # to do all labels: trainDf.iloc[:training_no,8:]\n",
    "#x_val = paths_to_tensor(x_val_paths,inputSize)#.astype('float32')/255\n",
    "x_val3Channel = paths_to_tensor_channel_last_3colour(x_val_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_val = trainDf.iloc[training_no:training_no+val_no,targetColumn]\n",
    "\n",
    "# Deleting dataframes in order to save memory and avoid OOM errors. \n",
    "del trainDf\n",
    "del posSample\n",
    "del negSample\n",
    "del x_train_paths\n",
    "del x_val_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(y_val))\\nprint(x_train[0].shape)\\nplt.imshow(x_train[0][0], interpolation='nearest')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(len(y_val))\n",
    "print(x_train[0].shape)\n",
    "plt.imshow(x_train[0][0], interpolation='nearest')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\\nmodel.add(Conv2D(32, (3,3)))\\nmodel.add(Conv2D(16, (3,3)))\\n\\nmodel.add(Flatten())\\n#model.add(Dropout(0.2))\\n#model.add(Dense(32,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n#model.add(Dense(16,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n\\n\\n\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\nmodel.summary()\\nweightsFilePath=\"weights.best.hdf5\"\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(32,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(16,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "weightsFilePath=\"weights.best.hdf5\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncheckpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\\n\\nhistory = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\\nmodel.load_weights(weightsFilePath)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "'''\n",
    "checkpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\n",
    "model.load_weights(weightsFilePath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAcc(predictions, truths):\n",
    "    wrongs = 0\n",
    "    for i,prediction in enumerate(predictions):\n",
    "        truth = truths[i]\n",
    "        for j, val in enumerate(prediction):\n",
    "            if val >= 0.5 and truth[j] == 0:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "            if val < 0.5 and truth[j] == 1:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "    total = 41*len(predictions) # len(predictions)\n",
    "    return (total - wrongs) / total, wrongs, total\n",
    "                \n",
    "            \n",
    "#checkAcc(predictions, y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try:\n",
    "- Could try using class weighting to handle class imbalance rather than sampling data to have no class imbalance\n",
    "- Adding in the other data as an input to a fully connected layer. This would allow network to use gender and age in it's predictions.\n",
    "- Try using no finding for the neg samples rather than 0 for the column, that way we don't have it confuse diseases. \n",
    "\n",
    "\n",
    "All of these were tested on the fracture data with 10k samples. \n",
    "## 1st Architecture:\n",
    "Tried using densenet with untrainable layers straighinto 0.3 dropout and 1 unit sigmoid output layer\n",
    "It acheived training acc around 70% and val acc of 56% after 10 epochs but didn't seem to be clearly improving\n",
    "\n",
    "## 2nd architecture\n",
    " Tried an architecture with include_top = False and two layers of 128 units and 0.2 dropouts. \n",
    "however it never got past a training acc of around 0.5. This motivates me to increase the complexity of the model and train more of it. \n",
    "## 3rd Architecture\n",
    "Same as first, but now trying with densenet first 200 layers as untrainable but rest trainable and removing last layer so it has only one class sigmoid rather than 1000 class softmax. This hadn't been possible on my laptop efore due to memm issues but is possible on Johnny's server. By removing the last layer we reduce the number of params by 1million, but allowing trainability means the network takes longer to train as we have ~4million trainable parameters. Achieved 95% training accuracy but only 54% val accuracy. At least this means we're able to get a decent accuracy somewhere, we clearly just need to prevent overfitting. Can't increase much more than 10k dataset, so best to try other ways to prevent overfitting -> dropout layers, or reducing trainable params\n",
    "\n",
    "## 4th Architecture\n",
    "addition of dropout layer before the last dense layer and also set the untrainable to be the first 300 layers rather than 200. reduces trainable params to 2 million. This actually resulted in training accuracy reaching 98% within 4 epochs, which is a bit disappointing/confusing. val acc maxed out at 0.50240Perhaps the trainble layers require more dropout or perhaps i need to furhter reduce the trainable params.Perhaps the difficulty is that it is seeing one of the other diseases, that can look like a fracture, so perhaps the data should be weighted to be 50% fracture, 50% no finding to avoid confusion -> however this is not how the model might be used in future so might not be a valid approach. perhaps it needs a higher weighting of the no-finding to achieve something similar but still training it to distinguish between fracture and other diseases. \n",
    "\n",
    "## 5th Architecture\n",
    "To avoid the overfitting, we reduce the number of trainable layers, so the first 400 layers are untrainable. Results in a mere 575K parameters to train. Reached val accuracy of 57% and trainina accuracy of aroun 80%. \n",
    "\n",
    "## 6th Architecture\n",
    "Changing the target column to be Enlarged Cardiomediastinum as that was found to be easier to detect in previous papers. Doing this also allowed us to increase the number of samples we use to 30K from 10K which should help a lot. Also increased untrainable layers to 420. This reduces trainable parameters to 200K.  If this doesn't work then we would also like to try data augementation I our next architecture to create more data, which will help the model generalise. Results were 80% training accuracy, 51% val accuracy. Therefore it's not working very well. \n",
    "\n",
    "## 7th Architecture\n",
    "Adding data augmentation. This changes the images slightly to increase the number of samples. Changes include slight rotations, slight translations. The images were also constrained to only include the PA angle, this reduced the number of samples to 20000. The training accuracy was 70% and val accuracy maxed out at 51%.\n",
    "\n",
    "## 8th\n",
    "same as 7th but using no finding as the negative case to avoid confusion with other diseases. Seemed very unstable but achieve max val acc of 56% and training acc of 66%. \n",
    "\n",
    "## 9th\n",
    "Tried freezing all the densenet layers. Reduced batch size to 16 to match the checxpert paper. 50k parameters. trainign 70% and val 50%.\n",
    "\n",
    "## 10th\n",
    "After reading: https://arxiv.org/pdf/1711.05225.pdf it turns out our original architecutre was much more similar to their papaer which ad some success. To more closely match theirs, i will change the disease to pneumonia, have all layers trainable and also set batch size to 16 to match their paper. They allow flipping of the image, which i think is invalid so will keep our data augmentation techniques. 7 million parameters. The batch size of 16 means we have a lot of backpropagations but it's much slower as a result. \n",
    "Achieved a training accuracy of 65% and validation accuracy of 72%, which is strange but we can see the val acc is very unstable so perhaps more reasonable to say around 70% if we take the average of the last few. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7ff619944eb8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trnsfer learning model\n",
    "# put into separate cell as getting the dense net takes time \n",
    "# and we often only want to tweak the downstream architecutre \n",
    "denseNet = DenseNet121(input_shape=(224,224,3), include_top=True)\n",
    "denseNet.layers.pop() # remov elast layer which has 1000 class softmax in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50176)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            50177       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,087,681\n",
      "Trainable params: 7,004,033\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thebox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model2Layers = Flatten()(denseNet.layers[-2].output)\n",
    "model2Layers = Dropout(0.3)(model2Layers)\n",
    "model2Layers = Dense(1,activation='sigmoid')(model2Layers)\n",
    "model2 = Model(input=denseNet.layers[0].input, output=model2Layers)\n",
    "for i,layer in enumerate(model2.layers):\n",
    "    # Don't train the first layers to save mem and they wil be picking up low level features anyway. \n",
    "    if i < 428:\n",
    "        #layer.trainable=False\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "weightsFilePath2=\"weights2.best.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/937 [==============================] - 260s 277ms/step - loss: 1.3947 - acc: 0.6121 - val_loss: 7.1000 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51600, saving model to weights2.best.hdf5\n",
      "Epoch 2/10\n",
      "938/937 [==============================] - 246s 263ms/step - loss: 1.1709 - acc: 0.6481 - val_loss: 0.7741 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.51600 to 0.62260, saving model to weights2.best.hdf5\n",
      "Epoch 3/10\n",
      "938/937 [==============================] - 246s 263ms/step - loss: 1.1312 - acc: 0.6430 - val_loss: 1.1354 - val_acc: 0.5234\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.62260\n",
      "Epoch 4/10\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.2572 - acc: 0.6334 - val_loss: 0.7320 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.62260\n",
      "Epoch 5/10\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.1227 - acc: 0.6535 - val_loss: 0.7506 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.62260 to 0.72260, saving model to weights2.best.hdf5\n",
      "Epoch 6/10\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.1357 - acc: 0.6603 - val_loss: 0.6581 - val_acc: 0.6478\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72260\n",
      "Epoch 7/10\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 1.0862 - acc: 0.6864 - val_loss: 0.5936 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72260\n",
      "Epoch 8/10\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0778 - acc: 0.6998 - val_loss: 0.6179 - val_acc: 0.6610\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.72260\n",
      "Epoch 9/10\n",
      "938/937 [==============================] - 245s 262ms/step - loss: 1.0040 - acc: 0.6967 - val_loss: 1.4373 - val_acc: 0.6736\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.72260\n",
      "Epoch 10/10\n",
      "938/937 [==============================] - 246s 262ms/step - loss: 0.9835 - acc: 0.6812 - val_loss: 0.5732 - val_acc: 0.7080\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.72260\n"
     ]
    }
   ],
   "source": [
    "checkpoint2 = ModelCheckpoint(weightsFilePath2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=.5,\n",
    "    height_shift_range=.5)\n",
    "#numberimage_gen.fit(x_train3Channel, augment=True)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "#history2 = model2.fit(x_train3Channel,y_train, epochs = 10, batch_size=128,  validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "history2 = model2.fit_generator(image_gen.flow(x_train3Channel, y_train, batch_size=batch_size),steps_per_epoch=len(x_train3Channel) / batch_size,  epochs = epochs, validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "model2.load_weights(weightsFilePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the history of this model\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('Model Accuracies')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'])\n",
    "plt.savefig(f\"Architecture10-{epochs}epochs-{colName}\")\n",
    "model2.save_weights(f\"Architecture10-{epochs}epochs-{colName}.hdf5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
