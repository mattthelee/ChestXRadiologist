{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image     \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "import os\n",
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('CheXpert-v1.0-small/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anomalous dataline\n",
    "trainDf = trainDf[trainDf.Sex != 'Unknown']\n",
    "\n",
    "def pathToID(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[2][7:]\n",
    "\n",
    "def pathToStudy(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[3][5:]\n",
    "\n",
    "# Convert all labels to a series of one-hot encoded labels. \n",
    "# -1 is uncertain, 0 is negative, 1 is positive, nans are no mention of the disease in the text\n",
    "trainDf = trainDf.fillna(0)\n",
    "# N.B. this is replacing unknowns with true as per u-ones model here: https://arxiv.org/pdf/1901.07031.pdf\n",
    "# This is essentialyl saying that if we're not sure of disease we say they have it. \n",
    "# Just to be on the safeside and have better recall as we care more about recall than precision\n",
    "trainDf = trainDf.replace(-1,1) \n",
    "\n",
    "\n",
    "# Onehot encode the sex and the xray orientation\n",
    "trainDf = trainDf.replace('Male',1)\n",
    "trainDf = trainDf.replace('Female',0)\n",
    "trainDf = trainDf.replace('Frontal',1)\n",
    "trainDf = trainDf.replace('Lateral',0)\n",
    "\n",
    "trainDf =trainDf.rename(index=str, columns={\"Sex\": \"Male?\",'Frontal/Lateral' :'Frontal1/Lateral0'})\n",
    "\n",
    "\n",
    "#trainDf.insert(0,'Path', trainDf['Path'])\n",
    "trainDf['Study'] = trainDf.Path.apply(pathToStudy)\n",
    "trainDf['Patient ID'] = trainDf.Path.apply(pathToID)\n",
    "\n",
    "# Rearrange Columns\n",
    "cols = ['Patient ID', 'Study', 'Path', 'Age', 'Male?', 'Frontal1/Lateral0', 'AP/PA','No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "trainDf = trainDf[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows age distribution of the data set. There are 3 0-olds and 7579 90 year olds. \n",
    "# Implies that over nineties were grouped together\n",
    "ages = trainDf['Age'].value_counts()\n",
    "plt.scatter(ages.keys(),ages.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people have no disease?\n",
    "no_finding = trainDf['No Finding'].value_counts()\n",
    "print(no_finding)\n",
    "\n",
    "# Plot pie chart to show how much of the data is labelled with each character\n",
    "values = no_finding.values\n",
    "labels = ['Disease present','All Clear']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Data Proportions', size=20)\n",
    "plt.pie(values, labels=labels, # explode=explode,\n",
    "        autopct='%1.1f%%', shadow=False, startangle=45)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    # Load image files\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (1, X, x) and return 3D tensor\n",
    "    return data.reshape(1,inputSize[0],inputSize[1])\n",
    "\n",
    "def paths_to_tensor(img_paths, inputSize):\n",
    "    # Convert paths to tensors for keras\n",
    "    list_of_tensors = [path_to_tensor(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)\n",
    "\n",
    "\n",
    "def path_to_tensor_channel_last_3colour(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (X, x, 3) and return 3D tensor\n",
    "    # Repeat the same image 3 times to create 3 channels for densenet\n",
    "    return np.stack((data,)*3, axis=-1)\n",
    "\n",
    "\n",
    "def paths_to_tensor_channel_last_3colour(img_paths, inputSize):\n",
    "    # Convert paths to tensors for keras\n",
    "    list_of_tensors = [path_to_tensor_channel_last_3colour(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = (224,224)\n",
    "\n",
    "sample_size =20000 # 30k is the memory limit for the server\n",
    "\n",
    "# Choose pathology to investigate\n",
    "targetColumn = [15]\n",
    "colName = trainDf.columns.tolist()[targetColumn[0]]\n",
    "print(f\"This model will be targetting {colName} column\")\n",
    "\n",
    "\n",
    "# Create balanced dataset with 50% pos examples and 50% neg examples, only take scans from the front\n",
    "pos = trainDf[(trainDf[colName] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "neg = trainDf[(trainDf['No Finding'] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "\n",
    "posSample = pos.sample(int(sample_size/2))\n",
    "negSample = neg.sample(int(sample_size/2))\n",
    "sample = pd.concat([posSample,negSample])\n",
    "x_train_paths, x_val_paths, y_train, y_val = train_test_split(sample.Path, sample[colName], stratify=sample[colName], random_state =2)\n",
    "\n",
    "# The 3 channel option is required for the denseNet and other transfer learning models\n",
    "# Single channel can be used on our none-transfer models\n",
    "\n",
    "#x_train = paths_to_tensor(x_train_paths,inputSize)#.astype('float32')/255\n",
    "x_train3Channel = paths_to_tensor_channel_last_3colour(x_train_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_train = trainDf.iloc[:training_no,targetColumn] # to do all labels: trainDf.iloc[:training_no,8:]\n",
    "#x_val = paths_to_tensor(x_val_paths,inputSize)#.astype('float32')/255\n",
    "x_val3Channel = paths_to_tensor_channel_last_3colour(x_val_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_val = trainDf.iloc[training_no:training_no+val_no,targetColumn]\n",
    "\n",
    "# Deleting dataframes in order to save memory and avoid OOM errors. \n",
    "del trainDf\n",
    "del posSample\n",
    "del negSample\n",
    "del x_train_paths\n",
    "del x_val_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trnsfer learning model\n",
    "# put into separate cell as getting the dense net takes time \n",
    "# and we often only want to tweak the downstream architecutre \n",
    "denseNet = DenseNet121(input_shape=(224,224,3), include_top=True)\n",
    "denseNet.layers.pop() # remov elast layer which has 1000 class softmax in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rest of the model\n",
    "model2Layers = Flatten()(denseNet.layers[-2].output)\n",
    "model2Layers = Dropout(0.3)(model2Layers)\n",
    "model2Layers = Dense(1,activation='sigmoid')(model2Layers)\n",
    "model2 = Model(input=denseNet.layers[0].input, output=model2Layers)\n",
    "for i,layer in enumerate(model2.layers):\n",
    "    # Don't train the first layers \n",
    "    if i < 428:\n",
    "        #layer.trainable=False\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "weightsFilePath2=\"weights2.best.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpointer that saves the best model weights\n",
    "checkpoint2 = ModelCheckpoint(weightsFilePath2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15)\n",
    "\n",
    "# Set model hyper params\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "\n",
    "# Train model\n",
    "history2 = model2.fit_generator(image_gen.flow(x_train3Channel, y_train, batch_size=batch_size),steps_per_epoch=len(x_train3Channel) / batch_size,  epochs = epochs, validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "# Load best weights\n",
    "model2.load_weights(weightsFilePath2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history of this model\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'])\n",
    "maxValAcc = max(history2.history['val_acc'])\n",
    "trainAcc = history2.history['acc'][history2.history['val_acc'].index(maxValAcc)]\n",
    "plt.savefig(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.png\")\n",
    "model2.save_weights(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.hdf5\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "In this section we analyse the results for each disease model. The models will load the weights from the best performing (as defined by validation accuracy) epoch. We then produce confusion matrices to calculate recall, precision and f1score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "testDf = pd.read_csv('CheXpert-v1.0-small/valid.csv')\n",
    "\n",
    "# Remove anomalous dataline\n",
    "testDf = testDf[testDf.Sex != 'Unknown']\n",
    "# Drop this column as it has many more classifications than lit suggests and shouldn't matter greatly for a CNN\n",
    "\n",
    "def pathToID(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[2][7:]\n",
    "\n",
    "def pathToStudy(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[3][5:]\n",
    "\n",
    "# Convert all labels to a series of one-hot encoded labels. \n",
    "# -1 is uncertain, 0 is negative, 1 is positive, nans are no mention of the disease in the text\n",
    "testDf = testDf.fillna(0)\n",
    "# N.B. this is replacing unknowns with true as per u-ones model here: https://arxiv.org/pdf/1901.07031.pdf\n",
    "# This is essentialyl saying that if we're not sure of disease we say they have it. \n",
    "# Just to be on the safeside and have better recall as we care more about recall than precision\n",
    "testDf = testDf.replace(-1,1) \n",
    "\n",
    "\n",
    "# Onehot encode the sex and the xray orientation\n",
    "testDf = testDf.replace('Male',1)\n",
    "testDf = testDf.replace('Female',0)\n",
    "testDf = testDf.replace('Frontal',1)\n",
    "testDf = testDf.replace('Lateral',0)\n",
    "\n",
    "testDf =testDf.rename(index=str, columns={\"Sex\": \"Male?\",'Frontal/Lateral' :'Frontal1/Lateral0'})\n",
    "\n",
    "\n",
    "#trainDf.insert(0,'Path', trainDf['Path'])\n",
    "testDf['Study'] = testDf.Path.apply(pathToStudy)\n",
    "testDf['Patient ID'] = testDf.Path.apply(pathToID)\n",
    "\n",
    "# Rearrange Columns\n",
    "cols = ['Patient ID', 'Study', 'Path', 'Age', 'Male?', 'Frontal1/Lateral0', 'AP/PA','No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "testDf = testDf[cols]\n",
    "\n",
    "x_test3Channel = paths_to_tensor_channel_last_3colour(testDf.Path,inputSize)#.astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseResults(model,x_test3Channel, testDf, disease, radiologistScores=None):\n",
    "    # Analyses for a given pathology, getting roc curve and AUROC\n",
    "    # Identify correct weights file to load\n",
    "    file = [f for f in os.listdir('.') if os.path.isfile(f) and f\"20epochs-{disease}\"  in f and \".hdf5\" in f]\n",
    "    if len(file) != 1:\n",
    "        print(f\"Error: can't find single weights file, instead found: {file}\")\n",
    "    \n",
    "    # Load in best weights\n",
    "    model.load_weights(file[0])\n",
    "    \n",
    "    # Generate roc curve values\n",
    "    model_predict_output = model.predict(x_test3Channel).flatten()\n",
    "    y_test = testDf[disease]\n",
    "    fpr, tpr, _ = roc_curve(y_test, model_predict_output)\n",
    "    \n",
    "    # Get AUROC\n",
    "    auroc = roc_auc_score(y_test,model_predict_output)\n",
    "    \n",
    "    # Plot ROC\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr)\n",
    "    \n",
    "    # If radiologist scores as provided, plot them\n",
    "    if radiologistScores != None:  \n",
    "        plt.plot(radiologistScores[0][0],radiologistScores[0][1],'ro', label=\"Rad1\") \n",
    "        plt.plot(radiologistScores[1][0],radiologistScores[1][1],'bo', label=\"Rad1\") \n",
    "        plt.plot(radiologistScores[2][0],radiologistScores[2][1],'go', label=\"Rad1\") \n",
    "\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.savefig(f\"Architecture10-{disease}--AUROC-{auroc}.png\")\n",
    "\n",
    "    plt.show()\n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['Cardiomegaly','Atelectasis','Edema','Pneumonia','Pneumothorax']\n",
    "# Radiologist scores from ChexPert paper. \n",
    "rads = [  [[0.05,0.48],[0.23,0.85],[0.11,0.70]], [[0.21,0.8],[0.18,0.71],[0.31,0.92]], [[0.09,0.63],[0.19,0.79],[0.07,0.58]] ]\n",
    "\n",
    "# Plot for each pathology\n",
    "for i,disease in enumerate(diseases):\n",
    "    if i <= 2:\n",
    "        auroc = analyseResults(model2,x_test3Channel,testDf,disease, radiologistScores=rads[i])\n",
    "    else:\n",
    "        auroc = analyseResults(model2,x_test3Channel,testDf,disease)\n",
    "    print(f\"{disease} AUROC: {auroc}\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
