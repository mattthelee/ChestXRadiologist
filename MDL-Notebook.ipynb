{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image     \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Accuracy is good but no better than guess all one class. Think this could be solved by addressing class imbalance\n",
    "- Accuracy is only good if we take the binary crossentropy and not the full label accuracy. Will need to speak to the lecturer about how to measure performance for this type of multilabel data. -> suggested splitting into sublabels and report average accuracy of models vs each of the different single label classification tasks. \n",
    "\n",
    "# TODO\n",
    "- Need to balance the classes before passing them into the model. I.e. we need to take in more data to get a 50 50 split between having a disease and not, then run through the model. This should be possible as currently we're only processing 1% of the data. 10% is without any disease so that;s 20k. We then use another 20k with a disease. \n",
    "- Also need to add the gender and age into the x train so the model can use this information as well as the image. \n",
    "- May want to pass the data into a high res image generator or use the high res images, which would require using the GPU servers\n",
    "- To allow a more complex model to learn quickly on the gpu servers, may want to try using transfer learning from an existing model\n",
    "\n",
    "# Done\n",
    "- Need to change all the unknowns into positives as evidenced by the success of u-ones model on this paper: https://arxiv.org/pdf/1901.07031.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('CheXpert-v1.0-small/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove anomalous dataline\n",
    "trainDf = trainDf[trainDf.Sex != 'Unknown']\n",
    "# Drop this column as it has many more classifications than lit suggests and shouldn't matter greatly for a CNN\n",
    "# TODO try with and without this column\n",
    "#trainDf = trainDf.drop('AP/PA', 1)\n",
    "\n",
    "def pathToID(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[2][7:]\n",
    "\n",
    "def pathToStudy(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[3][5:]\n",
    "\n",
    "# Convert all labels to a series of one-hot encoded labels. \n",
    "# -1 is uncertain, 0 is negative, 1 is positive, nans are no mention of the disease in the text\n",
    "trainDf = trainDf.fillna(0)\n",
    "# N.B. this is replacing unknowns with true as per u-ones model here: https://arxiv.org/pdf/1901.07031.pdf\n",
    "# This is essentialyl saying that if we're not sure of disease we say they have it. \n",
    "# Just to be on the safeside and have better recall as we care more about recall than precision\n",
    "trainDf = trainDf.replace(-1,1) \n",
    "\n",
    "\n",
    "# Onehot encode the sex and the xray orientation\n",
    "trainDf = trainDf.replace('Male',1)\n",
    "trainDf = trainDf.replace('Female',0)\n",
    "trainDf = trainDf.replace('Frontal',1)\n",
    "trainDf = trainDf.replace('Lateral',0)\n",
    "\n",
    "trainDf =trainDf.rename(index=str, columns={\"Sex\": \"Male?\",'Frontal/Lateral' :'Frontal1/Lateral0'})\n",
    "\n",
    "\n",
    "#trainDf.insert(0,'Path', trainDf['Path'])\n",
    "trainDf['Study'] = trainDf.Path.apply(pathToStudy)\n",
    "trainDf['Patient ID'] = trainDf.Path.apply(pathToID)\n",
    "\n",
    "# Rearrange Columns\n",
    "cols = ['Patient ID', 'Study', 'Path', 'Age', 'Male?', 'Frontal1/Lateral0', 'AP/PA','No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "trainDf = trainDf[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe5a22c9278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows age distribution of the data set. There are 3 0-olds and 7579 90 year olds. \n",
    "# Implies that over nineties were grouped together\n",
    "ages = trainDf['Age'].value_counts()\n",
    "plt.scatter(ages.keys(),ages.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe59fd5a3c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender = trainDf['Male?'].value_counts()\n",
    "plt.scatter(gender.keys(),gender.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    201033\n",
      "1.0     22380\n",
      "Name: No Finding, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many people have no disease?\n",
    "no_finding = trainDf['No Finding'].value_counts()\n",
    "print(no_finding)\n",
    "\n",
    "# Plot pie chart to show how much of the data is labelled with each character\n",
    "values = no_finding.values\n",
    "labels = ['Disease present','All Clear']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Data Proportions', size=20)\n",
    "plt.pie(values, labels=labels, # explode=explode,\n",
    "        autopct='%1.1f%%', shadow=False, startangle=45)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Study</th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>Male?</th>\n",
       "      <th>Frontal1/Lateral0</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>...</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00006</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00007</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study1/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00007</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study2/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00008</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00008</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study2/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00011</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study1/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00011</td>\n",
       "      <td>5</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study5/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00011</td>\n",
       "      <td>7</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study7/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00011</td>\n",
       "      <td>4</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study4/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00011</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study2/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00011</td>\n",
       "      <td>10</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study10...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00011</td>\n",
       "      <td>9</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study9/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00011</td>\n",
       "      <td>11</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study11...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223384</th>\n",
       "      <td>64515</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64515/study1/...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223385</th>\n",
       "      <td>64516</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64516/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223386</th>\n",
       "      <td>64517</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64517/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223387</th>\n",
       "      <td>64518</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64518/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223388</th>\n",
       "      <td>64519</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64519/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223389</th>\n",
       "      <td>64520</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64520/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223390</th>\n",
       "      <td>64521</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64521/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223391</th>\n",
       "      <td>64522</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64522/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223392</th>\n",
       "      <td>64523</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64523/study1/...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223393</th>\n",
       "      <td>64524</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64524/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223394</th>\n",
       "      <td>64525</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64525/study1/...</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223395</th>\n",
       "      <td>64526</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64526/study1/...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223396</th>\n",
       "      <td>64527</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study2/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223397</th>\n",
       "      <td>64527</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study1/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223398</th>\n",
       "      <td>64528</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64528/study1/...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223399</th>\n",
       "      <td>64529</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64529/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223400</th>\n",
       "      <td>64530</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64530/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223401</th>\n",
       "      <td>64531</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64531/study1/...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223402</th>\n",
       "      <td>64532</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64532/study1/...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>64533</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223404</th>\n",
       "      <td>64533</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study2/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>64534</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223406</th>\n",
       "      <td>64535</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64535/study1/...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>64536</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223408</th>\n",
       "      <td>64536</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>64537</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>64537</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223411</th>\n",
       "      <td>64538</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64538/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223412</th>\n",
       "      <td>64539</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64539/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223413</th>\n",
       "      <td>64540</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64540/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223413 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient ID Study                                               Path  \\\n",
       "0           00001     1  CheXpert-v1.0-small/train/patient00001/study1/...   \n",
       "1           00002     2  CheXpert-v1.0-small/train/patient00002/study2/...   \n",
       "2           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "3           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "4           00003     1  CheXpert-v1.0-small/train/patient00003/study1/...   \n",
       "5           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "6           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "7           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "8           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "9           00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "10          00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "11          00006     1  CheXpert-v1.0-small/train/patient00006/study1/...   \n",
       "12          00007     1  CheXpert-v1.0-small/train/patient00007/study1/...   \n",
       "13          00007     2  CheXpert-v1.0-small/train/patient00007/study2/...   \n",
       "14          00008     1  CheXpert-v1.0-small/train/patient00008/study1/...   \n",
       "15          00008     2  CheXpert-v1.0-small/train/patient00008/study2/...   \n",
       "16          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "17          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "18          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "19          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "20          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "21          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "22          00011     1  CheXpert-v1.0-small/train/patient00011/study1/...   \n",
       "23          00011     5  CheXpert-v1.0-small/train/patient00011/study5/...   \n",
       "24          00011     7  CheXpert-v1.0-small/train/patient00011/study7/...   \n",
       "25          00011     4  CheXpert-v1.0-small/train/patient00011/study4/...   \n",
       "26          00011     2  CheXpert-v1.0-small/train/patient00011/study2/...   \n",
       "27          00011    10  CheXpert-v1.0-small/train/patient00011/study10...   \n",
       "28          00011     9  CheXpert-v1.0-small/train/patient00011/study9/...   \n",
       "29          00011    11  CheXpert-v1.0-small/train/patient00011/study11...   \n",
       "...           ...   ...                                                ...   \n",
       "223384      64515     1  CheXpert-v1.0-small/train/patient64515/study1/...   \n",
       "223385      64516     1  CheXpert-v1.0-small/train/patient64516/study1/...   \n",
       "223386      64517     1  CheXpert-v1.0-small/train/patient64517/study1/...   \n",
       "223387      64518     1  CheXpert-v1.0-small/train/patient64518/study1/...   \n",
       "223388      64519     1  CheXpert-v1.0-small/train/patient64519/study1/...   \n",
       "223389      64520     1  CheXpert-v1.0-small/train/patient64520/study1/...   \n",
       "223390      64521     1  CheXpert-v1.0-small/train/patient64521/study1/...   \n",
       "223391      64522     1  CheXpert-v1.0-small/train/patient64522/study1/...   \n",
       "223392      64523     1  CheXpert-v1.0-small/train/patient64523/study1/...   \n",
       "223393      64524     1  CheXpert-v1.0-small/train/patient64524/study1/...   \n",
       "223394      64525     1  CheXpert-v1.0-small/train/patient64525/study1/...   \n",
       "223395      64526     1  CheXpert-v1.0-small/train/patient64526/study1/...   \n",
       "223396      64527     2  CheXpert-v1.0-small/train/patient64527/study2/...   \n",
       "223397      64527     1  CheXpert-v1.0-small/train/patient64527/study1/...   \n",
       "223398      64528     1  CheXpert-v1.0-small/train/patient64528/study1/...   \n",
       "223399      64529     1  CheXpert-v1.0-small/train/patient64529/study1/...   \n",
       "223400      64530     1  CheXpert-v1.0-small/train/patient64530/study1/...   \n",
       "223401      64531     1  CheXpert-v1.0-small/train/patient64531/study1/...   \n",
       "223402      64532     1  CheXpert-v1.0-small/train/patient64532/study1/...   \n",
       "223403      64533     1  CheXpert-v1.0-small/train/patient64533/study1/...   \n",
       "223404      64533     2  CheXpert-v1.0-small/train/patient64533/study2/...   \n",
       "223405      64534     1  CheXpert-v1.0-small/train/patient64534/study1/...   \n",
       "223406      64535     1  CheXpert-v1.0-small/train/patient64535/study1/...   \n",
       "223407      64536     2  CheXpert-v1.0-small/train/patient64536/study2/...   \n",
       "223408      64536     1  CheXpert-v1.0-small/train/patient64536/study1/...   \n",
       "223409      64537     2  CheXpert-v1.0-small/train/patient64537/study2/...   \n",
       "223410      64537     1  CheXpert-v1.0-small/train/patient64537/study1/...   \n",
       "223411      64538     1  CheXpert-v1.0-small/train/patient64538/study1/...   \n",
       "223412      64539     1  CheXpert-v1.0-small/train/patient64539/study1/...   \n",
       "223413      64540     1  CheXpert-v1.0-small/train/patient64540/study1/...   \n",
       "\n",
       "        Age  Male?  Frontal1/Lateral0 AP/PA  No Finding  \\\n",
       "0        68      0                  1    AP         1.0   \n",
       "1        87      0                  1    AP         0.0   \n",
       "2        83      0                  1    AP         0.0   \n",
       "3        83      0                  0     0         0.0   \n",
       "4        41      1                  1    AP         0.0   \n",
       "5        20      0                  1    PA         1.0   \n",
       "6        20      0                  0     0         1.0   \n",
       "7        33      1                  1    PA         1.0   \n",
       "8        33      1                  0     0         1.0   \n",
       "9        33      1                  1    AP         0.0   \n",
       "10       33      1                  1    AP         0.0   \n",
       "11       42      0                  1    AP         1.0   \n",
       "12       69      1                  1    AP         0.0   \n",
       "13       69      1                  1    AP         0.0   \n",
       "14       81      1                  1    AP         0.0   \n",
       "15       81      1                  1    AP         0.0   \n",
       "16       76      1                  1    PA         0.0   \n",
       "17       76      1                  0     0         0.0   \n",
       "18       50      0                  1    PA         1.0   \n",
       "19       50      0                  0     0         1.0   \n",
       "20       22      0                  1    PA         0.0   \n",
       "21       22      0                  0     0         0.0   \n",
       "22       19      0                  1    AP         0.0   \n",
       "23       19      0                  1    AP         0.0   \n",
       "24       19      0                  1    AP         0.0   \n",
       "25       19      0                  1    AP         0.0   \n",
       "26       19      0                  1    AP         0.0   \n",
       "27       19      0                  1    AP         0.0   \n",
       "28       19      0                  1    AP         0.0   \n",
       "29       19      0                  1    AP         0.0   \n",
       "...     ...    ...                ...   ...         ...   \n",
       "223384   25      1                  1    AP         1.0   \n",
       "223385   75      0                  1    AP         1.0   \n",
       "223386   21      1                  1    AP         1.0   \n",
       "223387   68      1                  1    AP         0.0   \n",
       "223388   33      0                  1    AP         1.0   \n",
       "223389   65      0                  1    AP         1.0   \n",
       "223390   63      0                  1    AP         0.0   \n",
       "223391   21      0                  1    AP         1.0   \n",
       "223392   90      0                  1    AP         0.0   \n",
       "223393   61      0                  1    AP         0.0   \n",
       "223394   87      1                  1    AP         0.0   \n",
       "223395   55      1                  1    AP         0.0   \n",
       "223396   85      1                  1    AP         0.0   \n",
       "223397   85      1                  1    AP         0.0   \n",
       "223398   77      1                  1    AP         0.0   \n",
       "223399   81      1                  1    AP         0.0   \n",
       "223400   65      1                  1    AP         0.0   \n",
       "223401   57      0                  1    AP         0.0   \n",
       "223402   52      0                  1    AP         1.0   \n",
       "223403   75      1                  1    AP         0.0   \n",
       "223404   75      1                  1    AP         0.0   \n",
       "223405   63      1                  1    AP         0.0   \n",
       "223406   60      1                  1    AP         0.0   \n",
       "223407   61      0                  1    AP         0.0   \n",
       "223408   61      0                  1    AP         0.0   \n",
       "223409   59      1                  1    AP         0.0   \n",
       "223410   59      1                  1    AP         0.0   \n",
       "223411    0      0                  1    AP         0.0   \n",
       "223412    0      0                  1    AP         0.0   \n",
       "223413    0      0                  1    AP         1.0   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly       ...         \\\n",
       "0                              0.0           0.0       ...          \n",
       "1                              0.0           1.0       ...          \n",
       "2                              0.0           0.0       ...          \n",
       "3                              0.0           0.0       ...          \n",
       "4                              0.0           0.0       ...          \n",
       "5                              0.0           0.0       ...          \n",
       "6                              0.0           0.0       ...          \n",
       "7                              0.0           0.0       ...          \n",
       "8                              0.0           0.0       ...          \n",
       "9                              0.0           0.0       ...          \n",
       "10                             0.0           0.0       ...          \n",
       "11                             0.0           0.0       ...          \n",
       "12                             0.0           1.0       ...          \n",
       "13                             1.0           0.0       ...          \n",
       "14                             0.0           0.0       ...          \n",
       "15                             0.0           0.0       ...          \n",
       "16                             0.0           1.0       ...          \n",
       "17                             0.0           1.0       ...          \n",
       "18                             0.0           0.0       ...          \n",
       "19                             0.0           0.0       ...          \n",
       "20                             0.0           0.0       ...          \n",
       "21                             0.0           0.0       ...          \n",
       "22                             0.0           0.0       ...          \n",
       "23                             0.0           0.0       ...          \n",
       "24                             0.0           0.0       ...          \n",
       "25                             0.0           0.0       ...          \n",
       "26                             0.0           0.0       ...          \n",
       "27                             0.0           0.0       ...          \n",
       "28                             1.0           0.0       ...          \n",
       "29                             0.0           0.0       ...          \n",
       "...                            ...           ...       ...          \n",
       "223384                         0.0           0.0       ...          \n",
       "223385                         0.0           0.0       ...          \n",
       "223386                         0.0           0.0       ...          \n",
       "223387                         0.0           0.0       ...          \n",
       "223388                         0.0           0.0       ...          \n",
       "223389                         0.0           0.0       ...          \n",
       "223390                         0.0           0.0       ...          \n",
       "223391                         0.0           0.0       ...          \n",
       "223392                         0.0           0.0       ...          \n",
       "223393                         0.0           0.0       ...          \n",
       "223394                         0.0           0.0       ...          \n",
       "223395                         0.0           0.0       ...          \n",
       "223396                         0.0           1.0       ...          \n",
       "223397                         0.0           1.0       ...          \n",
       "223398                         1.0           0.0       ...          \n",
       "223399                         0.0           0.0       ...          \n",
       "223400                         0.0           0.0       ...          \n",
       "223401                         0.0           0.0       ...          \n",
       "223402                         0.0           0.0       ...          \n",
       "223403                         0.0           1.0       ...          \n",
       "223404                         0.0           0.0       ...          \n",
       "223405                         0.0           0.0       ...          \n",
       "223406                         0.0           0.0       ...          \n",
       "223407                         0.0           0.0       ...          \n",
       "223408                         0.0           0.0       ...          \n",
       "223409                         0.0           0.0       ...          \n",
       "223410                         0.0           0.0       ...          \n",
       "223411                         0.0           0.0       ...          \n",
       "223412                         0.0           1.0       ...          \n",
       "223413                         0.0           0.0       ...          \n",
       "\n",
       "        Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0               0.0    0.0            0.0        0.0          0.0   \n",
       "1               0.0    1.0            1.0        0.0          1.0   \n",
       "2               0.0    0.0            1.0        0.0          0.0   \n",
       "3               0.0    0.0            1.0        0.0          0.0   \n",
       "4               0.0    1.0            0.0        0.0          0.0   \n",
       "5               0.0    0.0            0.0        0.0          0.0   \n",
       "6               0.0    0.0            0.0        0.0          0.0   \n",
       "7               0.0    0.0            0.0        0.0          0.0   \n",
       "8               0.0    0.0            0.0        0.0          0.0   \n",
       "9               0.0    0.0            0.0        0.0          0.0   \n",
       "10              0.0    0.0            0.0        0.0          0.0   \n",
       "11              0.0    0.0            0.0        0.0          0.0   \n",
       "12              0.0    0.0            0.0        0.0          1.0   \n",
       "13              0.0    0.0            0.0        0.0          1.0   \n",
       "14              0.0    0.0            0.0        0.0          0.0   \n",
       "15              0.0    0.0            0.0        0.0          0.0   \n",
       "16              0.0    0.0            0.0        0.0          1.0   \n",
       "17              0.0    0.0            0.0        0.0          1.0   \n",
       "18              0.0    0.0            0.0        0.0          0.0   \n",
       "19              0.0    0.0            0.0        0.0          0.0   \n",
       "20              0.0    0.0            0.0        0.0          0.0   \n",
       "21              0.0    0.0            0.0        0.0          0.0   \n",
       "22              0.0    0.0            1.0        0.0          0.0   \n",
       "23              0.0    0.0            0.0        0.0          0.0   \n",
       "24              0.0    0.0            0.0        0.0          0.0   \n",
       "25              0.0    0.0            0.0        0.0          1.0   \n",
       "26              0.0    0.0            1.0        0.0          0.0   \n",
       "27              0.0    1.0            0.0        0.0          0.0   \n",
       "28              0.0    0.0            0.0        0.0          0.0   \n",
       "29              0.0    1.0            0.0        0.0          0.0   \n",
       "...             ...    ...            ...        ...          ...   \n",
       "223384          0.0    0.0            0.0        0.0          0.0   \n",
       "223385          0.0    0.0            0.0        0.0          0.0   \n",
       "223386          0.0    0.0            0.0        0.0          0.0   \n",
       "223387          0.0    1.0            0.0        0.0          0.0   \n",
       "223388          0.0    0.0            0.0        0.0          0.0   \n",
       "223389          0.0    0.0            0.0        0.0          0.0   \n",
       "223390          0.0    0.0            0.0        0.0          0.0   \n",
       "223391          0.0    0.0            0.0        0.0          0.0   \n",
       "223392          0.0    0.0            1.0        0.0          0.0   \n",
       "223393          0.0    0.0            0.0        0.0          1.0   \n",
       "223394          0.0    0.0            0.0        0.0          0.0   \n",
       "223395          0.0    0.0            0.0        1.0          1.0   \n",
       "223396          0.0    1.0            0.0        0.0          0.0   \n",
       "223397          0.0    1.0            0.0        0.0          1.0   \n",
       "223398          0.0    0.0            0.0        0.0          0.0   \n",
       "223399          0.0    0.0            0.0        0.0          0.0   \n",
       "223400          0.0    1.0            0.0        0.0          0.0   \n",
       "223401          1.0    0.0            0.0        0.0          1.0   \n",
       "223402          0.0    0.0            0.0        0.0          0.0   \n",
       "223403          0.0    1.0            0.0        0.0          0.0   \n",
       "223404          0.0    0.0            1.0        0.0          1.0   \n",
       "223405          0.0    0.0            0.0        0.0          1.0   \n",
       "223406          0.0    0.0            1.0        0.0          1.0   \n",
       "223407          0.0    1.0            0.0        0.0          0.0   \n",
       "223408          0.0    1.0            0.0        0.0          1.0   \n",
       "223409          0.0    0.0            0.0        0.0          1.0   \n",
       "223410          0.0    0.0            0.0        0.0          1.0   \n",
       "223411          0.0    1.0            0.0        0.0          0.0   \n",
       "223412          0.0    0.0            0.0        1.0          1.0   \n",
       "223413          0.0    0.0            0.0        0.0          0.0   \n",
       "\n",
       "        Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "0                0.0               0.0            0.0       0.0   \n",
       "1                0.0               1.0            0.0       1.0   \n",
       "2                0.0               0.0            0.0       1.0   \n",
       "3                0.0               0.0            0.0       1.0   \n",
       "4                0.0               0.0            0.0       0.0   \n",
       "5                0.0               0.0            0.0       0.0   \n",
       "6                0.0               0.0            0.0       0.0   \n",
       "7                0.0               0.0            0.0       0.0   \n",
       "8                0.0               0.0            0.0       0.0   \n",
       "9                1.0               0.0            0.0       0.0   \n",
       "10               1.0               0.0            0.0       0.0   \n",
       "11               0.0               0.0            0.0       0.0   \n",
       "12               1.0               0.0            0.0       0.0   \n",
       "13               0.0               0.0            0.0       0.0   \n",
       "14               0.0               1.0            0.0       0.0   \n",
       "15               0.0               1.0            0.0       0.0   \n",
       "16               0.0               0.0            0.0       0.0   \n",
       "17               0.0               0.0            0.0       0.0   \n",
       "18               0.0               0.0            0.0       0.0   \n",
       "19               0.0               0.0            0.0       0.0   \n",
       "20               0.0               0.0            0.0       0.0   \n",
       "21               0.0               0.0            0.0       0.0   \n",
       "22               1.0               1.0            0.0       0.0   \n",
       "23               1.0               0.0            0.0       0.0   \n",
       "24               0.0               0.0            0.0       0.0   \n",
       "25               1.0               1.0            0.0       0.0   \n",
       "26               0.0               1.0            0.0       0.0   \n",
       "27               0.0               1.0            0.0       0.0   \n",
       "28               0.0               1.0            0.0       0.0   \n",
       "29               0.0               1.0            0.0       0.0   \n",
       "...              ...               ...            ...       ...   \n",
       "223384           0.0               0.0            0.0       0.0   \n",
       "223385           0.0               0.0            0.0       0.0   \n",
       "223386           0.0               0.0            0.0       0.0   \n",
       "223387           0.0               0.0            0.0       0.0   \n",
       "223388           0.0               0.0            0.0       0.0   \n",
       "223389           0.0               0.0            0.0       0.0   \n",
       "223390           0.0               0.0            0.0       1.0   \n",
       "223391           0.0               0.0            0.0       0.0   \n",
       "223392           0.0               0.0            0.0       0.0   \n",
       "223393           0.0               0.0            0.0       0.0   \n",
       "223394           0.0               1.0            0.0       0.0   \n",
       "223395           0.0               1.0            0.0       1.0   \n",
       "223396           0.0               1.0            0.0       0.0   \n",
       "223397           0.0               1.0            0.0       0.0   \n",
       "223398           0.0               1.0            0.0       0.0   \n",
       "223399           0.0               0.0            0.0       0.0   \n",
       "223400           0.0               0.0            0.0       0.0   \n",
       "223401           1.0               1.0            0.0       0.0   \n",
       "223402           0.0               0.0            0.0       0.0   \n",
       "223403           0.0               1.0            0.0       0.0   \n",
       "223404           0.0               0.0            0.0       0.0   \n",
       "223405           0.0               0.0            0.0       0.0   \n",
       "223406           0.0               0.0            0.0       0.0   \n",
       "223407           0.0               1.0            0.0       0.0   \n",
       "223408           0.0               0.0            0.0       0.0   \n",
       "223409           0.0               1.0            0.0       0.0   \n",
       "223410           0.0               1.0            0.0       0.0   \n",
       "223411           0.0               0.0            0.0       0.0   \n",
       "223412           0.0               0.0            0.0       0.0   \n",
       "223413           0.0               0.0            0.0       0.0   \n",
       "\n",
       "        Support Devices  \n",
       "0                   1.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  \n",
       "6                   0.0  \n",
       "7                   1.0  \n",
       "8                   1.0  \n",
       "9                   0.0  \n",
       "10                  0.0  \n",
       "11                  0.0  \n",
       "12                  1.0  \n",
       "13                  1.0  \n",
       "14                  1.0  \n",
       "15                  1.0  \n",
       "16                  0.0  \n",
       "17                  0.0  \n",
       "18                  0.0  \n",
       "19                  0.0  \n",
       "20                  0.0  \n",
       "21                  0.0  \n",
       "22                  1.0  \n",
       "23                  0.0  \n",
       "24                  1.0  \n",
       "25                  1.0  \n",
       "26                  1.0  \n",
       "27                  1.0  \n",
       "28                  1.0  \n",
       "29                  1.0  \n",
       "...                 ...  \n",
       "223384              0.0  \n",
       "223385              0.0  \n",
       "223386              1.0  \n",
       "223387              0.0  \n",
       "223388              1.0  \n",
       "223389              0.0  \n",
       "223390              0.0  \n",
       "223391              0.0  \n",
       "223392              0.0  \n",
       "223393              1.0  \n",
       "223394              0.0  \n",
       "223395              0.0  \n",
       "223396              1.0  \n",
       "223397              1.0  \n",
       "223398              0.0  \n",
       "223399              0.0  \n",
       "223400              1.0  \n",
       "223401              1.0  \n",
       "223402              1.0  \n",
       "223403              1.0  \n",
       "223404              0.0  \n",
       "223405              0.0  \n",
       "223406              0.0  \n",
       "223407              0.0  \n",
       "223408              1.0  \n",
       "223409              0.0  \n",
       "223410              0.0  \n",
       "223411              0.0  \n",
       "223412              0.0  \n",
       "223413              0.0  \n",
       "\n",
       "[223413 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (1, X, x) and return 3D tensor\n",
    "    return data.reshape(1,inputSize[0],inputSize[1])\n",
    "\n",
    "def paths_to_tensor(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)\n",
    "\n",
    "\n",
    "def path_to_tensor_channel_last_3colour(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (X, x, 3) and return 3D tensor\n",
    "    return np.stack((data,)*3, axis=-1)\n",
    "\n",
    "\n",
    "def paths_to_tensor_channel_last_3colour(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor_channel_last_3colour(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model will be targetting Edema column\n"
     ]
    }
   ],
   "source": [
    "inputSize = (224,224)\n",
    "\n",
    "sample_size =20000 # 30k is the memory limit for the server\n",
    "targetColumn = [12]\n",
    "colName = trainDf.columns.tolist()[targetColumn[0]]\n",
    "print(f\"This model will be targetting {colName} column\")\n",
    "\n",
    "\n",
    "# Create balanced dataset with 50% pos examples and 50% neg examples, only take scans from the front\n",
    "pos = trainDf[(trainDf[colName] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "neg = trainDf[(trainDf['No Finding'] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "posSample = pos.sample(int(sample_size/2))\n",
    "negSample = neg.sample(int(sample_size/2))\n",
    "sample = pd.concat([posSample,negSample])\n",
    "\n",
    "x_train_paths, x_val_paths, y_train, y_val = train_test_split(sample.Path, sample[colName], stratify=sample[colName], random_state =2)\n",
    "\n",
    "\n",
    "\n",
    "# The 3 channel option is required for the denseNet and other transfer learning models\n",
    "# Single channel can be used on our models\n",
    "\n",
    "#x_train = paths_to_tensor(x_train_paths,inputSize)#.astype('float32')/255\n",
    "x_train3Channel = paths_to_tensor_channel_last_3colour(x_train_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_train = trainDf.iloc[:training_no,targetColumn] # to do all labels: trainDf.iloc[:training_no,8:]\n",
    "#x_val = paths_to_tensor(x_val_paths,inputSize)#.astype('float32')/255\n",
    "x_val3Channel = paths_to_tensor_channel_last_3colour(x_val_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_val = trainDf.iloc[training_no:training_no+val_no,targetColumn]\n",
    "\n",
    "# Deleting dataframes in order to save memory and avoid OOM errors. \n",
    "del trainDf\n",
    "del posSample\n",
    "del negSample\n",
    "del x_train_paths\n",
    "del x_val_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(y_val))\\nprint(x_train[0].shape)\\nplt.imshow(x_train[0][0], interpolation='nearest')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(len(y_val))\n",
    "print(x_train[0].shape)\n",
    "plt.imshow(x_train[0][0], interpolation='nearest')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\\nmodel.add(Conv2D(32, (3,3)))\\nmodel.add(Conv2D(16, (3,3)))\\n\\nmodel.add(Flatten())\\n#model.add(Dropout(0.2))\\n#model.add(Dense(32,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n#model.add(Dense(16,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n\\n\\n\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\nmodel.summary()\\nweightsFilePath=\"weights.best.hdf5\"\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(32,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(16,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "weightsFilePath=\"weights.best.hdf5\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncheckpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\\n\\nhistory = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\\nmodel.load_weights(weightsFilePath)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "'''\n",
    "checkpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\n",
    "model.load_weights(weightsFilePath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAcc(predictions, truths):\n",
    "    wrongs = 0\n",
    "    for i,prediction in enumerate(predictions):\n",
    "        truth = truths[i]\n",
    "        for j, val in enumerate(prediction):\n",
    "            if val >= 0.5 and truth[j] == 0:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "            if val < 0.5 and truth[j] == 1:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "    total = 41*len(predictions) # len(predictions)\n",
    "    return (total - wrongs) / total, wrongs, total\n",
    "                \n",
    "            \n",
    "#checkAcc(predictions, y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try:\n",
    "- Could try using class weighting to handle class imbalance rather than sampling data to have no class imbalance\n",
    "- Adding in the other data as an input to a fully connected layer. This would allow network to use gender and age in it's predictions.\n",
    "- Try using no finding for the neg samples rather than 0 for the column, that way we don't have it confuse diseases. \n",
    "\n",
    "\n",
    "All of these were tested on the fracture data with 10k samples. \n",
    "## 1st Architecture:\n",
    "Tried using densenet with untrainable layers straighinto 0.3 dropout and 1 unit sigmoid output layer\n",
    "It acheived training acc around 70% and val acc of 56% after 10 epochs but didn't seem to be clearly improving\n",
    "\n",
    "## 2nd architecture\n",
    " Tried an architecture with include_top = False and two layers of 128 units and 0.2 dropouts. \n",
    "however it never got past a training acc of around 0.5. This motivates me to increase the complexity of the model and train more of it. \n",
    "## 3rd Architecture\n",
    "Same as first, but now trying with densenet first 200 layers as untrainable but rest trainable and removing last layer so it has only one class sigmoid rather than 1000 class softmax. This hadn't been possible on my laptop efore due to memm issues but is possible on Johnny's server. By removing the last layer we reduce the number of params by 1million, but allowing trainability means the network takes longer to train as we have ~4million trainable parameters. Achieved 95% training accuracy but only 54% val accuracy. At least this means we're able to get a decent accuracy somewhere, we clearly just need to prevent overfitting. Can't increase much more than 10k dataset, so best to try other ways to prevent overfitting -> dropout layers, or reducing trainable params\n",
    "\n",
    "## 4th Architecture\n",
    "addition of dropout layer before the last dense layer and also set the untrainable to be the first 300 layers rather than 200. reduces trainable params to 2 million. This actually resulted in training accuracy reaching 98% within 4 epochs, which is a bit disappointing/confusing. val acc maxed out at 0.50240Perhaps the trainble layers require more dropout or perhaps i need to furhter reduce the trainable params.Perhaps the difficulty is that it is seeing one of the other diseases, that can look like a fracture, so perhaps the data should be weighted to be 50% fracture, 50% no finding to avoid confusion -> however this is not how the model might be used in future so might not be a valid approach. perhaps it needs a higher weighting of the no-finding to achieve something similar but still training it to distinguish between fracture and other diseases. \n",
    "\n",
    "## 5th Architecture\n",
    "To avoid the overfitting, we reduce the number of trainable layers, so the first 400 layers are untrainable. Results in a mere 575K parameters to train. Reached val accuracy of 57% and trainina accuracy of aroun 80%. \n",
    "\n",
    "## 6th Architecture\n",
    "Changing the target column to be Enlarged Cardiomediastinum as that was found to be easier to detect in previous papers. Doing this also allowed us to increase the number of samples we use to 30K from 10K which should help a lot. Also increased untrainable layers to 420. This reduces trainable parameters to 200K.  If this doesn't work then we would also like to try data augementation I our next architecture to create more data, which will help the model generalise. Results were 80% training accuracy, 51% val accuracy. Therefore it's not working very well. \n",
    "\n",
    "## 7th Architecture\n",
    "Adding data augmentation. This changes the images slightly to increase the number of samples. Changes include slight rotations, slight translations. The images were also constrained to only include the PA angle, this reduced the number of samples to 20000. The training accuracy was 70% and val accuracy maxed out at 51%.\n",
    "\n",
    "## 8th\n",
    "same as 7th but using no finding as the negative case to avoid confusion with other diseases. Seemed very unstable but achieve max val acc of 56% and training acc of 66%. \n",
    "\n",
    "## 9th\n",
    "Tried freezing all the densenet layers. Reduced batch size to 16 to match the checxpert paper. 50k parameters. trainign 70% and val 50%.\n",
    "\n",
    "## 10th\n",
    "After reading: https://arxiv.org/pdf/1711.05225.pdf it turns out our original architecutre was much more similar to their papaer which ad some success. To more closely match theirs, i will change the disease to pneumonia, have all layers trainable and also set batch size to 16 to match their paper. They allow flipping of the image, which i think is invalid so will keep our data augmentation techniques. 7 million parameters. The batch size of 16 means we have a lot of backpropagations but it's much slower as a result. \n",
    "Achieved a training accuracy of 65% and validation accuracy of 72%, which is strange but we can see the val acc is very unstable so perhaps more reasonable to say around 70% if we take the average of the last few. \n",
    "\n",
    "## 11th\n",
    "Same as 10th, but to deal with the instability I increaed the epochs to 100. I will then repeat this architecture for different diseases and see what we get. \n",
    "\n",
    "## 12th \n",
    "11th was going to take 5 hours and we weres till seeing instability after 35 epochs so reduced to 20 epochs to help us understnd the instability. We also tried to run with batchsie 64 to reduce instability we had seen but gpu mem was too small for this so kept it at 16. Note pneumonia scored 76% val acc and 65% training acc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fe2530a9eb8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trnsfer learning model\n",
    "# put into separate cell as getting the dense net takes time \n",
    "# and we often only want to tweak the downstream architecutre \n",
    "denseNet = DenseNet121(input_shape=(224,224,3), include_top=True)\n",
    "denseNet.layers.pop() # remov elast layer which has 1000 class softmax in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50176)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            50177       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,087,681\n",
      "Trainable params: 7,004,033\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thebox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model2Layers = Flatten()(denseNet.layers[-2].output)\n",
    "model2Layers = Dropout(0.3)(model2Layers)\n",
    "model2Layers = Dense(1,activation='sigmoid')(model2Layers)\n",
    "model2 = Model(input=denseNet.layers[0].input, output=model2Layers)\n",
    "for i,layer in enumerate(model2.layers):\n",
    "    # Don't train the first layers to save mem and they wil be picking up low level features anyway. \n",
    "    if i < 428:\n",
    "        #layer.trainable=False\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "weightsFilePath2=\"weights2.best.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/937 [==============================] - 260s 278ms/step - loss: 1.4743 - acc: 0.5924 - val_loss: 1.5310 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to weights2.best.hdf5\n",
      "Epoch 2/20\n",
      "938/937 [==============================] - 247s 264ms/step - loss: 1.4736 - acc: 0.6165 - val_loss: 7.9553 - val_acc: 0.4908\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.50000\n",
      "Epoch 3/20\n",
      "938/937 [==============================] - 246s 263ms/step - loss: 1.2724 - acc: 0.6376 - val_loss: 0.8709 - val_acc: 0.5622\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50000 to 0.56220, saving model to weights2.best.hdf5\n",
      "Epoch 4/20\n",
      "938/937 [==============================] - 245s 262ms/step - loss: 1.1209 - acc: 0.6656 - val_loss: 4.1112 - val_acc: 0.5776\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.56220 to 0.57760, saving model to weights2.best.hdf5\n",
      "Epoch 5/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.1694 - acc: 0.6643 - val_loss: 0.9315 - val_acc: 0.5878\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.57760 to 0.58780, saving model to weights2.best.hdf5\n",
      "Epoch 6/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.1095 - acc: 0.6682 - val_loss: 1.1031 - val_acc: 0.7192\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.58780 to 0.71920, saving model to weights2.best.hdf5\n",
      "Epoch 7/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0799 - acc: 0.6830 - val_loss: 0.6779 - val_acc: 0.7446\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.71920 to 0.74460, saving model to weights2.best.hdf5\n",
      "Epoch 8/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0382 - acc: 0.6968 - val_loss: 0.4915 - val_acc: 0.7756\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.74460 to 0.77560, saving model to weights2.best.hdf5\n",
      "Epoch 9/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 0.9750 - acc: 0.7125 - val_loss: 0.4807 - val_acc: 0.7822\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.77560 to 0.78220, saving model to weights2.best.hdf5\n",
      "Epoch 10/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 0.9738 - acc: 0.7014 - val_loss: 0.5085 - val_acc: 0.7632\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78220\n",
      "Epoch 11/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 0.9907 - acc: 0.7008 - val_loss: 7.9552 - val_acc: 0.5002\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78220\n",
      "Epoch 12/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.1253 - acc: 0.6884 - val_loss: 0.5588 - val_acc: 0.7298\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78220\n",
      "Epoch 13/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.1125 - acc: 0.6860 - val_loss: 0.5157 - val_acc: 0.7620\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78220\n",
      "Epoch 14/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0389 - acc: 0.7064 - val_loss: 1.2213 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.78220\n",
      "Epoch 15/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0031 - acc: 0.7042 - val_loss: 0.5108 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78220\n",
      "Epoch 16/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0209 - acc: 0.7018 - val_loss: 0.5098 - val_acc: 0.7534\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78220\n",
      "Epoch 17/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0343 - acc: 0.7045 - val_loss: 0.4916 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78220\n",
      "Epoch 18/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0348 - acc: 0.7065 - val_loss: 0.4970 - val_acc: 0.7714\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.78220\n",
      "Epoch 19/20\n",
      "938/937 [==============================] - 244s 261ms/step - loss: 1.0273 - acc: 0.7064 - val_loss: 2.6122 - val_acc: 0.6164\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.78220\n",
      "Epoch 20/20\n",
      "938/937 [==============================] - 245s 261ms/step - loss: 1.0860 - acc: 0.6755 - val_loss: 0.5289 - val_acc: 0.7480\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.78220\n"
     ]
    }
   ],
   "source": [
    "checkpoint2 = ModelCheckpoint(weightsFilePath2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15)\n",
    "#numberimage_gen.fit(x_train3Channel, augment=True)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "#history2 = model2.fit(x_train3Channel,y_train, epochs = 10, batch_size=128,  validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "history2 = model2.fit_generator(image_gen.flow(x_train3Channel, y_train, batch_size=batch_size),steps_per_epoch=len(x_train3Channel) / batch_size,  epochs = epochs, validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "model2.load_weights(weightsFilePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the history of this model\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'])\n",
    "maxValAcc = max(history2.history['val_acc'])\n",
    "trainAcc = history2.history['acc'][history2.history['val_acc'].index(maxValAcc)]\n",
    "plt.savefig(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.png\")\n",
    "model2.save_weights(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.hdf5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-e031fb49d38f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-e031fb49d38f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    `ls`\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
