{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image     \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Accuracy is good but no better than guess all one class. Think this could be solved by addressing class imbalance\n",
    "- Accuracy is only good if we take the binary crossentropy and not the full label accuracy. Will need to speak to the lecturer about how to measure performance for this type of multilabel data. -> suggested splitting into sublabels and report average accuracy of models vs each of the different single label classification tasks. \n",
    "\n",
    "# TODO\n",
    "- Need to balance the classes before passing them into the model. I.e. we need to take in more data to get a 50 50 split between having a disease and not, then run through the model. This should be possible as currently we're only processing 1% of the data. 10% is without any disease so that;s 20k. We then use another 20k with a disease. \n",
    "- Also need to add the gender and age into the x train so the model can use this information as well as the image. \n",
    "- May want to pass the data into a high res image generator or use the high res images, which would require using the GPU servers\n",
    "- To allow a more complex model to learn quickly on the gpu servers, may want to try using transfer learning from an existing model\n",
    "\n",
    "# Done\n",
    "- Need to change all the unknowns into positives as evidenced by the success of u-ones model on this paper: https://arxiv.org/pdf/1901.07031.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('CheXpert-v1.0-small/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove anomalous dataline\n",
    "trainDf = trainDf[trainDf.Sex != 'Unknown']\n",
    "# Drop this column as it has many more classifications than lit suggests and shouldn't matter greatly for a CNN\n",
    "# TODO try with and without this column\n",
    "trainDf = trainDf.drop('AP/PA', 1)\n",
    "\n",
    "def pathToID(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[2][7:]\n",
    "\n",
    "def pathToStudy(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[3][5:]\n",
    "\n",
    "# Convert all labels to a series of one-hot encoded labels. \n",
    "# -1 is uncertain, 0 is negative, 1 is positive, nans are no mention of the disease in the text\n",
    "trainDf = trainDf.fillna(0)\n",
    "# N.B. this is replacing unknowns with true as per u-ones model here: https://arxiv.org/pdf/1901.07031.pdf\n",
    "# This is essentialyl saying that if we're not sure of disease we say they have it. \n",
    "# Just to be on the safeside and have better recall as we care more about recall than precision\n",
    "trainDf = trainDf.replace(-1,1) \n",
    "\n",
    "\n",
    "# Onehot encode the sex and the xray orientation\n",
    "trainDf = trainDf.replace('Male',1)\n",
    "trainDf = trainDf.replace('Female',0)\n",
    "trainDf = trainDf.replace('Frontal',1)\n",
    "trainDf = trainDf.replace('Lateral',0)\n",
    "\n",
    "trainDf =trainDf.rename(index=str, columns={\"Sex\": \"Male?\",'Frontal/Lateral' :'Frontal1/Lateral0'})\n",
    "\n",
    "\n",
    "#trainDf.insert(0,'Path', trainDf['Path'])\n",
    "trainDf['Study'] = trainDf.Path.apply(pathToStudy)\n",
    "trainDf['Patient ID'] = trainDf.Path.apply(pathToID)\n",
    "\n",
    "# Rearrange Columns\n",
    "cols = ['Patient ID', 'Study', 'Path', 'Age', 'Male?', 'Frontal1/Lateral0', 'No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "trainDf = trainDf[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f00dd60fd68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows age distribution of the data set. There are 3 0-olds and 7579 90 year olds. \n",
    "# Implies that over nineties were grouped together\n",
    "ages = trainDf['Age'].value_counts()\n",
    "plt.scatter(ages.keys(),ages.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f00db09fe80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender = trainDf['Male?'].value_counts()\n",
    "plt.scatter(gender.keys(),gender.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    201033\n",
      "1.0     22380\n",
      "Name: No Finding, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many people have no disease?\n",
    "no_finding = trainDf['No Finding'].value_counts()\n",
    "print(no_finding)\n",
    "\n",
    "# Plot pie chart to show how much of the data is labelled with each character\n",
    "values = no_finding.values\n",
    "labels = ['Disease present','All Clear']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Data Proportions', size=20)\n",
    "plt.pie(values, labels=labels, # explode=explode,\n",
    "        autopct='%1.1f%%', shadow=False, startangle=45)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Study</th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>Male?</th>\n",
       "      <th>Frontal1/Lateral0</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00006</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00007</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study1/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00007</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study2/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00008</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00008</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study2/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00011</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study1/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00011</td>\n",
       "      <td>5</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study5/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00011</td>\n",
       "      <td>7</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study7/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00011</td>\n",
       "      <td>4</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study4/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00011</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study2/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00011</td>\n",
       "      <td>10</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study10...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00011</td>\n",
       "      <td>9</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study9/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00011</td>\n",
       "      <td>11</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study11...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223384</th>\n",
       "      <td>64515</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64515/study1/...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223385</th>\n",
       "      <td>64516</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64516/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223386</th>\n",
       "      <td>64517</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64517/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223387</th>\n",
       "      <td>64518</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64518/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223388</th>\n",
       "      <td>64519</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64519/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223389</th>\n",
       "      <td>64520</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64520/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223390</th>\n",
       "      <td>64521</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64521/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223391</th>\n",
       "      <td>64522</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64522/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223392</th>\n",
       "      <td>64523</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64523/study1/...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223393</th>\n",
       "      <td>64524</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64524/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223394</th>\n",
       "      <td>64525</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64525/study1/...</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223395</th>\n",
       "      <td>64526</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64526/study1/...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223396</th>\n",
       "      <td>64527</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study2/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223397</th>\n",
       "      <td>64527</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study1/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223398</th>\n",
       "      <td>64528</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64528/study1/...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223399</th>\n",
       "      <td>64529</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64529/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223400</th>\n",
       "      <td>64530</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64530/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223401</th>\n",
       "      <td>64531</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64531/study1/...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223402</th>\n",
       "      <td>64532</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64532/study1/...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>64533</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223404</th>\n",
       "      <td>64533</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study2/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>64534</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223406</th>\n",
       "      <td>64535</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64535/study1/...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>64536</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223408</th>\n",
       "      <td>64536</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>64537</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>64537</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223411</th>\n",
       "      <td>64538</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64538/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223412</th>\n",
       "      <td>64539</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64539/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223413</th>\n",
       "      <td>64540</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64540/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223413 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient ID Study                                               Path  \\\n",
       "0           00001     1  CheXpert-v1.0-small/train/patient00001/study1/...   \n",
       "1           00002     2  CheXpert-v1.0-small/train/patient00002/study2/...   \n",
       "2           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "3           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "4           00003     1  CheXpert-v1.0-small/train/patient00003/study1/...   \n",
       "5           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "6           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "7           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "8           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "9           00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "10          00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "11          00006     1  CheXpert-v1.0-small/train/patient00006/study1/...   \n",
       "12          00007     1  CheXpert-v1.0-small/train/patient00007/study1/...   \n",
       "13          00007     2  CheXpert-v1.0-small/train/patient00007/study2/...   \n",
       "14          00008     1  CheXpert-v1.0-small/train/patient00008/study1/...   \n",
       "15          00008     2  CheXpert-v1.0-small/train/patient00008/study2/...   \n",
       "16          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "17          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "18          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "19          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "20          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "21          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "22          00011     1  CheXpert-v1.0-small/train/patient00011/study1/...   \n",
       "23          00011     5  CheXpert-v1.0-small/train/patient00011/study5/...   \n",
       "24          00011     7  CheXpert-v1.0-small/train/patient00011/study7/...   \n",
       "25          00011     4  CheXpert-v1.0-small/train/patient00011/study4/...   \n",
       "26          00011     2  CheXpert-v1.0-small/train/patient00011/study2/...   \n",
       "27          00011    10  CheXpert-v1.0-small/train/patient00011/study10...   \n",
       "28          00011     9  CheXpert-v1.0-small/train/patient00011/study9/...   \n",
       "29          00011    11  CheXpert-v1.0-small/train/patient00011/study11...   \n",
       "...           ...   ...                                                ...   \n",
       "223384      64515     1  CheXpert-v1.0-small/train/patient64515/study1/...   \n",
       "223385      64516     1  CheXpert-v1.0-small/train/patient64516/study1/...   \n",
       "223386      64517     1  CheXpert-v1.0-small/train/patient64517/study1/...   \n",
       "223387      64518     1  CheXpert-v1.0-small/train/patient64518/study1/...   \n",
       "223388      64519     1  CheXpert-v1.0-small/train/patient64519/study1/...   \n",
       "223389      64520     1  CheXpert-v1.0-small/train/patient64520/study1/...   \n",
       "223390      64521     1  CheXpert-v1.0-small/train/patient64521/study1/...   \n",
       "223391      64522     1  CheXpert-v1.0-small/train/patient64522/study1/...   \n",
       "223392      64523     1  CheXpert-v1.0-small/train/patient64523/study1/...   \n",
       "223393      64524     1  CheXpert-v1.0-small/train/patient64524/study1/...   \n",
       "223394      64525     1  CheXpert-v1.0-small/train/patient64525/study1/...   \n",
       "223395      64526     1  CheXpert-v1.0-small/train/patient64526/study1/...   \n",
       "223396      64527     2  CheXpert-v1.0-small/train/patient64527/study2/...   \n",
       "223397      64527     1  CheXpert-v1.0-small/train/patient64527/study1/...   \n",
       "223398      64528     1  CheXpert-v1.0-small/train/patient64528/study1/...   \n",
       "223399      64529     1  CheXpert-v1.0-small/train/patient64529/study1/...   \n",
       "223400      64530     1  CheXpert-v1.0-small/train/patient64530/study1/...   \n",
       "223401      64531     1  CheXpert-v1.0-small/train/patient64531/study1/...   \n",
       "223402      64532     1  CheXpert-v1.0-small/train/patient64532/study1/...   \n",
       "223403      64533     1  CheXpert-v1.0-small/train/patient64533/study1/...   \n",
       "223404      64533     2  CheXpert-v1.0-small/train/patient64533/study2/...   \n",
       "223405      64534     1  CheXpert-v1.0-small/train/patient64534/study1/...   \n",
       "223406      64535     1  CheXpert-v1.0-small/train/patient64535/study1/...   \n",
       "223407      64536     2  CheXpert-v1.0-small/train/patient64536/study2/...   \n",
       "223408      64536     1  CheXpert-v1.0-small/train/patient64536/study1/...   \n",
       "223409      64537     2  CheXpert-v1.0-small/train/patient64537/study2/...   \n",
       "223410      64537     1  CheXpert-v1.0-small/train/patient64537/study1/...   \n",
       "223411      64538     1  CheXpert-v1.0-small/train/patient64538/study1/...   \n",
       "223412      64539     1  CheXpert-v1.0-small/train/patient64539/study1/...   \n",
       "223413      64540     1  CheXpert-v1.0-small/train/patient64540/study1/...   \n",
       "\n",
       "        Age  Male?  Frontal1/Lateral0  No Finding  Enlarged Cardiomediastinum  \\\n",
       "0        68      0                  1         1.0                         0.0   \n",
       "1        87      0                  1         0.0                         0.0   \n",
       "2        83      0                  1         0.0                         0.0   \n",
       "3        83      0                  0         0.0                         0.0   \n",
       "4        41      1                  1         0.0                         0.0   \n",
       "5        20      0                  1         1.0                         0.0   \n",
       "6        20      0                  0         1.0                         0.0   \n",
       "7        33      1                  1         1.0                         0.0   \n",
       "8        33      1                  0         1.0                         0.0   \n",
       "9        33      1                  1         0.0                         0.0   \n",
       "10       33      1                  1         0.0                         0.0   \n",
       "11       42      0                  1         1.0                         0.0   \n",
       "12       69      1                  1         0.0                         0.0   \n",
       "13       69      1                  1         0.0                         1.0   \n",
       "14       81      1                  1         0.0                         0.0   \n",
       "15       81      1                  1         0.0                         0.0   \n",
       "16       76      1                  1         0.0                         0.0   \n",
       "17       76      1                  0         0.0                         0.0   \n",
       "18       50      0                  1         1.0                         0.0   \n",
       "19       50      0                  0         1.0                         0.0   \n",
       "20       22      0                  1         0.0                         0.0   \n",
       "21       22      0                  0         0.0                         0.0   \n",
       "22       19      0                  1         0.0                         0.0   \n",
       "23       19      0                  1         0.0                         0.0   \n",
       "24       19      0                  1         0.0                         0.0   \n",
       "25       19      0                  1         0.0                         0.0   \n",
       "26       19      0                  1         0.0                         0.0   \n",
       "27       19      0                  1         0.0                         0.0   \n",
       "28       19      0                  1         0.0                         1.0   \n",
       "29       19      0                  1         0.0                         0.0   \n",
       "...     ...    ...                ...         ...                         ...   \n",
       "223384   25      1                  1         1.0                         0.0   \n",
       "223385   75      0                  1         1.0                         0.0   \n",
       "223386   21      1                  1         1.0                         0.0   \n",
       "223387   68      1                  1         0.0                         0.0   \n",
       "223388   33      0                  1         1.0                         0.0   \n",
       "223389   65      0                  1         1.0                         0.0   \n",
       "223390   63      0                  1         0.0                         0.0   \n",
       "223391   21      0                  1         1.0                         0.0   \n",
       "223392   90      0                  1         0.0                         0.0   \n",
       "223393   61      0                  1         0.0                         0.0   \n",
       "223394   87      1                  1         0.0                         0.0   \n",
       "223395   55      1                  1         0.0                         0.0   \n",
       "223396   85      1                  1         0.0                         0.0   \n",
       "223397   85      1                  1         0.0                         0.0   \n",
       "223398   77      1                  1         0.0                         1.0   \n",
       "223399   81      1                  1         0.0                         0.0   \n",
       "223400   65      1                  1         0.0                         0.0   \n",
       "223401   57      0                  1         0.0                         0.0   \n",
       "223402   52      0                  1         1.0                         0.0   \n",
       "223403   75      1                  1         0.0                         0.0   \n",
       "223404   75      1                  1         0.0                         0.0   \n",
       "223405   63      1                  1         0.0                         0.0   \n",
       "223406   60      1                  1         0.0                         0.0   \n",
       "223407   61      0                  1         0.0                         0.0   \n",
       "223408   61      0                  1         0.0                         0.0   \n",
       "223409   59      1                  1         0.0                         0.0   \n",
       "223410   59      1                  1         0.0                         0.0   \n",
       "223411    0      0                  1         0.0                         0.0   \n",
       "223412    0      0                  1         0.0                         0.0   \n",
       "223413    0      0                  1         1.0                         0.0   \n",
       "\n",
       "        Cardiomegaly  Lung Opacity  Lung Lesion  Edema  Consolidation  \\\n",
       "0                0.0           0.0          0.0    0.0            0.0   \n",
       "1                1.0           1.0          0.0    1.0            1.0   \n",
       "2                0.0           1.0          0.0    0.0            1.0   \n",
       "3                0.0           1.0          0.0    0.0            1.0   \n",
       "4                0.0           0.0          0.0    1.0            0.0   \n",
       "5                0.0           0.0          0.0    0.0            0.0   \n",
       "6                0.0           0.0          0.0    0.0            0.0   \n",
       "7                0.0           0.0          0.0    0.0            0.0   \n",
       "8                0.0           0.0          0.0    0.0            0.0   \n",
       "9                0.0           0.0          0.0    0.0            0.0   \n",
       "10               0.0           0.0          0.0    0.0            0.0   \n",
       "11               0.0           0.0          0.0    0.0            0.0   \n",
       "12               1.0           1.0          0.0    0.0            0.0   \n",
       "13               0.0           1.0          0.0    0.0            0.0   \n",
       "14               0.0           1.0          0.0    0.0            0.0   \n",
       "15               0.0           1.0          0.0    0.0            0.0   \n",
       "16               1.0           0.0          0.0    0.0            0.0   \n",
       "17               1.0           0.0          0.0    0.0            0.0   \n",
       "18               0.0           0.0          0.0    0.0            0.0   \n",
       "19               0.0           0.0          0.0    0.0            0.0   \n",
       "20               0.0           0.0          0.0    0.0            0.0   \n",
       "21               0.0           0.0          0.0    0.0            0.0   \n",
       "22               0.0           1.0          0.0    0.0            1.0   \n",
       "23               0.0           1.0          0.0    0.0            0.0   \n",
       "24               0.0           1.0          0.0    0.0            0.0   \n",
       "25               0.0           1.0          0.0    0.0            0.0   \n",
       "26               0.0           1.0          0.0    0.0            1.0   \n",
       "27               0.0           1.0          0.0    1.0            0.0   \n",
       "28               0.0           1.0          0.0    0.0            0.0   \n",
       "29               0.0           1.0          0.0    1.0            0.0   \n",
       "...              ...           ...          ...    ...            ...   \n",
       "223384           0.0           0.0          0.0    0.0            0.0   \n",
       "223385           0.0           0.0          0.0    0.0            0.0   \n",
       "223386           0.0           0.0          0.0    0.0            0.0   \n",
       "223387           0.0           1.0          0.0    1.0            0.0   \n",
       "223388           0.0           0.0          0.0    0.0            0.0   \n",
       "223389           0.0           0.0          0.0    0.0            0.0   \n",
       "223390           0.0           1.0          0.0    0.0            0.0   \n",
       "223391           0.0           0.0          0.0    0.0            0.0   \n",
       "223392           0.0           0.0          0.0    0.0            1.0   \n",
       "223393           0.0           0.0          0.0    0.0            0.0   \n",
       "223394           0.0           1.0          0.0    0.0            0.0   \n",
       "223395           0.0           1.0          0.0    0.0            0.0   \n",
       "223396           1.0           0.0          0.0    1.0            0.0   \n",
       "223397           1.0           0.0          0.0    1.0            0.0   \n",
       "223398           0.0           0.0          0.0    0.0            0.0   \n",
       "223399           0.0           1.0          0.0    0.0            0.0   \n",
       "223400           0.0           0.0          0.0    1.0            0.0   \n",
       "223401           0.0           1.0          1.0    0.0            0.0   \n",
       "223402           0.0           0.0          0.0    0.0            0.0   \n",
       "223403           1.0           0.0          0.0    1.0            0.0   \n",
       "223404           0.0           0.0          0.0    0.0            1.0   \n",
       "223405           0.0           1.0          0.0    0.0            0.0   \n",
       "223406           0.0           1.0          0.0    0.0            1.0   \n",
       "223407           0.0           0.0          0.0    1.0            0.0   \n",
       "223408           0.0           0.0          0.0    1.0            0.0   \n",
       "223409           0.0           1.0          0.0    0.0            0.0   \n",
       "223410           0.0           1.0          0.0    0.0            0.0   \n",
       "223411           0.0           0.0          0.0    1.0            0.0   \n",
       "223412           1.0           1.0          0.0    0.0            0.0   \n",
       "223413           0.0           0.0          0.0    0.0            0.0   \n",
       "\n",
       "        Pneumonia  Atelectasis  Pneumothorax  Pleural Effusion  Pleural Other  \\\n",
       "0             0.0          0.0           0.0               0.0            0.0   \n",
       "1             0.0          1.0           0.0               1.0            0.0   \n",
       "2             0.0          0.0           0.0               0.0            0.0   \n",
       "3             0.0          0.0           0.0               0.0            0.0   \n",
       "4             0.0          0.0           0.0               0.0            0.0   \n",
       "5             0.0          0.0           0.0               0.0            0.0   \n",
       "6             0.0          0.0           0.0               0.0            0.0   \n",
       "7             0.0          0.0           0.0               0.0            0.0   \n",
       "8             0.0          0.0           0.0               0.0            0.0   \n",
       "9             0.0          0.0           1.0               0.0            0.0   \n",
       "10            0.0          0.0           1.0               0.0            0.0   \n",
       "11            0.0          0.0           0.0               0.0            0.0   \n",
       "12            0.0          1.0           1.0               0.0            0.0   \n",
       "13            0.0          1.0           0.0               0.0            0.0   \n",
       "14            0.0          0.0           0.0               1.0            0.0   \n",
       "15            0.0          0.0           0.0               1.0            0.0   \n",
       "16            0.0          1.0           0.0               0.0            0.0   \n",
       "17            0.0          1.0           0.0               0.0            0.0   \n",
       "18            0.0          0.0           0.0               0.0            0.0   \n",
       "19            0.0          0.0           0.0               0.0            0.0   \n",
       "20            0.0          0.0           0.0               0.0            0.0   \n",
       "21            0.0          0.0           0.0               0.0            0.0   \n",
       "22            0.0          0.0           1.0               1.0            0.0   \n",
       "23            0.0          0.0           1.0               0.0            0.0   \n",
       "24            0.0          0.0           0.0               0.0            0.0   \n",
       "25            0.0          1.0           1.0               1.0            0.0   \n",
       "26            0.0          0.0           0.0               1.0            0.0   \n",
       "27            0.0          0.0           0.0               1.0            0.0   \n",
       "28            0.0          0.0           0.0               1.0            0.0   \n",
       "29            0.0          0.0           0.0               1.0            0.0   \n",
       "...           ...          ...           ...               ...            ...   \n",
       "223384        0.0          0.0           0.0               0.0            0.0   \n",
       "223385        0.0          0.0           0.0               0.0            0.0   \n",
       "223386        0.0          0.0           0.0               0.0            0.0   \n",
       "223387        0.0          0.0           0.0               0.0            0.0   \n",
       "223388        0.0          0.0           0.0               0.0            0.0   \n",
       "223389        0.0          0.0           0.0               0.0            0.0   \n",
       "223390        0.0          0.0           0.0               0.0            0.0   \n",
       "223391        0.0          0.0           0.0               0.0            0.0   \n",
       "223392        0.0          0.0           0.0               0.0            0.0   \n",
       "223393        0.0          1.0           0.0               0.0            0.0   \n",
       "223394        0.0          0.0           0.0               1.0            0.0   \n",
       "223395        1.0          1.0           0.0               1.0            0.0   \n",
       "223396        0.0          0.0           0.0               1.0            0.0   \n",
       "223397        0.0          1.0           0.0               1.0            0.0   \n",
       "223398        0.0          0.0           0.0               1.0            0.0   \n",
       "223399        0.0          0.0           0.0               0.0            0.0   \n",
       "223400        0.0          0.0           0.0               0.0            0.0   \n",
       "223401        0.0          1.0           1.0               1.0            0.0   \n",
       "223402        0.0          0.0           0.0               0.0            0.0   \n",
       "223403        0.0          0.0           0.0               1.0            0.0   \n",
       "223404        0.0          1.0           0.0               0.0            0.0   \n",
       "223405        0.0          1.0           0.0               0.0            0.0   \n",
       "223406        0.0          1.0           0.0               0.0            0.0   \n",
       "223407        0.0          0.0           0.0               1.0            0.0   \n",
       "223408        0.0          1.0           0.0               0.0            0.0   \n",
       "223409        0.0          1.0           0.0               1.0            0.0   \n",
       "223410        0.0          1.0           0.0               1.0            0.0   \n",
       "223411        0.0          0.0           0.0               0.0            0.0   \n",
       "223412        1.0          1.0           0.0               0.0            0.0   \n",
       "223413        0.0          0.0           0.0               0.0            0.0   \n",
       "\n",
       "        Fracture  Support Devices  \n",
       "0            0.0              1.0  \n",
       "1            1.0              0.0  \n",
       "2            1.0              0.0  \n",
       "3            1.0              0.0  \n",
       "4            0.0              0.0  \n",
       "5            0.0              0.0  \n",
       "6            0.0              0.0  \n",
       "7            0.0              1.0  \n",
       "8            0.0              1.0  \n",
       "9            0.0              0.0  \n",
       "10           0.0              0.0  \n",
       "11           0.0              0.0  \n",
       "12           0.0              1.0  \n",
       "13           0.0              1.0  \n",
       "14           0.0              1.0  \n",
       "15           0.0              1.0  \n",
       "16           0.0              0.0  \n",
       "17           0.0              0.0  \n",
       "18           0.0              0.0  \n",
       "19           0.0              0.0  \n",
       "20           0.0              0.0  \n",
       "21           0.0              0.0  \n",
       "22           0.0              1.0  \n",
       "23           0.0              0.0  \n",
       "24           0.0              1.0  \n",
       "25           0.0              1.0  \n",
       "26           0.0              1.0  \n",
       "27           0.0              1.0  \n",
       "28           0.0              1.0  \n",
       "29           0.0              1.0  \n",
       "...          ...              ...  \n",
       "223384       0.0              0.0  \n",
       "223385       0.0              0.0  \n",
       "223386       0.0              1.0  \n",
       "223387       0.0              0.0  \n",
       "223388       0.0              1.0  \n",
       "223389       0.0              0.0  \n",
       "223390       1.0              0.0  \n",
       "223391       0.0              0.0  \n",
       "223392       0.0              0.0  \n",
       "223393       0.0              1.0  \n",
       "223394       0.0              0.0  \n",
       "223395       1.0              0.0  \n",
       "223396       0.0              1.0  \n",
       "223397       0.0              1.0  \n",
       "223398       0.0              0.0  \n",
       "223399       0.0              0.0  \n",
       "223400       0.0              1.0  \n",
       "223401       0.0              1.0  \n",
       "223402       0.0              1.0  \n",
       "223403       0.0              1.0  \n",
       "223404       0.0              0.0  \n",
       "223405       0.0              0.0  \n",
       "223406       0.0              0.0  \n",
       "223407       0.0              0.0  \n",
       "223408       0.0              1.0  \n",
       "223409       0.0              0.0  \n",
       "223410       0.0              0.0  \n",
       "223411       0.0              0.0  \n",
       "223412       0.0              0.0  \n",
       "223413       0.0              0.0  \n",
       "\n",
       "[223413 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (1, X, x) and return 3D tensor\n",
    "    return data.reshape(1,inputSize[0],inputSize[1])\n",
    "\n",
    "def paths_to_tensor(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)\n",
    "\n",
    "\n",
    "def path_to_tensor_channel_last_3colour(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (X, x, 3) and return 3D tensor\n",
    "    return np.stack((data,)*3, axis=-1)\n",
    "\n",
    "\n",
    "def paths_to_tensor_channel_last_3colour(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor_channel_last_3colour(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model will be targetting Fracture column\n"
     ]
    }
   ],
   "source": [
    "inputSize = (224,224)\n",
    "\n",
    "sample_size = 10000\n",
    "targetColumn = [18]\n",
    "colName = trainDf.columns.tolist()[targetColumn[0]]\n",
    "print(f\"This model will be targetting {colName} column\")\n",
    "\n",
    "\n",
    "# Create balanced dataset with 50% pos examples and 50% neg examples, only take frontal scans for now\n",
    "pos = trainDf[(trainDf[colName] == 1) & (trainDf['Frontal1/Lateral0'] == 1 )]\n",
    "neg = trainDf[(trainDf[colName] == 0) & (trainDf['Frontal1/Lateral0'] == 1 )]\n",
    "\n",
    "# Deleting training dataframe in order to save memory and avoid OOM errors. \n",
    "#del trainDf\n",
    "\n",
    "\n",
    "posSample = pos.sample(int(sample_size/2))\n",
    "negSample = neg.sample(int(sample_size/2))\n",
    "sample = pd.concat([posSample,negSample])\n",
    "\n",
    "\n",
    "x_train_paths, x_val_paths, y_train, y_val = train_test_split(sample.Path, sample[colName], stratify=sample[colName], random_state =2)\n",
    "\n",
    "\n",
    "# The 3 channel option is required for the denseNet and other transfer learning models\n",
    "# Single channel can be used on our models\n",
    "\n",
    "#x_train = paths_to_tensor(x_train_paths,inputSize)#.astype('float32')/255\n",
    "x_train3Channel = paths_to_tensor_channel_last_3colour(x_train_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_train = trainDf.iloc[:training_no,targetColumn] # to do all labels: trainDf.iloc[:training_no,8:]\n",
    "#x_val = paths_to_tensor(x_val_paths,inputSize)#.astype('float32')/255\n",
    "x_val3Channel = paths_to_tensor_channel_last_3colour(x_val_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_val = trainDf.iloc[training_no:training_no+val_no,targetColumn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(y_val))\\nprint(x_train[0].shape)\\nplt.imshow(x_train[0][0], interpolation='nearest')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(len(y_val))\n",
    "print(x_train[0].shape)\n",
    "plt.imshow(x_train[0][0], interpolation='nearest')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\\nmodel.add(Conv2D(32, (3,3)))\\nmodel.add(Conv2D(16, (3,3)))\\n\\nmodel.add(Flatten())\\n#model.add(Dropout(0.2))\\n#model.add(Dense(32,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n#model.add(Dense(16,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n\\n\\n\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\nmodel.summary()\\nweightsFilePath=\"weights.best.hdf5\"\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(32,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(16,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "weightsFilePath=\"weights.best.hdf5\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncheckpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\\n\\nhistory = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\\nmodel.load_weights(weightsFilePath)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "'''\n",
    "checkpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\n",
    "model.load_weights(weightsFilePath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAcc(predictions, truths):\n",
    "    wrongs = 0\n",
    "    for i,prediction in enumerate(predictions):\n",
    "        truth = truths[i]\n",
    "        for j, val in enumerate(prediction):\n",
    "            if val >= 0.5 and truth[j] == 0:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "            if val < 0.5 and truth[j] == 1:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "    total = 41*len(predictions) # len(predictions)\n",
    "    return (total - wrongs) / total, wrongs, total\n",
    "                \n",
    "            \n",
    "#checkAcc(predictions, y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these were tested on the fracture data with 10k samples. \n",
    "## 1st Architecture:\n",
    "Tried using densenet with untrainable layers straighinto 0.3 dropout and 1 unit sigmoid output layer\n",
    "It acheived training acc around 70% and val acc of 56% after 10 epochs but didn't seem to be clearly improving\n",
    "\n",
    "## 2nd architecture\n",
    " Tried an architecture with include_top = False and two layers of 128 units and 0.2 dropouts. \n",
    "however it never got past a training acc of around 0.5. This motivates me to increase the complexity of the model and train more of it. \n",
    "## 3rd Architecture\n",
    "Same as first, but now trying with densenet first 200 layers as untrainable but rest trainable and removing last layer so it has only one class sigmoid rather than 1000 class softmax. This hadn't been possible on my laptop efore due to memm issues but is possible on Johnny's server. By removing the last layer we reduce the number of params by 1million, but allowing trainability means the network takes longer to train as we have ~4million trainable parameters. Achieved 95% training accuracy but only 54% val accuracy. At least this means we're able to get a decent accuracy somewhere, we clearly just need to prevent overfitting. Can't increase much more than 10k dataset, so best to try other ways to prevent overfitting -> dropout layers, or reducing trainable params\n",
    "\n",
    "## 4th Architecture\n",
    "addition of dropout layer before the last dense layer and also set the untrainable to be the first 300 layers rather than 200. reduces trainable params to 2 million. This actually resulted in training accuracy reaching 98% within 4 epochs, which is a bit disappointing/confusing. val acc maxed out at 0.50240Perhaps the trainble layers require more dropout or perhaps i need to furhter reduce the trainable params.Perhaps the difficulty is that it is seeing one of the other diseases, that can look like a fracture, so perhaps the data should be weighted to be 50% fracture, 50% no finding to avoid confusion -> however this is not how the model might be used in future so might not be a valid approach. perhaps it needs a higher weighting of the no-finding to achieve something similar but still training it to distinguish between fracture and other diseases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7efeef7340f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trnsfer learning model\n",
    "# put into separate cell as getting the dense net takes time \n",
    "# and we often only want to tweak the downstream architecutre \n",
    "denseNet = DenseNet121(input_shape=(224,224,3), include_top=True)\n",
    "denseNet.layers.pop() # remov elast layer which has 1000 class softmax in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 50176)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50176)        0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            50177       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,087,681\n",
      "Trainable params: 2,939,585\n",
      "Non-trainable params: 4,148,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thebox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model2Layers = Flatten()(denseNet.layers[-2].output)\n",
    "model2Layers = Dropout(0.3)(model2Layers)\n",
    "model2Layers = Dense(1,activation='sigmoid')(model2Layers)\n",
    "model2 = Model(input=denseNet.layers[0].input, output=model2Layers)\n",
    "for i,layer in enumerate(model2.layers):\n",
    "    # Don't train the first layers to save mem and they wil be picking up low level features anyway. \n",
    "    if i < 300:\n",
    "        layer.trainable=False\n",
    "    else:\n",
    "        continue\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "weightsFilePath2=\"weights2.best.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 49s 7ms/step - loss: 1.4834 - acc: 0.5664 - val_loss: 7.9708 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to weights2.best.hdf5\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 37s 5ms/step - loss: 0.5046 - acc: 0.7796 - val_loss: 7.8798 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.50000\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.2920 - acc: 0.8764 - val_loss: 3.3988 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50000 to 0.50200, saving model to weights2.best.hdf5\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.1209 - acc: 0.9543 - val_loss: 2.7813 - val_acc: 0.5012\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.50200\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.0562 - acc: 0.9812 - val_loss: 3.0230 - val_acc: 0.5024\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.50200 to 0.50240, saving model to weights2.best.hdf5\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.0386 - acc: 0.9859 - val_loss: 3.4933 - val_acc: 0.4996\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.50240\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.0250 - acc: 0.9912 - val_loss: 3.1425 - val_acc: 0.4664\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.50240\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.0200 - acc: 0.9940 - val_loss: 3.3168 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50240\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.0086 - acc: 0.9984 - val_loss: 5.8754 - val_acc: 0.4888\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50240\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 39s 5ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 4.6699 - val_acc: 0.4884\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50240\n"
     ]
    }
   ],
   "source": [
    "checkpoint2 = ModelCheckpoint(weightsFilePath2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history2 = model2.fit(x_train3Channel,y_train, epochs = 10, batch_size=128,  validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "model2.load_weights(weightsFilePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcFdWd9/HPr3eanWYRaJpGRBGJAragYiKKMWiiuCWKouIaMzHJxCyDeZxMksfMmJk8MyZRkzFRwGUkLjExPi7Jo2RFZVFAWUVopGmQZqcbev89f1T15dJ00xfkdnXf+32/Xvd1q06dqv7dq5zfrXNOVZm7IyIiApARdQAiItJxKCmIiEiMkoKIiMQoKYiISIySgoiIxCgpiIhIjJKCpBwzKzYzN7OsBOrOMLO/tUdc7c3MPmlmq6OOQzoXJQWJlJmVmlmtmfVtVr4kbNiLo4nsoFi6mlmlmb0UdSxHwt3/6u4nRR2HdC5KCtIRrAemNa2Y2SeALtGFc4irgBrgQjMb2J5/OJGzHZFjSUlBOoLHgRvi1m8EHouvYGY9zewxM6swsw1mdo+ZZYTbMs3sx2a2zczWAZ9tYd9HzGyzmW0ys3vNLPMI4rsR+AWwDLiu2bGHmNlvwri2m9kDcdtuM7OVZrbXzFaY2biw3M3shLh6s83s3nB5kpmVmdk/mdkWYJaZ9TazF8O/sTNcLozbv4+ZzTKz8nD7b+OPFVdvkJk9Fx5nvZl9NW7beDNbZGZ7zOwjM/vPI/h+JIUoKUhH8CbQw8xODhvrq4EnmtX5GdATOB44lyCJ3BRuuw34HDAWKCH4ZR9vDlAPnBDWuRC4NZHAzKwImAQ8Gb5uiNuWCbwIbACKgcHA3HDb54HvhfV7AJcC2xP5m8BxQB9gKHA7wb/TWeF6EbAfeCCu/uNAPnAK0B/4rxY+Rwbwe2BpGOdk4B/N7DNhlZ8AP3H3HsBw4OkEY5VU4+566RXZCygFLgDuAf4NmAL8EcgCnKCxzSTovhkVt98XgT+Fy68Dd8RtuzDcNwsYEO7bJW77NGBeuDwD+Nth4rsHWBIuDwIagLHh+llABZDVwn6vAl9r5ZgOnBC3Phu4N1yeBNQCeYeJaQywM1weCDQCvVuoNwkoC5cnAB822343MCtc/gvwfaBv1P9P6BXtS/2V0lE8TtAwDaNZ1xHQF8gh+EXeZAPBL14IGuuNzbY1GQpkA5vNrKkso1n9w7kB+CWAu5eb2Z8JupPeAYYAG9y9voX9hgAfJPg3mqtw9+qmFTPLJ/j1PwXoHRZ3D89UhgA73H1nG8ccCgwys11xZZnAX8PlW4AfAKvMbD3wfXd/8Sjjl05M3UfSIbj7BoIB54uB3zTbvA2oI2jYmhQBm8LlzQSNY/y2JhsJzhT6unuv8NXD3U9pKyYzOxsYAdxtZlvCPv4JwLRwAHgjUNTKYPBGgm6Yluwj6O5pclyz7c1vXfwN4CRgggfdO59qCjH8O33MrFcbH2cjsD7uO+jl7t3d/WIAd3/f3acRdD/9CHjWzLq2cUxJQUoK0pHcApzv7lXxhe7eQNDH/UMz625mQ4G7ODDu8DTwVTMrNLPewMy4fTcDfwD+j5n1MLMMMxtuZucmEM+NBF1Zowi6bMYAowka9IuABQQJ6b5w2mqemU0M9/0V8E0zO90CJ4RxAywBrg0HyKcQjJEcTneCcYRdZtYH+Jdmn+9l4KFwQDrbzD7VwjEWAHvCAewu4d8ebWZnAJjZdDPr5+6NQNPZREMC35GkGCUF6TDc/QN3X9TK5q8AVcA64G/A/wCPhtt+SdCHvxR4m0PPNG4g6H5aAewEniXoi2+VmeUBXwB+5u5b4l7rCbq6bgyT1SUEA9gfAmUEg+S4+zPAD8M49wK/JRg8BvhauN8ugtlMvz1cLMD9BFN0txEMyr/SbPv1BGdSq4CtwD82P0BcrGMIzsi2ESSunmGVKcByM6skGHS+Jr4LS9KHueshOyIiEtCZgoiIxCgpiIhIjJKCiIjEKCmIiEhMp7t4rW/fvl5cXBx1GCIincrixYu3uXu/tup1uqRQXFzMokWtzVoUEZGWmNmGtmup+0hEROIoKYiISIySgoiIxHS6MYWW1NXVUVZWRnV1+lyVn5eXR2FhIdnZ2VGHIiIpJCWSQllZGd27d6e4uJi42yOnLHdn+/btlJWVMWzYsKjDEZEUkrTuIzN71My2mtl7rWw3M/upma01s2VNjyo8GtXV1RQUFKRFQgAwMwoKCtLqzEhE2kcyxxRmE9x5sTUXEdyrfgTBIwd//nH+WLokhCbp9nlFpH0krfvI3f9iZsWHqTIVeMyD27S+aWa9zGxgeH94EZF20dDo7Kutp6qmgaraevbVNFBZUx+U1Tawr6aeukYHdxxourG0N18Py5q4g+PNtgdlNDvOgfrxx/NYWVOFyScP4LQhbT1P6eOJckxhMAc/ErEsLDskKZjZ7QRnExQVFTXfHLnt27czefJkALZs2UJmZib9+gUXDi5YsICcnJw2j3HTTTcxc+ZMTjrppKTGKtKZuTv76xqoqmlgX2192HiHjXjYqFeFZVU1wXJVbVPdoIGvCrc17V9d1xj1x0pY/x55KZ0UWur/aPHhDu7+MPAwQElJSYd7AERBQQFLliwB4Hvf+x7dunXjm9/85kF1mh6KnZHRco/drFmzkh6nyLHi7tQ1ODX1DdTUN1JT30htfWOwXtcYlh1Yrm1oubxp/9r6lrftr2uI++UeNPqJPgImK8PomptF15xM8nOzYsu9u+bEyrrlZpGfk0nXnHB7bib5OcF7U1l+TibZmcG/W7Og4WrqvrVYWdic2YE6hPWa6gSbjfie36Z9D2w/sE9sezt3FUeZFMo4+Lm6hUB5RLEkxdq1a7nssss455xzeOutt3jxxRf5/ve/z9tvv83+/fu5+uqr+e53vwvAOeecwwMPPMDo0aPp27cvd9xxBy+//DL5+fn87ne/o3///hF/GumsGhudqtp69lY3verYW13PnvA9vqzpvaq2PmiY6xpbbvjrGxNunFtjBnlZmeRmZ5CblUFuVia5WRnkZB1Y79cti64FTY132Fg3NfRxDXlQFjTg3XKzyM/NJCczQ2NvRyHKpPACcKeZzSV4GPruYzGe8P3fL2dF+Z6PHVy8UYN68C+XtPmc9xatWLGCWbNm8Ytf/AKA++67jz59+lBfX895553HVVddxahRow7aZ/fu3Zx77rncd9993HXXXTz66KPMnDmzpcNLimtq0Pe00HC3VNZ8eU91HZU1bf+6zswwuudlBa/cbLqFv6ILuh5orIPG+9CGu3mjnpudQU5my+W5WZmxfbMyTI12B5S0pGBmTwGTgL5mVkbwsPFsAHf/BfAScDGwFtgH3JSsWKI0fPhwzjjjjNj6U089xSOPPEJ9fT3l5eWsWLHikKTQpUsXLrroIgBOP/10/vrXv7ZrzPLxuHusT7uyJhjArIz1b9fHliurg37uqpp6KsO+8Kqa+iNu0LNiDXp2rGEf0ief7nlZ9IgrO7A9O9x2YLlLdqYaaAGSO/toWhvbHfjysf67R/uLPlm6du0aW37//ff5yU9+woIFC+jVqxfTp09v8VqD+IHpzMxM6uvr2yXWdFbX0Bg20vWxwcpYgx3fiMca77iGPq7xb2rgE+1a6RbX/dEt7AIp6pPfYsPdvVkD37QtL1vdJHLspMQVzZ3Fnj176N69Oz169GDz5s28+uqrTJlyuEs5JJnWVVTy+qqtvL5qKwvW76C+se2WPCcz4+BGPDeLXvk5FPbOP6Q8WM6kW242XXMzY+VN7/nZmWRkqDGXjkVJoR2NGzeOUaNGMXr0aI4//ngmTpwYdUhppba+kYWlO3ht5Vbmrd7K+m1VAJw4oBs3TSxmYM8ucQ36wY1403JOlu4hKanN/ONOIWhnJSUl3vwhOytXruTkk0+OKKLopOvnPhLbKmuYtypIAn9Zs43KmnpysjI46/gCJp/cn/NO6s+QPvlRhymSdGa22N1L2qqnMwVJKe7O8vI9sW6hpWW7cIcBPXK55LSBnD9yABNPKCA/R//ri7RE/zKk09tXW8/f127n9VVbmbdqK1v2VGMGpxb24usXnMj5I/tzyqAeGowVSYCSgnRKG3fsY97q4Gxg/gfbqa1vpGtOJp86sR/nj+zPpJP60697btRhinQ6SgrSKdQ3NPLOxl3BIPGqraz+aC8AxQX5TJ8wlMkn9+eM4j4aCBb5mJQUpMPava+OP60JksCf1lSwa18dWRnGGcV9uOezJ3P+yP4c369b1GGKpBQlBekw3J21Wyt5LRwkXrxhJw2NTp+uOZw/sj+TRw7gkyf2pUeeHkEqkixKCsfApEmTuPvuu/nMZz4TK7v//vtZs2YNDz30UIv7dOvWjcrKyvYKscOqrmvgrfU7eH3lR7y+eisbd+wH4OSBPfjSucM5/+T+nFbYi0xd5CXSLpQUjoFp06Yxd+7cg5LC3Llz+Y//+I8Io+r4Fm/YyRcfX8y2yhrysjOYOLwvd5w7nPNO6s+gXl2iDk8kLSkpHANXXXUV99xzDzU1NeTm5lJaWkp5eTljxoxh8uTJ7Ny5k7q6Ou69916mTp0adbgdwu+XlvONZ5YyqGceP7qyhIkn9CUvOzPqsETSXuolhZdnwpZ3j+0xj/sEXHRfq5sLCgoYP348r7zyClOnTmXu3LlcffXVdOnSheeff54ePXqwbds2zjzzTC699NK0ni/v7jw4by0//sMaxhf34RfXn06frm0/mU5E2ofm7x0jTV1IEHQdTZs2DXfnO9/5DqeeeioXXHABmzZt4qOPPoo40ujU1jfyzWeW8eM/rOHysYN5/NbxSggiHUzqnSkc5hd9Ml122WXcddddsaeqjRs3jtmzZ1NRUcHixYvJzs6muLi4xVtlp4Nd+2q544nFvLluB/94wQi+NnlEWp8xiXRUqZcUItKtWzcmTZrEzTffzLRpwaMkdu/eTf/+/cnOzmbevHls2LAh4iijUbqtiptnL6Rs537uv3oMl40dHHVIItIKJYVjaNq0aVxxxRWxbqTrrruOSy65hJKSEsaMGcPIkSMjjrD9LSzdwe2PBXe1ffK2CZxR3CfiiETkcJQUjqHLL7+c+FuR9+3blzfeeKPFuulwjcLvlmziW88so7B3Fx6dcQbFfbu2vZOIREpJQY45d+cnr73P/f/vfc48vg+/mH46vfI1oCzSGSgpyDFVU9/AzOfe5fl3NnHluEL+7YpP6CZ1Ip1IyiQFd0+r2Swd8Yl5O6tq+eLji1lQuoNvXngiXz7vhLT6byKSClIiKeTl5bF9+3YKCgrSohFyd7Zv305eXl7UocSsq6jk5tkLKd9dzU+njeXS0wZFHZKIHIWUSAqFhYWUlZVRUVERdSjtJi8vj8LCwqjDAODNddu544nFZJjx1G0TOH2oZhiJdFYpkRSys7MZNmxY1GGkpecWlzHzN8so6pPPrBnjKSrIjzokEfkYUiIpSPtzd/7rj2v46etrOXt4AT+/7nR65us5ByKdnZKCHLHquga+/ewyXlhazhdKCrn3Ms0wEkkVSgpyRLZX1nD744tZvGEn355yEl86d3haDO6LpAslBUnY2q3BDKOP9lTz4LXj+OypA6MOSUSOsaSe85vZFDNbbWZrzWxmC9uHmtlrZrbMzP5kZh1jOo0cYv7abVzx0N/ZV1vP3NvPVEIQSVFJSwpmlgk8CFwEjAKmmdmoZtV+DDzm7qcCPwD+LVnxyNF7etFGbnh0AQN65PH8P0xkbFHvqEMSkSRJ5pnCeGCtu69z91pgLtD8WZSjgNfC5XktbJcINTY6//7KKr797DLOGl7Ac/9wNkP6aMqpSCpLZlIYDGyMWy8Ly+ItBa4Mly8HuptZQfMDmdntZrbIzBal0wVqUaqua+ArT73DQ3/6gGnji3h0xhn0yNOUU5FUl8yk0NKUlOY37PkmcK6ZvQOcC2wC6g/Zyf1hdy9x95J+/fod+0jlIBV7a7jm4Td56b3NfOfikfzr5aPJztSUU5F0kMzZR2XAkLj1QqA8voK7lwNXAJhZN+BKd9+dxJikDe9/tJebZi9kW2UNP7/udKaMPi7qkESkHSXz599CYISZDTOzHOAa4IX4CmbW18yaYrgbeDSJ8Ugb/vb+Nq54aD419Y38+vazlBBE0lDSkoK71wN3Aq8CK4Gn3X25mf3AzC4Nq00CVpvZGmAA8MNkxSOH99SCD7lx1gIG9+7Cb788kdOG9Io6JBGJgHXE+/IfTklJiS9atCjqMFJGY6Pzo1dW8d9/Wce5J/bjgWvH0l0DyiIpx8wWu3tJW/V0RXMa21/bwNd/vYRXlm9h+plFfO+SU8jSgLJIWlNSSFNb91Zz25xFLNu0m3/+3ChunlisexiJiJJCOvpoTzWf/8UbVOyt4eHrS/j0qAFRhyQiHYSSQprZWVXL9Y+8xbbKGp68bQLjdMsKEYmjpJBG9lbXceOsBZRu38fsm85QQhCRQ2hUMU1U1zVwy5xFrCjfw0PXjuPs4X2jDklEOiCdKaSB2vpGvvTEYhaW7uD+q8dwgcYQRKQVOlNIcQ2Nzl1PL2He6gp+eNknmDqm+T0JRUQOUFJIYe7O/3r+XV5ctpm7LxrJtROKog5JRDo4JYUU5e7860srmbtwI3eedwJfPHd41CGJSCegpJCifvb6Wn751/XceNZQvnHhiVGHIyKdhJJCCnr0b+v5zz+u4Ypxg/mXS07RlcoikjAlhRTz9KKN/ODFFXzmlAH8+5WnkpGhhCAiiVNSSCEvv7uZmc8t45Mj+vLTaWN1czsROWJqNVLEn9dU8NW57zC2qDf/ff3p5GZlRh2SiHRCSgopYGHpDr74+CJG9O/OozPOID9H1ySKyNFRUujk3tu0m5tnLWRQzy48dst4enbRA3JE5OgpKXRia7fu5YZHF9CjSzZP3DqBvt1yow5JRDo5JYVOauOOfUz/1QIyzHji1gkM6tUl6pBEJAUoKXRCW/dUM/2Rt9hXW8/jt4xnWN+uUYckIilCI5KdzK59tVz/yAIq9tbwxK0TOHlgj6hDEpEUoqTQiVTW1HPjrIWs317F7Bl6SI6IHHvqPuokqusauHXOQt7btJsHpo3l7BP0kBwROfaUFDqBuoZGvvzk27y1fgf/5/OnceEpx0UdkoikKCWFDq6h0fnG00t5bdVW/vfU0Vw2Vg/JEZHkUVLowNyde377Hi8sLeefpoxk+plDow5JRFKckkIH5e7c9/IqnlrwIf8waThfmqSH5IhI8ikpdFAPzlvLf/9lHdefOZRvfeakqMMRkTSR1KRgZlPMbLWZrTWzmS1sLzKzeWb2jpktM7OLkxlPZzFnfik//sMaLh87mO9fqofkiEj7SVpSMLNM4EHgImAUMM3MRjWrdg/wtLuPBa4BHkpWPJ3Fc4vL+JcXlvPpUQP4j6v0kBwRaV/JPFMYD6x193XuXgvMBaY2q+NA0yW5PYHyJMbT4b3y3ha+9exSJp5QwM/0kBwRiUAyW53BwMa49bKwLN73gOlmVga8BHylpQOZ2e1mtsjMFlVUVCQj1sj99f0KvvrUO4wZ0ouHry8hL1sPyRGR9pfMpNBSv4c3W58GzHb3QuBi4HEzOyQmd3/Y3UvcvaRfv35JCDVai0p3cPtjixnevxuzZoyna67uPiIi0UhmUigDhsStF3Jo99AtwNMA7v4GkAek1f0b3tu0m5tmL2Rgzzweu3k8PfP1kBwRiU4yk8JCYISZDTOzHIKB5Bea1fkQmAxgZicTJIXU7B9qwQcVldz46AK652bx+K0T6NddD8kRkWglLSm4ez1wJ/AqsJJgltFyM/uBmV0aVvsGcJuZLQWeAma4e/MuppRUtnMf03/1FmbwxK0TGKyH5IhIB9Bm57WZ3Qk86e47j/Tg7v4SwQByfNl345ZXABOP9Lid3da91Uz/1VtU1dQz9/azOL5ft6hDEhEBEjtTOA5YaGZPhxejaeL8x7BrXy03PLKArXtrmHXTeEYN0kNyRKTjaDMpuPs9wAjgEWAG8L6Z/auZ6WY8R+Gff7ecdRVVPHx9CacP1UNyRKRjSWhMIezn3xK+6oHewLNm9u9JjC3llO/az0vvbmbGxGLOGZFWk6xEpJNIZEzhq8CNwDbgV8C33L0uvJ7gfeDbyQ0xdTz51gYa3blet8AWkQ4qkauk+gJXuPuG+EJ3bzSzzyUnrNRTXdfAUws2csHJAxjSJz/qcEREWpRI99FLwI6mFTPrbmYTANx9ZbICSzW/X1rOjqpaZpxdHHUoIiKtSiQp/ByojFuvCsskQe7OnDdKGdG/G2cPL4g6HBGRViWSFCz+gjJ3bySxbicJvf3hTt7btIcbzy7WsxFEpENLJCmsM7Ovmll2+PoasC7ZgaWSWX8vpXteFpePbX6TWBGRjiWRpHAHcDawieAmdxOA25MZVCr5aE81r7y3hatLhujupyLS4bXZSrn7VoKb2clRePLNDTS4c8NZxVGHIiLSpkSuU8gjuMX1KQR3MQXA3W9OYlwpoaa+gf9Z8CHnn9SfogJNQxWRji+R7qPHCe5/9BngzwTPRdibzKBSxf9dtpltlbXMmFgcdSgiIglJJCmc4O7/DFS5+xzgs8AnkhtW5+fuzJ5fyvB+XTnnBN3SQkQ6h0SSQl34vsvMRgM9geKkRZQi3tm4i2VluzUNVUQ6lUSmwzxsZr2BewienNYN+OekRpUC5swvpXtuFleMK4w6FBGRhB02KYQ3vdsTPmDnL8Dx7RJVJ7d1TzUvvbuZ6WcOpZumoYpIJ3LY7qPw6uU72ymWlPHkWx9S16BpqCLS+SQypvBHM/ummQ0xsz5Nr6RH1knV1jfyPws+5LyT+jGsb9eowxEROSKJ9G00XY/w5bgyR11JLXr5vc1U7K3hRt0NVUQ6oUSuaB7WHoGkill/L2VY3658akS/qEMRETliiVzRfENL5e7+2LEPp3NbunEXSzbu4nuXjCIjQ9NQRaTzSaT76Iy45TxgMvA2oKTQzJz5pXTNyeTK0zUNVUQ6p0S6j74Sv25mPQlufSFxKvbW8Ptl5Vw7vojuedlRhyMiclQSmX3U3D5gxLEOpLN7akE4DVUDzCLSiSUypvB7gtlGECSRUcDTyQyqs6lraOSJNzfwqRP7Mbxft6jDERE5aomMKfw4brke2ODuZUmKp1N6+b0tbN1bw31XDo06FBGRjyWRpPAhsNndqwHMrIuZFbt7aVIj60TmzC9laEE+k07sH3UoIiIfSyJjCs8AjXHrDWFZm8xsipmtNrO1Zjazhe3/ZWZLwtcaM9uVWNgdx7tlu1m8YSc3nFWsaagi0uklcqaQ5e61TSvuXmtmOW3tZGaZwIPApwme7bzQzF5w9xVxx/p6XP2vAGOPJPiOYPb8UvJzMvl8iaahikjnl8iZQoWZXdq0YmZTgW0J7DceWOvu68KkMheYepj604CnEjhuh7GtsobfLy3nynGF9NA0VBFJAYmcKdwBPGlmD4TrZUCLVzk3MxjYGLdeBkxoqaKZDQWGAa+3sv124HaAoqKiBP50+5i74ENqGxq58WwNMItIakjk4rUPgDPNrBtg7p7o85lb6mD3FsoArgGedfeGVmJ4GHgYoKSkpLVjtKtgGuqHfHJEX07o3z3qcEREjok2u4/M7F/NrJe7V7r7XjPrbWb3JnDsMmBI3HohUN5K3WvoZF1Hf1j+EVv2VHOjnpkgIikkkTGFi9w9NisofArbxQnstxAYYWbDwoHpawge53kQMzsJ6A28kVjIHcPs+esZ0qcL543UNFQRSR2JJIVMM8ttWjGzLkDuYeoD4O71BE9texVYCTzt7svN7AfxA9cEA8xz3b1DdAslYnn5bhaW7uTGs4rJ1DRUEUkhiQw0PwG8ZmazwvWbgDmJHNzdXwJealb23Wbr30vkWB3JnPmldMnO5PMlQ9quLCLSiSQy0PzvZrYMuIBg8PgVIG2n2+yoquW3S8q56vRCenbRNFQRSS2J3iV1C8FVzVcSPE9hZdIi6uDmLvyQ2vpGZuhuqCKSglo9UzCzEwkGh6cB24FfE0xJPa+dYutw6hsaeeKNDZw9vIATB2gaqoiknsOdKawiOCu4xN3PcfefEdz3KG39ccVHlO+u5kadJYhIijpcUriSoNtonpn90swm0/IFaWlj9vxSBvfqwgUnD4g6FBGRpGg1Kbj78+5+NTAS+BPwdWCAmf3czC5sp/g6jJWb9/DW+h3ccNZQTUMVkZTV5kCzu1e5+5Pu/jmCq5KXAIfcBjvVzZlfSl52BlefoWmoIpK6jugZze6+w93/293PT1ZAHdGufbX8dskmLh87mF75bd41XESk0zqipJCufr1wI9V1jRpgFpGUp6TQhoZG57E3NjBhWB9GHtcj6nBERJJKSaEN/2/lR2zatZ+bJhZHHYqISNIpKbRhzvxSBvXM0zRUEUkLSgqHsXrLXuZ/sJ3pZw0lK1NflYikPrV0hzHnjVJyszK45oyO8whQEZFkUlJoxe59dTz/9iamjhlEn66ahioi6UFJoRVPL9rI/roGTUMVkbSipNCChkbnsTdLGV/ch1MG9Yw6HBGRdqOk0IJ5q7ayccd+nSWISNpRUmjB7PmlDOyZx4WnaBqqiKQXJYVm1m7dy9/WbmP6mUPJ1jRUEUkzavWamTN/AzlZGVyju6GKSBpSUoizp7qO594u49LTBlHQLTfqcERE2p2SQpxnFpWxr7aBGRpgFpE0paQQamx0HnujlNOH9mb0YE1DFZH0pKQQ+tOarWzYvk9nCSKS1pQUQrPnb2BAj1ymjD4u6lBERCKjpAB8UFHJX9ZUcN0ETUMVkfSmFhB4bH4pOZkZTBuvu6GKSHpLalIwsylmttrM1prZzFbqfMHMVpjZcjP7n2TG05K91XU8u7iMz506kH7dNQ1VRNJbVrIObGaZwIPAp4EyYKGZveDuK+LqjADuBia6+04z65+seFrz7OIyqmp1N1QREUjumcJ4YK27r3P3WmAuMLVZnduAB919J4C7b01iPIcIpqFuYGxRL04b0qs9/7SISIeUzKQwGNgYt14WlsU7ETjRzP5uZm+a2ZSWDmRmt5vZIjNbVFFRccwC/Mv7FazfVqVZzyFLAAAMFUlEQVRpqCIioWQmBWuhzJutZwEjgEnANOBXZnbIT3Z3f9jdS9y9pF+/fscswNnzS+nXPZeLRg88ZscUEenMkpkUyoD4u8oVAuUt1Pmdu9e5+3pgNUGSSLr126r40+oKrptQRE6WJmGJiEByk8JCYISZDTOzHOAa4IVmdX4LnAdgZn0JupPWJTGmmMfeKCU707h2gqahiog0SVpScPd64E7gVWAl8LS7LzezH5jZpWG1V4HtZrYCmAd8y923JyumJpU19TyzqIyLPzGQ/t3zkv3nREQ6jaRNSQVw95eAl5qVfTdu2YG7wle7+c3bZVTW1GuAWUSkmbTrTG9sdObML+W0wp6MLeoddTgiIh1K2iWFv63dxgcVVbpYTUSkBWmXFObML6Vvtxw+e6qmoYqINJdWSWHD9ipeX72Va8cXkZuVGXU4IiIdTlolhcfe2ECmGdedOTTqUEREOqS0SQpVNfU8vWgjF31iIAN6aBqqiEhL0iYpPP/OJvZW1zPjbJ0liIi0Jm2SwimDenDbJ4cxTtNQRURaldSL1zqSsUW9dV2CiEgb0uZMQURE2qakICIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFKCiIiEpPUpGBmU8xstZmtNbOZLWyfYWYVZrYkfN2azHhEROTwspJ1YDPLBB4EPg2UAQvN7AV3X9Gs6q/d/c5kxSHNNDZCYx001AEOlhH3ygzfLXh1No2N4A3QWA+N4bs3xi03HL48Kxey8iAzJ3iPrWd3zu9D5CgkLSkA44G17r4OwMzmAlOB5kmhfWz/ALaujORPH8Ibgka5oQ4aag800g21B8obm603LcfK68P32qBha1puKj/omHFljfUJBmmQkXmYpJHRynY7sH7I9mavpu3eeKAhjzXc8Q12YyuNevw+iX6uo2FxSSL3QLKIvee1nlAOes9teZ+sXMgMt3XpDb2HJvGziBxeMpPCYGBj3HoZMKGFelea2aeANcDX3X1j8wpmdjtwO0BRUdHRRbPqRfjjd49u3yhkZAUNTEZ28Es1MwcyWyoLl7PzD15vWs5otm9mTnjs7AMNctOvZvcD694Qt5zI9saD1xPd3tgQJofM4D0jK0wYWXHlWZCREbccX69puWn/zIPrtVZ+yP4ZQeKsr4H66vA9frmF94baA+v7d7awb1O9miP7b3/cqXDaNTD6Kug+IDn/f4m0wtw9OQc2+zzwGXe/NVy/Hhjv7l+Jq1MAVLp7jZndAXzB3c8/3HFLSkp80aJFRx5QZQXs3Xzk+yWDZbTRgKu7IqU0Nh6cQJonlPrqA8s7N8C7z0D520ESG35+kCBOuhhy8qP+JNKJmdlidy9pq14yzxTKgCFx64VAeXwFd98et/pL4EdJi6Zbv+Al0t4yMiAjD7LzEqt/1j9AxRpYNheWPQ3P3QI53WHUpUGCGHpOcEyRJEhmUlgIjDCzYcAm4Brg2vgKZjbQ3Zt+vl8KdJBOf5GI9TsRJn8XzrsHNvw9SBDLfwdLnoQehXDq5+HUa6D/yKgjTX17P4KaPUDcBAyzcD0jbrmFd8toYVui+7eyLcm9CEnrPgIws4uB+4FM4FF3/6GZ/QBY5O4vmNm/ESSDemAH8CV3X3W4Yx5195FIZ1e7D1a/BMt+DWtfC8ZlBo45MP6gM+GPb9+OoOtu0ztQ/k6w3FG6nQE++59wxi1HtWui3UdJTQrJoKQgAlRuhXefDc4gNi8Nxh9OuABOuzoYf8juEnWEHV9NZfDdlb8Nm94O3neWHtheMAIGjYXB4yC/L+DBZIvm797Y+rZYncNtO8z+zctGXBjEcxSUFETSxdaVsHRuMEC9ZxPk9oBRU4MziKKzNf4AwSD+lvcOTgAVq4Gw/es55EACGDQOBo2BvJ6RhnysKSmIpJvGBij9Kyz9Nax8AWoroWcRnPqFIEH0HRF1hO2joR4qVsUlgHfgo+XBdToAXfsFDX8sAYxNi643JQWRdFZbBav+b3AGsW5e0EUx+PRgcHr0ldC1IOoIj43GRtixLkgA5e8ESWDLMqjbF2zP7Rn86h8cNv6DxkHPwrSc8q2kICKBvVuCrqWlv4aP3g0u1htxIZx6NZw4JfGpslFzh91lBwaAN70N5UugZnewPasLDDzt4G6gPser+yykpCAih9ryXnj9wzNQuSXoNz/l8uAMoujMaH9BuwcX8dXtD37p1+2HHesPHgeoqgjqZmTBgFMO7gbqNzK4cl9apKQgIq1rbID1fw66l1b+PmiEew0Nzh5OuwYKhh9av27/wQ123b5myy297w+6spqXHbRcdWCZltojg34nHZwABpzSec5wOgglBRFJTE1lkBiWzYV1fwYcehUFA7ZNjfeR3r8JgmmyOV2D6bHZXSA7fjm/2Xu4nJN/8LbuxwVdQrndj/nHTjcd4TYXItIZ5HaDMdOC157yYPxh87Lgl3h2ftyrtQa9qTFvVpaZHfUnk6OgpCAiB/QYBBO/FnUUEiENy4uISIySgoiIxCgpiIhIjJKCiIjEKCmIiEiMkoKIiMQoKYiISIySgoiIxHS621yYWQWw4Sh37wtsO4bhdHb6Pg6m7+MAfRcHS4XvY6i7t/ngiE6XFD4OM1uUyL0/0oW+j4Pp+zhA38XB0un7UPeRiIjEKCmIiEhMuiWFh6MOoIPR93EwfR8H6Ls4WNp8H2k1piAiIoeXbmcKIiJyGEoKIiISkzZJwcymmNlqM1trZjOjjicqZjbEzOaZ2UozW25meqIKYGaZZvaOmb0YdSxRM7NeZvasma0K/z85K+qYomJmXw//nbxnZk+ZWco/GDotkoKZZQIPAhcBo4BpZjYq2qgiUw98w91PBs4EvpzG30W8rwErow6ig/gJ8Iq7jwROI02/FzMbDHwVKHH30UAmcE20USVfWiQFYDyw1t3XuXstMBeYGnFMkXD3ze7+dri8l+Af/OBoo4qWmRUCnwV+FXUsUTOzHsCngEcA3L3W3XdFG1WksoAuZpYF5APlEceTdOmSFAYDG+PWy0jzhhDAzIqBscBb0UYSufuBbwONUQfSARwPVACzwu60X5lZ16iDioK7bwJ+DHwIbAZ2u/sfoo0q+dIlKVgLZWk9F9fMugHPAf/o7nuijicqZvY5YKu7L446lg4iCxgH/NzdxwJVQFqOwZlZb4IehWHAIKCrmU2PNqrkS5ekUAYMiVsvJA1OA1tjZtkECeFJd/9N1PFEbCJwqZmVEnQrnm9mT0QbUqTKgDJ3bzp7fJYgSaSjC4D17l7h7nXAb4CzI44p6dIlKSwERpjZMDPLIRgseiHimCJhZkbQX7zS3f8z6nii5u53u3uhuxcT/H/xurun/K/B1rj7FmCjmZ0UFk0GVkQYUpQ+BM40s/zw381k0mDQPSvqANqDu9eb2Z3AqwQzCB519+URhxWVicD1wLtmtiQs+467vxRhTNKxfAV4MvwBtQ64KeJ4IuHub5nZs8DbBLP23iENbneh21yIiEhMunQfiYhIApQUREQkRklBRERilBRERCRGSUFERGKUFESaMbMGM1sS9zpmV/SaWbGZvXesjidyrKXFdQoiR2i/u4+JOgiRKOhMQSRBZlZqZj8yswXh64SwfKiZvWZmy8L3orB8gJk9b2ZLw1fTLRIyzeyX4X36/2BmXSL7UCLNKCmIHKpLs+6jq+O27XH38cADBHdXJVx+zN1PBZ4EfhqW/xT4s7ufRnD/oKar6EcAD7r7KcAu4Mokfx6RhOmKZpFmzKzS3bu1UF4KnO/u68KbCm5x9wIz2wYMdPe6sHyzu/c1swqg0N1r4o5RDPzR3UeE6/8EZLv7vcn/ZCJt05mCyJHxVpZbq9OSmrjlBjS2Jx2IkoLIkbk67v2NcHk+Bx7TeB3wt3D5NeBLEHsGdI/2ClLkaOkXisihusTdQRaC5xU3TUvNNbO3CH5QTQvLvgo8ambfInhqWdNdRb8GPGxmtxCcEXyJ4AleIh2WxhREEhSOKZS4+7aoYxFJFnUfiYhIjM4UREQkRmcKIiISo6QgIiIxSgoiIhKjpCAiIjFKCiIiEvP/AT1rqT+CKWzCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the history of this model\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('Model Accuracies')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
