{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image     \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Accuracy is good but no better than guess all one class. Think this could be solved by addressing class imbalance\n",
    "- Accuracy is only good if we take the binary crossentropy and not the full label accuracy. Will need to speak to the lecturer about how to measure performance for this type of multilabel data. -> suggested splitting into sublabels and report average accuracy of models vs each of the different single label classification tasks. \n",
    "\n",
    "# TODO\n",
    "- Need to balance the classes before passing them into the model. I.e. we need to take in more data to get a 50 50 split between having a disease and not, then run through the model. This should be possible as currently we're only processing 1% of the data. 10% is without any disease so that;s 20k. We then use another 20k with a disease. \n",
    "- Also need to add the gender and age into the x train so the model can use this information as well as the image. \n",
    "- May want to pass the data into a high res image generator or use the high res images, which would require using the GPU servers\n",
    "- To allow a more complex model to learn quickly on the gpu servers, may want to try using transfer learning from an existing model\n",
    "\n",
    "# Done\n",
    "- Need to change all the unknowns into positives as evidenced by the success of u-ones model on this paper: https://arxiv.org/pdf/1901.07031.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('CheXpert-v1.0-small/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove anomalous dataline\n",
    "trainDf = trainDf[trainDf.Sex != 'Unknown']\n",
    "# Drop this column as it has many more classifications than lit suggests and shouldn't matter greatly for a CNN\n",
    "# TODO try with and without this column\n",
    "#trainDf = trainDf.drop('AP/PA', 1)\n",
    "\n",
    "def pathToID(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[2][7:]\n",
    "\n",
    "def pathToStudy(path):\n",
    "    pathList = path.split('/')\n",
    "    return pathList[3][5:]\n",
    "\n",
    "# Convert all labels to a series of one-hot encoded labels. \n",
    "# -1 is uncertain, 0 is negative, 1 is positive, nans are no mention of the disease in the text\n",
    "trainDf = trainDf.fillna(0)\n",
    "# N.B. this is replacing unknowns with true as per u-ones model here: https://arxiv.org/pdf/1901.07031.pdf\n",
    "# This is essentialyl saying that if we're not sure of disease we say they have it. \n",
    "# Just to be on the safeside and have better recall as we care more about recall than precision\n",
    "trainDf = trainDf.replace(-1,1) \n",
    "\n",
    "\n",
    "# Onehot encode the sex and the xray orientation\n",
    "trainDf = trainDf.replace('Male',1)\n",
    "trainDf = trainDf.replace('Female',0)\n",
    "trainDf = trainDf.replace('Frontal',1)\n",
    "trainDf = trainDf.replace('Lateral',0)\n",
    "\n",
    "trainDf =trainDf.rename(index=str, columns={\"Sex\": \"Male?\",'Frontal/Lateral' :'Frontal1/Lateral0'})\n",
    "\n",
    "\n",
    "#trainDf.insert(0,'Path', trainDf['Path'])\n",
    "trainDf['Study'] = trainDf.Path.apply(pathToStudy)\n",
    "trainDf['Patient ID'] = trainDf.Path.apply(pathToID)\n",
    "\n",
    "# Rearrange Columns\n",
    "cols = ['Patient ID', 'Study', 'Path', 'Age', 'Male?', 'Frontal1/Lateral0', 'AP/PA','No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "trainDf = trainDf[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f963f511208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows age distribution of the data set. There are 3 0-olds and 7579 90 year olds. \n",
    "# Implies that over nineties were grouped together\n",
    "ages = trainDf['Age'].value_counts()\n",
    "plt.scatter(ages.keys(),ages.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f963cfa5390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEjFJREFUeJzt3X+MXtV95/H3pzZk3R+JCR6iYENNVReVpt2FjAj9J6VNhQ2qwE3Jimgr3KxVq2yy2l9CAUWqV6FVk7VWSFQpLRUIE7UQlk3BahO5Fskuq1WcMohuMGm9zCYNDI5iZ43ZVLgJkO/+8ZypHibjmePxzDyM5/2SHs19vvfce89hxnzm3nvmuakqJEnq8UOj7oAkaeUwNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdVs76g4stg0bNtTmzZtH3Q1JWlGeeuqpb1fV2HztzrrQ2Lx5MxMTE6PuhiStKEm+0dPOy1OSpG6GhiSpm6EhSepmaEiSuhkakqRuZ93sKUlaDR59+kX27D/MkRMnuXD9Om7deinbL9+45Mc1NCRphXn06Re5/bPPcPLV1wF48cRJbv/sMwBLHhxenpKkFWbP/sP/GBjTTr76Onv2H17yYxsakrTCHDlx8rTqi8nQkKQV5sL1606rvpgMDUlaYW7deinrzlnzhtq6c9Zw69ZLl/zY3giXpBVm+ma3s6ckSV22X75xWUJiJi9PSZK6GRqSpG6GhiSpm6EhSeo2b2gkuS/J0SSHhmp3JPlKkr9O8pdJLmz1JLkryWRbf8XQNjuSPNdeO4bq707yTNvmriRp9bcnOdDaH0hy3uIOXZJ0unrONO4Hts2o7amqn6uqfwb8OfDbrX4tsKW9dgF3wyAAgN3Ae4Argd1DIXB3azu93fSxbgMer6otwOPtvSRphOYNjap6Ajg+o/b/ht7+CFBt+QbggRo4CKxP8k5gK3Cgqo5X1UvAAWBbW/fWqvpSVRXwALB9aF972/LeobokaUQW/HcaSX4XuBl4GfjFVt4IvDDUbKrV5qpPzVIHeEdVfROgqr6Z5IKF9lWStDgWfCO8qj5WVRcBfwJ8pJUzW9MF1E9Lkl1JJpJMHDt27HQ3lyR1WozZU38K/FpbngIuGlq3CTgyT33TLHWAb7XLV7SvR0/Vgaq6p6rGq2p8bGzsDIYiSZrLgkIjyZaht9cDf9uW9wE3t1lUVwEvt0tM+4FrkpzXboBfA+xv676T5Ko2a+pm4LGhfU3PstoxVJckjci89zSSPAhcDWxIMsVgFtR1SS4Fvg98A/it1vxzwHXAJPAK8CGAqjqe5A7gydbu41U1fXP9FgYztNYBn28vgE8ADyfZCTwPfGDBo5QkLYoMJi2dPcbHx2tiYmLU3ZCkFSXJU1U1Pl87/yJcktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdZs3NJLcl+RokkNDtT1J/jbJV5L8WZL1Q+tuTzKZ5HCSrUP1ba02meS2ofolSb6c5Lkkn0lybqu/pb2fbOs3L9agJUkL03OmcT+wbUbtAPCuqvo54H8DtwMkuQy4CfiZts0fJFmTZA3wKeBa4DLgg60twCeBO6tqC/ASsLPVdwIvVdVPAne2dpKkEZo3NKrqCeD4jNpfVtVr7e1BYFNbvgF4qKq+W1VfByaBK9trsqq+VlXfAx4CbkgS4JeAR9r2e4HtQ/va25YfAd7X2kuSRmQx7mn8S+DzbXkj8MLQuqlWO1X9fODEUABN19+wr7b+5dZekjQiZxQaST4GvAb8yXRplma1gPpc+5qtH7uSTCSZOHbs2NydliQt2IJDI8kO4FeAf1FV0/8znwIuGmq2CTgyR/3bwPoka2fU37Cvtv5tzLhMNq2q7qmq8aoaHxsbW+iQJEnzWFBoJNkGfBS4vqpeGVq1D7ipzXy6BNgC/BXwJLClzZQ6l8HN8n0tbL4I3Ni23wE8NrSvHW35RuALQ+EkSRqBtfM1SPIgcDWwIckUsJvBbKm3AAfavemDVfVbVfVskoeBrzK4bPXhqnq97ecjwH5gDXBfVT3bDvFR4KEkvwM8Ddzb6vcCn04yyeAM46ZFGK8k6QzkbPvlfXx8vCYmJkbdDUlaUZI8VVXj87XzL8IlSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSt3lDI8l9SY4mOTRU+0CSZ5N8P8n4jPa3J5lMcjjJ1qH6tlabTHLbUP2SJF9O8lySzyQ5t9Xf0t5PtvWbF2PAkqSF6znTuB/YNqN2CHg/8MRwMcllwE3Az7Rt/iDJmiRrgE8B1wKXAR9sbQE+CdxZVVuAl4Cdrb4TeKmqfhK4s7WTJI3QvKFRVU8Ax2fU/qaqDs/S/Abgoar6blV9HZgErmyvyar6WlV9D3gIuCFJgF8CHmnb7wW2D+1rb1t+BHhfay9JGpHFvqexEXhh6P1Uq52qfj5woqpem1F/w77a+pdbe0nSiCx2aMx2JlALqM+1rx88aLIryUSSiWPHjnV1VJJ0+hY7NKaAi4bebwKOzFH/NrA+ydoZ9Tfsq61/GzMuk02rqnuqaryqxsfGxhZpKJKkmRY7NPYBN7WZT5cAW4C/Ap4EtrSZUucyuFm+r6oK+CJwY9t+B/DY0L52tOUbgS+09pKkEVk7X4MkDwJXAxuSTAG7GfzG//vAGPAXSf66qrZW1bNJHga+CrwGfLiqXm/7+QiwH1gD3FdVz7ZDfBR4KMnvAE8D97b6vcCnk0y24920GAOWJC1czrZf3sfHx2tiYmLU3ZCkFSXJU1U1Pl87/yJcktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEnd5g2NJPclOZrk0FDt7UkOJHmufT2v1ZPkriSTSb6S5IqhbXa09s8l2TFUf3eSZ9o2dyXJXMeQJI1Oz5nG/cC2GbXbgMeragvweHsPcC2wpb12AXfDIACA3cB7gCuB3UMhcHdrO73dtnmOIUkakXlDo6qeAI7PKN8A7G3Le4HtQ/UHauAgsD7JO4GtwIGqOl5VLwEHgG1t3Vur6ktVVcADM/Y12zEkSSOy0Hsa76iqbwK0rxe0+kbghaF2U602V31qlvpcx/gBSXYlmUgycezYsQUOSZI0n8W+EZ5ZarWA+mmpqnuqaryqxsfGxk53c0lSp4WGxrfapSXa16OtPgVcNNRuE3BknvqmWepzHUOSNCILDY19wPQMqB3AY0P1m9ssqquAl9ulpf3ANUnOazfArwH2t3XfSXJVmzV184x9zXYMSdKIrJ2vQZIHgauBDUmmGMyC+gTwcJKdwPPAB1rzzwHXAZPAK8CHAKrqeJI7gCdbu49X1fTN9VsYzNBaB3y+vZjjGJKkEclg0tLZY3x8vCYmJkbdDUlaUZI8VVXj87XzL8IlSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1G3tqDvwZvPo0y+yZ/9hjpw4yYXr13Hr1kvZfvnGUXdLkt4UDI0hjz79Ird/9hlOvvo6AC+eOMntn30GwOCQJLw89QZ79h/+x8CYdvLV19mz//CIeiRJby5nFBpJ/k2SQ0meTfJvW+3tSQ4kea59Pa/Vk+SuJJNJvpLkiqH97Gjtn0uyY6j+7iTPtG3uSpIz6e98jpw4eVp1SVptFhwaSd4F/CZwJfBPgV9JsgW4DXi8qrYAj7f3ANcCW9prF3B328/bgd3Ae9q+dk8HTWuza2i7bQvtb48L1687rbokrTZncqbx08DBqnqlql4D/jvwq8ANwN7WZi+wvS3fADxQAweB9UneCWwFDlTV8ap6CTgAbGvr3lpVX6qqAh4Y2teSuHXrpaw7Z80bauvOWcOtWy9dysNK0opxJqFxCHhvkvOT/DBwHXAR8I6q+iZA+3pBa78ReGFo+6lWm6s+NUt9yWy/fCO/9/6fZeP6dQTYuH4dv/f+n/UmuCQ1C549VVV/k+STDM4M/h74X8Brc2wy2/2IWkD9B3ec7GJwGYuLL754ji7Mb/vlGw0JSTqFM7oRXlX3VtUVVfVe4DjwHPCtdmmJ9vVoaz7F4Exk2ibgyDz1TbPUZ+vHPVU1XlXjY2NjZzIkSdIcznT21AXt68XA+4EHgX3A9AyoHcBjbXkfcHObRXUV8HK7fLUfuCbJee0G+DXA/rbuO0muarOmbh7alyRpBM70j/v+a5LzgVeBD1fVS0k+ATycZCfwPPCB1vZzDO57TAKvAB8CqKrjSe4AnmztPl5Vx9vyLcD9wDrg8+0lSRqRDCYmnT3Gx8drYmJi1N2QpBUlyVNVNT5fO/8iXJLU7aw700hyDPjGIuxqA/DtRdjPSrGaxruaxgqO92y3WOP98aqadybRWRcaiyXJRM+p2tliNY13NY0VHO/ZbrnH6+UpSVI3Q0OS1M3QOLV7Rt2BZbaaxruaxgqO92y3rOP1noYkqZtnGpKkbqs+NJJsS3K4PejptlnWvyXJZ9r6LyfZvPy9XBwdY/33Sb7aHpL1eJIfH0U/F8t84x1qd2OSSrKiZ9z0jDfJP2/f42eT/Oly93Exdfw8X5zki0mebj/T142in4shyX1JjiY5dIr1p3zI3aKrqlX7AtYA/wf4CeBcBp/Ue9mMNv8K+MO2fBPwmVH3ewnH+ovAD7flW1bqWHvH29r9GPAEcBAYH3W/l/j7uwV4Gjivvb9g1P1e4vHeA9zSli8D/m7U/T6D8b4XuAI4dIr11zH4mKUAVwFfXqq+rPYzjSuByar6WlV9D3iIwcOihg0/VOoR4H1L/djZJTLvWKvqi1X1Snt7kDd+yvBK0/O9BbgD+E/APyxn55ZAz3h/E/hUDR52RlUdZeXqGW8Bb23Lb+MUn5K9ElTVEww+SfxUTvWQu0W32kPjVA+AmrVNDZ5Q+DJw/rL0bnH1jHXYTlb2B0TOO94klwMXVdWfL2fHlkjP9/engJ9K8j+THEyypI9PXmI94/2PwK8nmWLwgan/enm6NhKn++97wc70U25Xup4HPXU/DOpN7nQeavXrwDjwC0vao6U153iT/BBwJ/Aby9WhJdbz/V3L4BLV1QzOIv9HkndV1Ykl7ttS6BnvB4H7q+o/J/l54NNtvN9f+u4tu2X7/9RqP9M41QOgZm2TZC2D09y5ThPfrHrGSpJfBj4GXF9V312mvi2F+cb7Y8C7gP+W5O8YXAfet4Jvhvf+LD9WVa9W1deBwwxCZCXqGe9O4GGAqvoS8E8YfE7T2ajr3/diWO2h8SSwJcklSc5lcKN734w2ww+VuhH4QrU7TyvMvGNtl2v+iEFgrOTr3TDPeKvq5araUFWbq2ozg3s411fVSv1c/Z6f5UcZTHYgyQYGl6u+tqy9XDw9430eeB9Akp9mEBrHlrWXy+dUD7lbdKv68lRVvZbkIwyeHrgGuK+qnk3ycWCiqvYB9zI4rZ1kcIZx0+h6vHCdY90D/CjwX9q9/uer6vqRdfoMdI73rNE53umnZH4VeB24tar+7+h6vXCd4/0PwB8n+XcMLtX8xgr9hY8kDzK4rLih3aPZDZwDUFV/yCkecrckfVmh/w0lSSOw2i9PSZJOg6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkbv8fjcGCoCESv/MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender = trainDf['Male?'].value_counts()\n",
    "plt.scatter(gender.keys(),gender.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    201033\n",
      "1.0     22380\n",
      "Name: No Finding, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many people have no disease?\n",
    "no_finding = trainDf['No Finding'].value_counts()\n",
    "print(no_finding)\n",
    "\n",
    "# Plot pie chart to show how much of the data is labelled with each character\n",
    "values = no_finding.values\n",
    "labels = ['Disease present','All Clear']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Data Proportions', size=20)\n",
    "plt.pie(values, labels=labels, # explode=explode,\n",
    "        autopct='%1.1f%%', shadow=False, startangle=45)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Study</th>\n",
       "      <th>Path</th>\n",
       "      <th>Age</th>\n",
       "      <th>Male?</th>\n",
       "      <th>Frontal1/Lateral0</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>...</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00004</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00004/study1/...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00005</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00005/study2/...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00006</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00006/study1/...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00007</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study1/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00007</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00007/study2/...</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00008</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00008</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00008/study2/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00009</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00009/study1/...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00010</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00010/study1/...</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00011</td>\n",
       "      <td>13</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study13...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00011</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study1/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00011</td>\n",
       "      <td>5</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study5/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00011</td>\n",
       "      <td>7</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study7/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00011</td>\n",
       "      <td>4</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study4/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00011</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study2/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00011</td>\n",
       "      <td>10</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study10...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00011</td>\n",
       "      <td>9</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study9/...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00011</td>\n",
       "      <td>11</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient00011/study11...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223384</th>\n",
       "      <td>64515</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64515/study1/...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223385</th>\n",
       "      <td>64516</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64516/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223386</th>\n",
       "      <td>64517</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64517/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223387</th>\n",
       "      <td>64518</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64518/study1/...</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223388</th>\n",
       "      <td>64519</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64519/study1/...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223389</th>\n",
       "      <td>64520</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64520/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223390</th>\n",
       "      <td>64521</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64521/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223391</th>\n",
       "      <td>64522</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64522/study1/...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223392</th>\n",
       "      <td>64523</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64523/study1/...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223393</th>\n",
       "      <td>64524</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64524/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223394</th>\n",
       "      <td>64525</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64525/study1/...</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223395</th>\n",
       "      <td>64526</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64526/study1/...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223396</th>\n",
       "      <td>64527</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study2/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223397</th>\n",
       "      <td>64527</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64527/study1/...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223398</th>\n",
       "      <td>64528</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64528/study1/...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223399</th>\n",
       "      <td>64529</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64529/study1/...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223400</th>\n",
       "      <td>64530</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64530/study1/...</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223401</th>\n",
       "      <td>64531</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64531/study1/...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223402</th>\n",
       "      <td>64532</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64532/study1/...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223403</th>\n",
       "      <td>64533</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study1/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223404</th>\n",
       "      <td>64533</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64533/study2/...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>64534</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64534/study1/...</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223406</th>\n",
       "      <td>64535</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64535/study1/...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223407</th>\n",
       "      <td>64536</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study2/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223408</th>\n",
       "      <td>64536</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64536/study1/...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223409</th>\n",
       "      <td>64537</td>\n",
       "      <td>2</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study2/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223410</th>\n",
       "      <td>64537</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64537/study1/...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223411</th>\n",
       "      <td>64538</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64538/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223412</th>\n",
       "      <td>64539</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64539/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223413</th>\n",
       "      <td>64540</td>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/train/patient64540/study1/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223413 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient ID Study                                               Path  \\\n",
       "0           00001     1  CheXpert-v1.0-small/train/patient00001/study1/...   \n",
       "1           00002     2  CheXpert-v1.0-small/train/patient00002/study2/...   \n",
       "2           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "3           00002     1  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "4           00003     1  CheXpert-v1.0-small/train/patient00003/study1/...   \n",
       "5           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "6           00004     1  CheXpert-v1.0-small/train/patient00004/study1/...   \n",
       "7           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "8           00005     1  CheXpert-v1.0-small/train/patient00005/study1/...   \n",
       "9           00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "10          00005     2  CheXpert-v1.0-small/train/patient00005/study2/...   \n",
       "11          00006     1  CheXpert-v1.0-small/train/patient00006/study1/...   \n",
       "12          00007     1  CheXpert-v1.0-small/train/patient00007/study1/...   \n",
       "13          00007     2  CheXpert-v1.0-small/train/patient00007/study2/...   \n",
       "14          00008     1  CheXpert-v1.0-small/train/patient00008/study1/...   \n",
       "15          00008     2  CheXpert-v1.0-small/train/patient00008/study2/...   \n",
       "16          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "17          00009     1  CheXpert-v1.0-small/train/patient00009/study1/...   \n",
       "18          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "19          00010     1  CheXpert-v1.0-small/train/patient00010/study1/...   \n",
       "20          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "21          00011    13  CheXpert-v1.0-small/train/patient00011/study13...   \n",
       "22          00011     1  CheXpert-v1.0-small/train/patient00011/study1/...   \n",
       "23          00011     5  CheXpert-v1.0-small/train/patient00011/study5/...   \n",
       "24          00011     7  CheXpert-v1.0-small/train/patient00011/study7/...   \n",
       "25          00011     4  CheXpert-v1.0-small/train/patient00011/study4/...   \n",
       "26          00011     2  CheXpert-v1.0-small/train/patient00011/study2/...   \n",
       "27          00011    10  CheXpert-v1.0-small/train/patient00011/study10...   \n",
       "28          00011     9  CheXpert-v1.0-small/train/patient00011/study9/...   \n",
       "29          00011    11  CheXpert-v1.0-small/train/patient00011/study11...   \n",
       "...           ...   ...                                                ...   \n",
       "223384      64515     1  CheXpert-v1.0-small/train/patient64515/study1/...   \n",
       "223385      64516     1  CheXpert-v1.0-small/train/patient64516/study1/...   \n",
       "223386      64517     1  CheXpert-v1.0-small/train/patient64517/study1/...   \n",
       "223387      64518     1  CheXpert-v1.0-small/train/patient64518/study1/...   \n",
       "223388      64519     1  CheXpert-v1.0-small/train/patient64519/study1/...   \n",
       "223389      64520     1  CheXpert-v1.0-small/train/patient64520/study1/...   \n",
       "223390      64521     1  CheXpert-v1.0-small/train/patient64521/study1/...   \n",
       "223391      64522     1  CheXpert-v1.0-small/train/patient64522/study1/...   \n",
       "223392      64523     1  CheXpert-v1.0-small/train/patient64523/study1/...   \n",
       "223393      64524     1  CheXpert-v1.0-small/train/patient64524/study1/...   \n",
       "223394      64525     1  CheXpert-v1.0-small/train/patient64525/study1/...   \n",
       "223395      64526     1  CheXpert-v1.0-small/train/patient64526/study1/...   \n",
       "223396      64527     2  CheXpert-v1.0-small/train/patient64527/study2/...   \n",
       "223397      64527     1  CheXpert-v1.0-small/train/patient64527/study1/...   \n",
       "223398      64528     1  CheXpert-v1.0-small/train/patient64528/study1/...   \n",
       "223399      64529     1  CheXpert-v1.0-small/train/patient64529/study1/...   \n",
       "223400      64530     1  CheXpert-v1.0-small/train/patient64530/study1/...   \n",
       "223401      64531     1  CheXpert-v1.0-small/train/patient64531/study1/...   \n",
       "223402      64532     1  CheXpert-v1.0-small/train/patient64532/study1/...   \n",
       "223403      64533     1  CheXpert-v1.0-small/train/patient64533/study1/...   \n",
       "223404      64533     2  CheXpert-v1.0-small/train/patient64533/study2/...   \n",
       "223405      64534     1  CheXpert-v1.0-small/train/patient64534/study1/...   \n",
       "223406      64535     1  CheXpert-v1.0-small/train/patient64535/study1/...   \n",
       "223407      64536     2  CheXpert-v1.0-small/train/patient64536/study2/...   \n",
       "223408      64536     1  CheXpert-v1.0-small/train/patient64536/study1/...   \n",
       "223409      64537     2  CheXpert-v1.0-small/train/patient64537/study2/...   \n",
       "223410      64537     1  CheXpert-v1.0-small/train/patient64537/study1/...   \n",
       "223411      64538     1  CheXpert-v1.0-small/train/patient64538/study1/...   \n",
       "223412      64539     1  CheXpert-v1.0-small/train/patient64539/study1/...   \n",
       "223413      64540     1  CheXpert-v1.0-small/train/patient64540/study1/...   \n",
       "\n",
       "        Age  Male?  Frontal1/Lateral0 AP/PA  No Finding  \\\n",
       "0        68      0                  1    AP         1.0   \n",
       "1        87      0                  1    AP         0.0   \n",
       "2        83      0                  1    AP         0.0   \n",
       "3        83      0                  0     0         0.0   \n",
       "4        41      1                  1    AP         0.0   \n",
       "5        20      0                  1    PA         1.0   \n",
       "6        20      0                  0     0         1.0   \n",
       "7        33      1                  1    PA         1.0   \n",
       "8        33      1                  0     0         1.0   \n",
       "9        33      1                  1    AP         0.0   \n",
       "10       33      1                  1    AP         0.0   \n",
       "11       42      0                  1    AP         1.0   \n",
       "12       69      1                  1    AP         0.0   \n",
       "13       69      1                  1    AP         0.0   \n",
       "14       81      1                  1    AP         0.0   \n",
       "15       81      1                  1    AP         0.0   \n",
       "16       76      1                  1    PA         0.0   \n",
       "17       76      1                  0     0         0.0   \n",
       "18       50      0                  1    PA         1.0   \n",
       "19       50      0                  0     0         1.0   \n",
       "20       22      0                  1    PA         0.0   \n",
       "21       22      0                  0     0         0.0   \n",
       "22       19      0                  1    AP         0.0   \n",
       "23       19      0                  1    AP         0.0   \n",
       "24       19      0                  1    AP         0.0   \n",
       "25       19      0                  1    AP         0.0   \n",
       "26       19      0                  1    AP         0.0   \n",
       "27       19      0                  1    AP         0.0   \n",
       "28       19      0                  1    AP         0.0   \n",
       "29       19      0                  1    AP         0.0   \n",
       "...     ...    ...                ...   ...         ...   \n",
       "223384   25      1                  1    AP         1.0   \n",
       "223385   75      0                  1    AP         1.0   \n",
       "223386   21      1                  1    AP         1.0   \n",
       "223387   68      1                  1    AP         0.0   \n",
       "223388   33      0                  1    AP         1.0   \n",
       "223389   65      0                  1    AP         1.0   \n",
       "223390   63      0                  1    AP         0.0   \n",
       "223391   21      0                  1    AP         1.0   \n",
       "223392   90      0                  1    AP         0.0   \n",
       "223393   61      0                  1    AP         0.0   \n",
       "223394   87      1                  1    AP         0.0   \n",
       "223395   55      1                  1    AP         0.0   \n",
       "223396   85      1                  1    AP         0.0   \n",
       "223397   85      1                  1    AP         0.0   \n",
       "223398   77      1                  1    AP         0.0   \n",
       "223399   81      1                  1    AP         0.0   \n",
       "223400   65      1                  1    AP         0.0   \n",
       "223401   57      0                  1    AP         0.0   \n",
       "223402   52      0                  1    AP         1.0   \n",
       "223403   75      1                  1    AP         0.0   \n",
       "223404   75      1                  1    AP         0.0   \n",
       "223405   63      1                  1    AP         0.0   \n",
       "223406   60      1                  1    AP         0.0   \n",
       "223407   61      0                  1    AP         0.0   \n",
       "223408   61      0                  1    AP         0.0   \n",
       "223409   59      1                  1    AP         0.0   \n",
       "223410   59      1                  1    AP         0.0   \n",
       "223411    0      0                  1    AP         0.0   \n",
       "223412    0      0                  1    AP         0.0   \n",
       "223413    0      0                  1    AP         1.0   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly       ...         \\\n",
       "0                              0.0           0.0       ...          \n",
       "1                              0.0           1.0       ...          \n",
       "2                              0.0           0.0       ...          \n",
       "3                              0.0           0.0       ...          \n",
       "4                              0.0           0.0       ...          \n",
       "5                              0.0           0.0       ...          \n",
       "6                              0.0           0.0       ...          \n",
       "7                              0.0           0.0       ...          \n",
       "8                              0.0           0.0       ...          \n",
       "9                              0.0           0.0       ...          \n",
       "10                             0.0           0.0       ...          \n",
       "11                             0.0           0.0       ...          \n",
       "12                             0.0           1.0       ...          \n",
       "13                             1.0           0.0       ...          \n",
       "14                             0.0           0.0       ...          \n",
       "15                             0.0           0.0       ...          \n",
       "16                             0.0           1.0       ...          \n",
       "17                             0.0           1.0       ...          \n",
       "18                             0.0           0.0       ...          \n",
       "19                             0.0           0.0       ...          \n",
       "20                             0.0           0.0       ...          \n",
       "21                             0.0           0.0       ...          \n",
       "22                             0.0           0.0       ...          \n",
       "23                             0.0           0.0       ...          \n",
       "24                             0.0           0.0       ...          \n",
       "25                             0.0           0.0       ...          \n",
       "26                             0.0           0.0       ...          \n",
       "27                             0.0           0.0       ...          \n",
       "28                             1.0           0.0       ...          \n",
       "29                             0.0           0.0       ...          \n",
       "...                            ...           ...       ...          \n",
       "223384                         0.0           0.0       ...          \n",
       "223385                         0.0           0.0       ...          \n",
       "223386                         0.0           0.0       ...          \n",
       "223387                         0.0           0.0       ...          \n",
       "223388                         0.0           0.0       ...          \n",
       "223389                         0.0           0.0       ...          \n",
       "223390                         0.0           0.0       ...          \n",
       "223391                         0.0           0.0       ...          \n",
       "223392                         0.0           0.0       ...          \n",
       "223393                         0.0           0.0       ...          \n",
       "223394                         0.0           0.0       ...          \n",
       "223395                         0.0           0.0       ...          \n",
       "223396                         0.0           1.0       ...          \n",
       "223397                         0.0           1.0       ...          \n",
       "223398                         1.0           0.0       ...          \n",
       "223399                         0.0           0.0       ...          \n",
       "223400                         0.0           0.0       ...          \n",
       "223401                         0.0           0.0       ...          \n",
       "223402                         0.0           0.0       ...          \n",
       "223403                         0.0           1.0       ...          \n",
       "223404                         0.0           0.0       ...          \n",
       "223405                         0.0           0.0       ...          \n",
       "223406                         0.0           0.0       ...          \n",
       "223407                         0.0           0.0       ...          \n",
       "223408                         0.0           0.0       ...          \n",
       "223409                         0.0           0.0       ...          \n",
       "223410                         0.0           0.0       ...          \n",
       "223411                         0.0           0.0       ...          \n",
       "223412                         0.0           1.0       ...          \n",
       "223413                         0.0           0.0       ...          \n",
       "\n",
       "        Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0               0.0    0.0            0.0        0.0          0.0   \n",
       "1               0.0    1.0            1.0        0.0          1.0   \n",
       "2               0.0    0.0            1.0        0.0          0.0   \n",
       "3               0.0    0.0            1.0        0.0          0.0   \n",
       "4               0.0    1.0            0.0        0.0          0.0   \n",
       "5               0.0    0.0            0.0        0.0          0.0   \n",
       "6               0.0    0.0            0.0        0.0          0.0   \n",
       "7               0.0    0.0            0.0        0.0          0.0   \n",
       "8               0.0    0.0            0.0        0.0          0.0   \n",
       "9               0.0    0.0            0.0        0.0          0.0   \n",
       "10              0.0    0.0            0.0        0.0          0.0   \n",
       "11              0.0    0.0            0.0        0.0          0.0   \n",
       "12              0.0    0.0            0.0        0.0          1.0   \n",
       "13              0.0    0.0            0.0        0.0          1.0   \n",
       "14              0.0    0.0            0.0        0.0          0.0   \n",
       "15              0.0    0.0            0.0        0.0          0.0   \n",
       "16              0.0    0.0            0.0        0.0          1.0   \n",
       "17              0.0    0.0            0.0        0.0          1.0   \n",
       "18              0.0    0.0            0.0        0.0          0.0   \n",
       "19              0.0    0.0            0.0        0.0          0.0   \n",
       "20              0.0    0.0            0.0        0.0          0.0   \n",
       "21              0.0    0.0            0.0        0.0          0.0   \n",
       "22              0.0    0.0            1.0        0.0          0.0   \n",
       "23              0.0    0.0            0.0        0.0          0.0   \n",
       "24              0.0    0.0            0.0        0.0          0.0   \n",
       "25              0.0    0.0            0.0        0.0          1.0   \n",
       "26              0.0    0.0            1.0        0.0          0.0   \n",
       "27              0.0    1.0            0.0        0.0          0.0   \n",
       "28              0.0    0.0            0.0        0.0          0.0   \n",
       "29              0.0    1.0            0.0        0.0          0.0   \n",
       "...             ...    ...            ...        ...          ...   \n",
       "223384          0.0    0.0            0.0        0.0          0.0   \n",
       "223385          0.0    0.0            0.0        0.0          0.0   \n",
       "223386          0.0    0.0            0.0        0.0          0.0   \n",
       "223387          0.0    1.0            0.0        0.0          0.0   \n",
       "223388          0.0    0.0            0.0        0.0          0.0   \n",
       "223389          0.0    0.0            0.0        0.0          0.0   \n",
       "223390          0.0    0.0            0.0        0.0          0.0   \n",
       "223391          0.0    0.0            0.0        0.0          0.0   \n",
       "223392          0.0    0.0            1.0        0.0          0.0   \n",
       "223393          0.0    0.0            0.0        0.0          1.0   \n",
       "223394          0.0    0.0            0.0        0.0          0.0   \n",
       "223395          0.0    0.0            0.0        1.0          1.0   \n",
       "223396          0.0    1.0            0.0        0.0          0.0   \n",
       "223397          0.0    1.0            0.0        0.0          1.0   \n",
       "223398          0.0    0.0            0.0        0.0          0.0   \n",
       "223399          0.0    0.0            0.0        0.0          0.0   \n",
       "223400          0.0    1.0            0.0        0.0          0.0   \n",
       "223401          1.0    0.0            0.0        0.0          1.0   \n",
       "223402          0.0    0.0            0.0        0.0          0.0   \n",
       "223403          0.0    1.0            0.0        0.0          0.0   \n",
       "223404          0.0    0.0            1.0        0.0          1.0   \n",
       "223405          0.0    0.0            0.0        0.0          1.0   \n",
       "223406          0.0    0.0            1.0        0.0          1.0   \n",
       "223407          0.0    1.0            0.0        0.0          0.0   \n",
       "223408          0.0    1.0            0.0        0.0          1.0   \n",
       "223409          0.0    0.0            0.0        0.0          1.0   \n",
       "223410          0.0    0.0            0.0        0.0          1.0   \n",
       "223411          0.0    1.0            0.0        0.0          0.0   \n",
       "223412          0.0    0.0            0.0        1.0          1.0   \n",
       "223413          0.0    0.0            0.0        0.0          0.0   \n",
       "\n",
       "        Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "0                0.0               0.0            0.0       0.0   \n",
       "1                0.0               1.0            0.0       1.0   \n",
       "2                0.0               0.0            0.0       1.0   \n",
       "3                0.0               0.0            0.0       1.0   \n",
       "4                0.0               0.0            0.0       0.0   \n",
       "5                0.0               0.0            0.0       0.0   \n",
       "6                0.0               0.0            0.0       0.0   \n",
       "7                0.0               0.0            0.0       0.0   \n",
       "8                0.0               0.0            0.0       0.0   \n",
       "9                1.0               0.0            0.0       0.0   \n",
       "10               1.0               0.0            0.0       0.0   \n",
       "11               0.0               0.0            0.0       0.0   \n",
       "12               1.0               0.0            0.0       0.0   \n",
       "13               0.0               0.0            0.0       0.0   \n",
       "14               0.0               1.0            0.0       0.0   \n",
       "15               0.0               1.0            0.0       0.0   \n",
       "16               0.0               0.0            0.0       0.0   \n",
       "17               0.0               0.0            0.0       0.0   \n",
       "18               0.0               0.0            0.0       0.0   \n",
       "19               0.0               0.0            0.0       0.0   \n",
       "20               0.0               0.0            0.0       0.0   \n",
       "21               0.0               0.0            0.0       0.0   \n",
       "22               1.0               1.0            0.0       0.0   \n",
       "23               1.0               0.0            0.0       0.0   \n",
       "24               0.0               0.0            0.0       0.0   \n",
       "25               1.0               1.0            0.0       0.0   \n",
       "26               0.0               1.0            0.0       0.0   \n",
       "27               0.0               1.0            0.0       0.0   \n",
       "28               0.0               1.0            0.0       0.0   \n",
       "29               0.0               1.0            0.0       0.0   \n",
       "...              ...               ...            ...       ...   \n",
       "223384           0.0               0.0            0.0       0.0   \n",
       "223385           0.0               0.0            0.0       0.0   \n",
       "223386           0.0               0.0            0.0       0.0   \n",
       "223387           0.0               0.0            0.0       0.0   \n",
       "223388           0.0               0.0            0.0       0.0   \n",
       "223389           0.0               0.0            0.0       0.0   \n",
       "223390           0.0               0.0            0.0       1.0   \n",
       "223391           0.0               0.0            0.0       0.0   \n",
       "223392           0.0               0.0            0.0       0.0   \n",
       "223393           0.0               0.0            0.0       0.0   \n",
       "223394           0.0               1.0            0.0       0.0   \n",
       "223395           0.0               1.0            0.0       1.0   \n",
       "223396           0.0               1.0            0.0       0.0   \n",
       "223397           0.0               1.0            0.0       0.0   \n",
       "223398           0.0               1.0            0.0       0.0   \n",
       "223399           0.0               0.0            0.0       0.0   \n",
       "223400           0.0               0.0            0.0       0.0   \n",
       "223401           1.0               1.0            0.0       0.0   \n",
       "223402           0.0               0.0            0.0       0.0   \n",
       "223403           0.0               1.0            0.0       0.0   \n",
       "223404           0.0               0.0            0.0       0.0   \n",
       "223405           0.0               0.0            0.0       0.0   \n",
       "223406           0.0               0.0            0.0       0.0   \n",
       "223407           0.0               1.0            0.0       0.0   \n",
       "223408           0.0               0.0            0.0       0.0   \n",
       "223409           0.0               1.0            0.0       0.0   \n",
       "223410           0.0               1.0            0.0       0.0   \n",
       "223411           0.0               0.0            0.0       0.0   \n",
       "223412           0.0               0.0            0.0       0.0   \n",
       "223413           0.0               0.0            0.0       0.0   \n",
       "\n",
       "        Support Devices  \n",
       "0                   1.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  \n",
       "6                   0.0  \n",
       "7                   1.0  \n",
       "8                   1.0  \n",
       "9                   0.0  \n",
       "10                  0.0  \n",
       "11                  0.0  \n",
       "12                  1.0  \n",
       "13                  1.0  \n",
       "14                  1.0  \n",
       "15                  1.0  \n",
       "16                  0.0  \n",
       "17                  0.0  \n",
       "18                  0.0  \n",
       "19                  0.0  \n",
       "20                  0.0  \n",
       "21                  0.0  \n",
       "22                  1.0  \n",
       "23                  0.0  \n",
       "24                  1.0  \n",
       "25                  1.0  \n",
       "26                  1.0  \n",
       "27                  1.0  \n",
       "28                  1.0  \n",
       "29                  1.0  \n",
       "...                 ...  \n",
       "223384              0.0  \n",
       "223385              0.0  \n",
       "223386              1.0  \n",
       "223387              0.0  \n",
       "223388              1.0  \n",
       "223389              0.0  \n",
       "223390              0.0  \n",
       "223391              0.0  \n",
       "223392              0.0  \n",
       "223393              1.0  \n",
       "223394              0.0  \n",
       "223395              0.0  \n",
       "223396              1.0  \n",
       "223397              1.0  \n",
       "223398              0.0  \n",
       "223399              0.0  \n",
       "223400              1.0  \n",
       "223401              1.0  \n",
       "223402              1.0  \n",
       "223403              1.0  \n",
       "223404              0.0  \n",
       "223405              0.0  \n",
       "223406              0.0  \n",
       "223407              0.0  \n",
       "223408              1.0  \n",
       "223409              0.0  \n",
       "223410              0.0  \n",
       "223411              0.0  \n",
       "223412              0.0  \n",
       "223413              0.0  \n",
       "\n",
       "[223413 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    return files\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (1, X, x) and return 3D tensor\n",
    "    return data.reshape(1,inputSize[0],inputSize[1])\n",
    "\n",
    "def paths_to_tensor(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)\n",
    "\n",
    "\n",
    "def path_to_tensor_channel_last_3colour(img_path,inputSize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, color_mode = \"grayscale\", target_size=inputSize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (x, x, 1)\n",
    "    x = image.img_to_array(img)\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    # convert 2D tensor to 3D tensor with shape (X, x, 3) and return 3D tensor\n",
    "    return np.stack((data,)*3, axis=-1)\n",
    "\n",
    "\n",
    "def paths_to_tensor_channel_last_3colour(img_paths, inputSize):\n",
    "    list_of_tensors = [path_to_tensor_channel_last_3colour(img_path, inputSize) for img_path in img_paths]\n",
    "    return np.array(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model will be targetting Pneumothorax column\n"
     ]
    }
   ],
   "source": [
    "inputSize = (224,224)\n",
    "\n",
    "sample_size =20000 # 30k is the memory limit for the server\n",
    "targetColumn = [16]\n",
    "colName = trainDf.columns.tolist()[targetColumn[0]]\n",
    "print(f\"This model will be targetting {colName} column\")\n",
    "\n",
    "\n",
    "# Create balanced dataset with 50% pos examples and 50% neg examples, only take scans from the front\n",
    "pos = trainDf[(trainDf[colName] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "neg = trainDf[(trainDf['No Finding'] == 1) & (trainDf['Frontal1/Lateral0'] == 1 ) & (trainDf['AP/PA'] == 'AP')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "posSample = pos.sample(int(sample_size/2))\n",
    "negSample = neg.sample(int(sample_size/2))\n",
    "sample = pd.concat([posSample,negSample])\n",
    "\n",
    "x_train_paths, x_val_paths, y_train, y_val = train_test_split(sample.Path, sample[colName], stratify=sample[colName], random_state =2)\n",
    "\n",
    "\n",
    "\n",
    "# The 3 channel option is required for the denseNet and other transfer learning models\n",
    "# Single channel can be used on our models\n",
    "\n",
    "#x_train = paths_to_tensor(x_train_paths,inputSize)#.astype('float32')/255\n",
    "x_train3Channel = paths_to_tensor_channel_last_3colour(x_train_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_train = trainDf.iloc[:training_no,targetColumn] # to do all labels: trainDf.iloc[:training_no,8:]\n",
    "#x_val = paths_to_tensor(x_val_paths,inputSize)#.astype('float32')/255\n",
    "x_val3Channel = paths_to_tensor_channel_last_3colour(x_val_paths,inputSize)#.astype('float32')/255\n",
    "\n",
    "#y_val = trainDf.iloc[training_no:training_no+val_no,targetColumn]\n",
    "\n",
    "# Deleting dataframes in order to save memory and avoid OOM errors. \n",
    "del trainDf\n",
    "del posSample\n",
    "del negSample\n",
    "del x_train_paths\n",
    "del x_val_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(y_val))\\nprint(x_train[0].shape)\\nplt.imshow(x_train[0][0], interpolation='nearest')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(len(y_val))\n",
    "print(x_train[0].shape)\n",
    "plt.imshow(x_train[0][0], interpolation='nearest')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel = Sequential()\\n\\nmodel.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\\nmodel.add(Conv2D(32, (3,3)))\\nmodel.add(Conv2D(16, (3,3)))\\n\\nmodel.add(Flatten())\\n#model.add(Dropout(0.2))\\n#model.add(Dense(32,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n#model.add(Dense(16,activation=\\'relu\\'))\\n#model.add(Dropout(0.2))\\n\\n\\n\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\nmodel.summary()\\nweightsFilePath=\"weights.best.hdf5\"\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), input_shape=(1,inputSize[0],inputSize[1])))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(32,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(16,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "weightsFilePath=\"weights.best.hdf5\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncheckpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\\n\\nhistory = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\\nmodel.load_weights(weightsFilePath)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLDMODEL\n",
    "'''\n",
    "checkpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(x_train,y_train, epochs = 10, batch_size=32,  validation_data=(x_val, y_val), callbacks=[checkpoint])\n",
    "model.load_weights(weightsFilePath)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAcc(predictions, truths):\n",
    "    wrongs = 0\n",
    "    for i,prediction in enumerate(predictions):\n",
    "        truth = truths[i]\n",
    "        for j, val in enumerate(prediction):\n",
    "            if val >= 0.5 and truth[j] == 0:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "            if val < 0.5 and truth[j] == 1:\n",
    "                wrongs += 1\n",
    "                # break\n",
    "    total = 41*len(predictions) # len(predictions)\n",
    "    return (total - wrongs) / total, wrongs, total\n",
    "                \n",
    "            \n",
    "#checkAcc(predictions, y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try:\n",
    "- Could try using class weighting to handle class imbalance rather than sampling data to have no class imbalance\n",
    "- Adding in the other data as an input to a fully connected layer. This would allow network to use gender and age in it's predictions.\n",
    "- Try using no finding for the neg samples rather than 0 for the column, that way we don't have it confuse diseases. \n",
    "\n",
    "\n",
    "All of these were tested on the fracture data with 10k samples. \n",
    "## 1st Architecture:\n",
    "Tried using densenet with untrainable layers straighinto 0.3 dropout and 1 unit sigmoid output layer\n",
    "It acheived training acc around 70% and val acc of 56% after 10 epochs but didn't seem to be clearly improving\n",
    "\n",
    "## 2nd architecture\n",
    " Tried an architecture with include_top = False and two layers of 128 units and 0.2 dropouts. \n",
    "however it never got past a training acc of around 0.5. This motivates me to increase the complexity of the model and train more of it. \n",
    "## 3rd Architecture\n",
    "Same as first, but now trying with densenet first 200 layers as untrainable but rest trainable and removing last layer so it has only one class sigmoid rather than 1000 class softmax. This hadn't been possible on my laptop efore due to memm issues but is possible on Johnny's server. By removing the last layer we reduce the number of params by 1million, but allowing trainability means the network takes longer to train as we have ~4million trainable parameters. Achieved 95% training accuracy but only 54% val accuracy. At least this means we're able to get a decent accuracy somewhere, we clearly just need to prevent overfitting. Can't increase much more than 10k dataset, so best to try other ways to prevent overfitting -> dropout layers, or reducing trainable params\n",
    "\n",
    "## 4th Architecture\n",
    "addition of dropout layer before the last dense layer and also set the untrainable to be the first 300 layers rather than 200. reduces trainable params to 2 million. This actually resulted in training accuracy reaching 98% within 4 epochs, which is a bit disappointing/confusing. val acc maxed out at 0.50240Perhaps the trainble layers require more dropout or perhaps i need to furhter reduce the trainable params.Perhaps the difficulty is that it is seeing one of the other diseases, that can look like a fracture, so perhaps the data should be weighted to be 50% fracture, 50% no finding to avoid confusion -> however this is not how the model might be used in future so might not be a valid approach. perhaps it needs a higher weighting of the no-finding to achieve something similar but still training it to distinguish between fracture and other diseases. \n",
    "\n",
    "## 5th Architecture\n",
    "To avoid the overfitting, we reduce the number of trainable layers, so the first 400 layers are untrainable. Results in a mere 575K parameters to train. Reached val accuracy of 57% and trainina accuracy of aroun 80%. \n",
    "\n",
    "## 6th Architecture\n",
    "Changing the target column to be Enlarged Cardiomediastinum as that was found to be easier to detect in previous papers. Doing this also allowed us to increase the number of samples we use to 30K from 10K which should help a lot. Also increased untrainable layers to 420. This reduces trainable parameters to 200K.  If this doesn't work then we would also like to try data augementation I our next architecture to create more data, which will help the model generalise. Results were 80% training accuracy, 51% val accuracy. Therefore it's not working very well. \n",
    "\n",
    "## 7th Architecture\n",
    "Adding data augmentation. This changes the images slightly to increase the number of samples. Changes include slight rotations, slight translations. The images were also constrained to only include the PA angle, this reduced the number of samples to 20000. The training accuracy was 70% and val accuracy maxed out at 51%.\n",
    "\n",
    "## 8th\n",
    "same as 7th but using no finding as the negative case to avoid confusion with other diseases. Seemed very unstable but achieve max val acc of 56% and training acc of 66%. \n",
    "\n",
    "## 9th\n",
    "Tried freezing all the densenet layers. Reduced batch size to 16 to match the checxpert paper. 50k parameters. trainign 70% and val 50%.\n",
    "\n",
    "## 10th\n",
    "After reading: https://arxiv.org/pdf/1711.05225.pdf it turns out our original architecutre was much more similar to their papaer which ad some success. To more closely match theirs, i will change the disease to pneumonia, have all layers trainable and also set batch size to 16 to match their paper. They allow flipping of the image, which i think is invalid so will keep our data augmentation techniques. 7 million parameters. The batch size of 16 means we have a lot of backpropagations but it's much slower as a result. \n",
    "Achieved a training accuracy of 65% and validation accuracy of 72%, which is strange but we can see the val acc is very unstable so perhaps more reasonable to say around 70% if we take the average of the last few. \n",
    "\n",
    "## 11th\n",
    "Same as 10th, but to deal with the instability I increaed the epochs to 100. I will then repeat this architecture for different diseases and see what we get. \n",
    "\n",
    "## 12th \n",
    "11th was going to take 5 hours and we weres till seeing instability after 35 epochs so reduced to 20 epochs to help us understnd the instability. We also tried to run with batchsie 64 to reduce instability we had seen but gpu mem was too small for this so kept it at 16. Note pneumonia scored 76% val acc and 65% training acc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7f92ec326eb8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trnsfer learning model\n",
    "# put into separate cell as getting the dense net takes time \n",
    "# and we often only want to tweak the downstream architecutre \n",
    "denseNet = DenseNet121(input_shape=(224,224,3), include_top=True)\n",
    "denseNet.layers.pop() # remov elast layer which has 1000 class softmax in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50176)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            50177       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,087,681\n",
      "Trainable params: 7,004,033\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thebox/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model2Layers = Flatten()(denseNet.layers[-2].output)\n",
    "model2Layers = Dropout(0.3)(model2Layers)\n",
    "model2Layers = Dense(1,activation='sigmoid')(model2Layers)\n",
    "model2 = Model(input=denseNet.layers[0].input, output=model2Layers)\n",
    "for i,layer in enumerate(model2.layers):\n",
    "    # Don't train the first layers to save mem and they wil be picking up low level features anyway. \n",
    "    if i < 428:\n",
    "        #layer.trainable=False\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "weightsFilePath2=\"weights2.best.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/937 [==============================] - 255s 271ms/step - loss: 1.5264 - acc: 0.5494 - val_loss: 7.4305 - val_acc: 0.5072\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50720, saving model to weights2.best.hdf5\n",
      "Epoch 2/20\n",
      "938/937 [==============================] - 234s 249ms/step - loss: 1.4165 - acc: 0.5530 - val_loss: 0.6395 - val_acc: 0.6576\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50720 to 0.65760, saving model to weights2.best.hdf5\n",
      "Epoch 3/20\n",
      "938/937 [==============================] - 233s 248ms/step - loss: 1.3129 - acc: 0.5601 - val_loss: 2.7189 - val_acc: 0.5656\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.65760\n",
      "Epoch 4/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2507 - acc: 0.5792 - val_loss: 0.7732 - val_acc: 0.6148\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.65760\n",
      "Epoch 5/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.1389 - acc: 0.5919 - val_loss: 0.6861 - val_acc: 0.5250\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.65760\n",
      "Epoch 6/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2289 - acc: 0.5745 - val_loss: 0.6615 - val_acc: 0.6180\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.65760\n",
      "Epoch 7/20\n",
      "938/937 [==============================] - 234s 249ms/step - loss: 1.1929 - acc: 0.5885 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.65760\n",
      "Epoch 8/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.3136 - acc: 0.5686 - val_loss: 0.6498 - val_acc: 0.6090\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.65760\n",
      "Epoch 9/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.1339 - acc: 0.6007 - val_loss: 0.6357 - val_acc: 0.6520\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.65760\n",
      "Epoch 10/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2620 - acc: 0.5844 - val_loss: 1.7054 - val_acc: 0.5770\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.65760\n",
      "Epoch 11/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2597 - acc: 0.5897 - val_loss: 0.7727 - val_acc: 0.6470\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.65760\n",
      "Epoch 12/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2131 - acc: 0.6097 - val_loss: 0.7005 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.65760\n",
      "Epoch 13/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.0976 - acc: 0.6229 - val_loss: 0.8856 - val_acc: 0.5658\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.65760\n",
      "Epoch 14/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2190 - acc: 0.5964 - val_loss: 1.5945 - val_acc: 0.6242\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.65760\n",
      "Epoch 15/20\n",
      "938/937 [==============================] - 233s 248ms/step - loss: 1.1802 - acc: 0.6090 - val_loss: 0.6113 - val_acc: 0.6686\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.65760 to 0.66860, saving model to weights2.best.hdf5\n",
      "Epoch 16/20\n",
      "938/937 [==============================] - 233s 248ms/step - loss: 1.1300 - acc: 0.6309 - val_loss: 0.6135 - val_acc: 0.6638\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.66860\n",
      "Epoch 17/20\n",
      "938/937 [==============================] - 233s 248ms/step - loss: 1.0923 - acc: 0.6489 - val_loss: 0.5968 - val_acc: 0.6850\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.66860 to 0.68500, saving model to weights2.best.hdf5\n",
      "Epoch 18/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.1250 - acc: 0.6365 - val_loss: 0.6360 - val_acc: 0.6338\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.68500\n",
      "Epoch 19/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2063 - acc: 0.5974 - val_loss: 0.6432 - val_acc: 0.6356\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.68500\n",
      "Epoch 20/20\n",
      "938/937 [==============================] - 233s 249ms/step - loss: 1.2100 - acc: 0.5900 - val_loss: 0.7076 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.68500\n"
     ]
    }
   ],
   "source": [
    "checkpoint2 = ModelCheckpoint(weightsFilePath2, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15)\n",
    "#numberimage_gen.fit(x_train3Channel, augment=True)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "#history2 = model2.fit(x_train3Channel,y_train, epochs = 10, batch_size=128,  validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "history2 = model2.fit_generator(image_gen.flow(x_train3Channel, y_train, batch_size=batch_size),steps_per_epoch=len(x_train3Channel) / batch_size,  epochs = epochs, validation_data=(x_val3Channel, y_val), callbacks=[checkpoint2])\n",
    "model2.load_weights(weightsFilePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4VFX6xz8njVASAim0BEJJCD1AQKqComBDRUFR1w7q6jbX3VVX3f25665tV90Vu2JbRUARVBAbAgIKAUJJIKEESEICaaT3nN8fZyYMwyRT70xCzud55pmZO+feeyaZmfeet3xfIaVEo9FoNBpX8fP1BDQajUbTttGGRKPRaDRuoQ2JRqPRaNxCGxKNRqPRuIU2JBqNRqNxC21INBqNRuMW2pBoNBqNxi20IdFoNBqNW2hDotFoNBq3CPD1BLxBRESEjI2N9fU0NBqNpk2xffv2AillpL1x7cKQxMbGkpyc7OtpaDQaTZtCCHHUkXHataXRaDQat9CGRKPRaDRuoQ2JRqPRaNyiXcRIbFFXV0d2djbV1dW+nopXCA4OJjo6msDAQF9PRaPRnGO0W0OSnZ1NSEgIsbGxCCF8PR1DkVJSWFhIdnY2/fv39/V0NBrNOUa7dW1VV1cTHh5+zhsRACEE4eHh7Wb1pdFovEu7NSRAuzAiZtrTe9VoNN6lXRsSjUajaZbyfNjxHuh25HbRhsRHFBYWkpiYSGJiIj179qRPnz5Nz2trax06xu233056errBM9Vo2iGNDbD8dlj1Kzi+w9ezafW022C7rwkPDyclJQWAv/71r3Tp0oUHH3zwjDFSSqSU+PnZtveLFy82fJ4aTbtk83/hyEb1OONr6DPWt/Np5egVSSvj4MGDDB8+nHvuuYcxY8aQm5vLwoULSUpKYtiwYTzxxBNNY6dMmUJKSgr19fWEhYXx0EMPMWrUKCZOnMjJkyd9+C40mjbM8RT4/u8w5EqIHg8H1vp6Rq0evSIB/u/zVNKOl3r0mEN7h/KXK4e5tG9aWhqLFy/m1VdfBeCpp56ie/fu1NfXM336dK677jqGDh16xj4lJSVccMEFPPXUUzzwwAO8/fbbPPTQQ26/D42mXVFbCZ8ugM4RcOV/IPktZVTKTkBID1/PrtWiVyStkIEDBzJu3Lim5x999BFjxoxhzJgx7Nu3j7S0tLP26dixI5deeikAY8eO5ciRI96arkZz7vDNY1CQAVe/Ap26Q9xMtf3gN76dVytHr0jA5ZWDUXTu3Lnp8YEDB3jxxRfZunUrYWFh3HzzzTbrQYKCgpoe+/v7U19f75W5ajTnDBlrYdubMPF+GDhdbes5AkJ6qddG3+zb+bVi9IqklVNaWkpISAihoaHk5uaydq3212o0Hqc8H1beBz2Gw0WPn94uBMRdDIfWQb1j2ZTtEUMNiRBilhAiXQhxUAhh02EvhJgnhEgTQqQKIT40bZsuhEixuFULIa42vfaOECLT4rVEI9+DrxkzZgxDhw5l+PDhLFiwgMmTJ/t6ShrNuYWUyohUl8K1b0JAhzNfj5sJtWVwbItv5tcGENKgYhshhD+QAVwMZAPbgPlSyjSLMXHAUuBCKWWxECJKSnnS6jjdgYNAtJSyUgjxDvCFlHK5o3NJSkqS1o2t9u3bx5AhQ1x7c22U9vieNRq7bHsTvvw9zHoaJtxz9us15fBMfxi/EGY+6f35+RAhxHYpZZK9cUauSMYDB6WUh6WUtcAS4CqrMQuARVLKYgBrI2LiOmCNlLLSwLlqNJr2SH4GrH0UBl4E591te0yHLtBvsoqTaGxipCHpA2RZPM82bbMkHogXQmwSQvwkhJhl4zg3AB9ZbXtSCLFbCPG8EKKDjX00Go2mZepr4dO7IKgTXP2yioc0R/xMKDwARYe9N782hJGGxNZ/xdqPFgDEAdOA+cCbQoiwpgMI0QsYAVheCjwMJADjgO7An2yeXIiFQohkIURyfn6+q+9Bo9Gcq6x7EnJ3wez/QkjPlsfGXaLuM742fl5tECMNSTYQY/E8GjhuY8xKKWWdlDITSEcZFjPzgBVSyjrzBillrlTUAItRLrSzkFK+LqVMklImRUZGeuDtaDSac4bMjbDpRRhzKyRcbn98+EAIH6Sr3JvBSEOyDYgTQvQXQgShXFSrrMZ8BkwHEEJEoFxdlmvH+Vi5tUyrFITSRb8a2GvI7DUazblJVTGsuAe6D4BZ/3R8v7iZcORHFXzXnIFhhkRKWQ/cj3JL7QOWSilThRBPCCFmm4atBQqFEGnAOuAPUspCACFELGpFs97q0P8TQuwB9gARwN+Neg8ajeYcQ0qVoVWeB9e+AUGd7e9jJv4SaKiFTOufJI2hdSRSytVSyngp5UAp5ZOmbY9LKVeZHksp5QNSyqFSyhFSyiUW+x6RUvaRUjZaHfNC09jhUsqbpZRt8vJg2rRpZxUXvvDCC/zyl79sdp8uXboYPS2N5txm91LY+wlMe9h5Rd++kyAoBA7oOIk1urLdR8yfP58lS5acsW3JkiXMnz/fRzPSaM5xio/C6geVQZjyO+f3DwiCgdPgwDe62ZUV2pD4iOuuu44vvviCmpoaAI4cOcLx48dJTEzkoosuYsyYMYwYMYKVK1f6eKYajY9IWwXPxcMnC9Tj2grXj9XYACtMdSJzXgM/f9eOEzcTSnPghA7NWqJFGwHWPAR5ezx7zJ4j4NKnmn05PDyc8ePH89VXX3HVVVexZMkSrr/+ejp27MiKFSsIDQ2loKCACRMmMHv2bN1zXdP+SH4L6mvg4LewZykEdIRBF8GQ2aquo2OY/WOY+fHfSuJkzhsQ1tf1OTWlAa9V33ENoFckPsXSvWV2a0kpeeSRRxg5ciQzZswgJyeHEydO+HimGo2XqSiAzA0w7i548ADc+jmM+QXk7IAVC+HZgfD+HEheDOV2mrhlb4d1/4Th18HIee7NK6QH9ErUcRIr9IoEWlw5GMnVV1/NAw88wI4dO6iqqmLMmDG888475Ofns337dgIDA4mNjbUpG6/RnNOkrQTZCMOuAf8A6H++us16WvVQ37dKubu++C188TvoO1F1NBxyxZkrjppyVb0e2hsu/5dn5hY/EzY8C5VFqmeJRq9IfEmXLl2YNm0ad9xxR1OQvaSkhKioKAIDA1m3bh1Hjx718Sw1Gh+QugIi4qGHVa8gPz+IToKLn4Bf74R7N8O0h6CmFNY+DC+MgNcugA3PmXS0HoaiTLjmVedcYS0RN1MZuYPfeuZ45wB6ReJj5s+fz5w5c5pcXDfddBNXXnklSUlJJCYmkpCQ4OMZajRepuwEHN0E5/+hZf0rIZSh6TFMGZPCQ7D/C9j3OXz/N3UDlaEVO8Vz8+s9GjpHqjiJu66ycwRtSHzMNddcg6WUf0REBFu22O57UF7eJktmNBrn2LfqtFvLGcIHwuTfqFvpcdj/JZRkwbRHPDs/Pz8YdDGkr4aGeuV6a+fov4BGo2ldpK6AyCEQ5UbvnNDeMH6B5+ZkTfwlsOtDyN4G/SYad542go6RaDSa1kNpLhzd7PxqxNsMvBD8ArSIo4l2bUiM6g7ZGmlP71XThklbCcjWb0iCu6pMMS0rD7RjQxIcHExhYWG7+IGVUlJYWEhwcLCvp6LRtEzqp9BjOETG+3om9om7BE6mwqks+2PPcdptjCQ6Oprs7GwMbXolG1UrLz/f2+vg4GCio6N9PQ2NpnlKsiHrZ7jwMV/PxDHiZ8I3j6nixHF3+no2PqXdGpLAwED69+9v7Ek+Xahy2O/6xtjzaDTnAqmfqfvW7tYyExEPYf20IaEdu7a8QkGGauXZ2ODrmWg0rZ/UFdBrlErjbQsIodxbh9dDXZWvZ+NTtCExkrIT0FADxUd8PRNNeyQ/HQ597+tZOEbxUchJbjurETPxM6G+SnVObMdoQ2IUjQ1QbhJbzE/37Vw07YtTWfDZL+HlCfDBtVBT5usZ2Setjbm1zMROUarEGe07DVgbEqOoLARpcmnl7/ftXDTtg4pCWPtn+O9Y2LMM+l+gEj7awoVM6groPQa6xfp6Js4R2BEGXKDqSdpBBmhzGGpIhBCzhBDpQoiDQoiHmhkzTwiRJoRIFUJ8aLG9QQiRYrqtstjeXwjxsxDigBDiYyFEkJHvwWXKck8/bgtfZM3Z1FUpqY3WTk05rH8W/pMIP70MI+bCr3acVrs9uc+387NH0WE4vrPtrUbMxF0Cp4616++5YVlbQgh/YBFwMZANbBNCrJJSplmMiQMeBiZLKYuFEFEWh6iSUibaOPTTwPNSyiVCiFeBO4FXjHofLlNmcmsFd4WC9vsBa9N8/Ziqa3jwgOsd9YykvhZ2vAvrn4GKk5BwBVz46GlpkcYGCAhu/Svipmytq307D1cxN7s6sBai2qfIqpErkvHAQSnlYSllLbAEuMpqzAJgkZSyGEBK2WKHGqHaBF4ILDdtehdonZ8+84okdqqSs25s9O18NM5RX6vcQ5WFUHjQ17M5k8ZG2L0MFo1TPcgj4uDOb+CG/52pT+Xnr1JUW/uKJPVTiB7nXudCXxIWA1HD2nWVu5GGpA9gWfKZbdpmSTwQL4TYJIT4SQgxy+K1YCFEsmm72ViEA6eklPUtHLN1YA609z8f6iqgNNu389E4x6HvofqUenx8p2/nYkZKOPANvHa+atYUFAI3LYfbvoSY8bb3iRrSulckBQdVm+thc3w9E5tU1zmYuh9/iWrlW3XK2Am1Uow0JLYaCVhHowKAOGAaMB94Uwhh7j7TV0qZBNwIvCCEGOjgMdXJhVhoMkTJhlavN0dZLnTsfrqvc36G9+egcZ29y6FjN5WRczzF17OBrG3wzhXwv+ugtgzmvAl3b4C4i1vu2RGZAKU5UF3ivbk6Q+oKdT/U2lnhe57/JoORf/2aj7cdsz84bqZKrjm8zviJtUKMNCTZQIzF82jAOnKZDayUUtZJKTOBdJRhQUp53HR/GPgBGA0UAGFCiIAWjolpv9ellElSyqTIyEjPvCNnKDsBIb3UFxla91Wh5kxqK1Qvi6FXqQuBXB8akvx0WHITvDVDxdouew7u2wYj5zomvWN2dbXWQHDqCiV+2LV1ORZWpuTw4ncHCO0YyJ8+2cMTn6dR39CCezp6HASHtVv3lpGGZBsQZ8qyCgJuAFZZjfkMmA4ghIhAuboOCyG6CSE6WGyfDKRJpbC4DrjOtP+twEoD34PrlOVCSA/V07lzpDYkbYn0NVBXCcOvg96JkLvbN+oEqZ+pWpDD62H6o/DrFNVjI8CJREXzhUxrjJPkpyvRw1aWrZWSdYo/Lt/N+NjubPzjdG6bFMvbmzK5491kSqrqbO/kHwCDZsDBb9plPNQwQ2KKY9wPrAX2AUullKlCiCeEELNNw9YChUKINJSB+IOUshAYAiQLIXaZtj9lke31J+ABIcRBVMzkLaPeg1uUm1YkoL7MrfWKUHM2ez+BkN7QbxL0SlQxLl8E3PcuV/P4zS644A/QoYvzxwjrB4GdWueFTOoKQMCQ2XaHeou8kmoWvpdMZEgHXrl5DB2D/Pnr7GH8c84INh8s4JqXN3E4v5lOpfEzoSK/9cTUvIihdSRSytVSyngp5UAp5ZOmbY9LKVeZHksp5QNSyqFSyhFSyiWm7ZtNz0eZ7t+yOOZhKeV4KeUgKeVcKWWNke/BJRoblSHp0kM9j4hXbol2XLDUZqgqVgHt4XNU1lPv0Wq7L34csrdD3wnQOdz1Y/j5td7MrdQV0G8yhPby9UwAqKptYMF7yVTU1PPWreMI79Kh6bX54/vywV3nUVxRy9WLNrHxgI2466AZIPxaT7Or/AxYeb/KQDQYXdluBJWF0Fh/5oqkuuR0Jpem9ZK2ChrrYPi16nlEvG8C7qXHoew4RCe5f6zWmLl1Ik3NqZXUjkgpeXD5LvYeL+HFG0YzuGfIWWMmDAhn1f1T6NW1I7ct3sa7m4+c2c+oU3cVK/G1XEptJXz3BLwyCfatgpNp9vdxE21IjMBcQxJiWpFEDlb3re3LrDmbvcuh+4DTKxH/AN8E3LOT1X0fDxiSyAT1mWxNqampK9TVeyvJ1vrPdwf5cncuf5qVwIyhPZodF9O9E5/8chLTB0fyl1WpPLJiL7X1FjGRuEvUZ6UszwuztkHGWnj5PNj4L3UxdH+yivMZjDYkRmBeeTStSMyGRKcAt2rK8iBzo5IYsUyp9UXAPScZ/AJPp4+7Q1PmViu5kJFSFSHGToEuUfbHG8zqPbk8/20Gc8b04e7zB9gd36VDAK//Iol7pw3ko63H+MVbP1NUYXIfxc9U9we83IOoJBs+vhk+nKfUDG79Aua85rW/rzYkRmBekZhjJF16KKmU1vJF1tgmdQUgVbaWJb4IuOfsUEYk0APtkVtb5taJvepv2QqKEPfmlPDA0hTG9A3jH9eMQLRUk2OBn5/gT7MSeP76UezMOsVVi34k40SZahMc2sd7cZKGOtj8X3hpvDJeFz0O92yC/lO9c34T2pAYgVlnK6SnuhdCZ261BfYsUz/e1v3Cza4Bb8VJGhtUcN8T8RGArjEQ2Ln1XMikrgDh7/NsrZOl1Sx4L5nunYJ47RdJBAc6r6d2zehoPl44geq6Rq5ZtInv9p9URaKHfjA+yH3sJ3jtAvj6UbW6u+9nmPp759LDPYQ2JEZgrmoPOJ31QeTg1vNF1pxN0WHI2X72agQgYrAp4O6lzK38/VBbDn3GeuZ4fn7q89caViRSwt5PlfS6O9loblJd18DC97dzqrKON25NIjKkg/2dmmF0326sun8y/SM7c9d7yaypHaXUB45t9uCMLagsUtlYb89UMj7XfwA3fuxTCX5tSIygLO/0asRMxGCoLFA9IzStj72fqHtztpYl3g64ezLQbiZqaOu4kMndBcWZPi1ClFLy0Ce7Sck6xfPXj2JY765uH7NX144su3sSl43oxQPbulIngqjf/5UHZmtBYyPseF/1m0n5ECb9Cu7bCkOubFkmxwtoQ2IE5TYMidlPrSXlWx9Swp7lSqojLMb2GG8G3HOSldyGJ3uXRyWoJJDKIs8d0xVSPwW/ACV57yNeWX+Iz1KO8+Al8cwa7rkalo5B/rw0fzT3XjySzfUJnNi+ipNl1Z45+IlUWHwprLpfpaTfsxEu+btrRaoGoA2JEZTlQRdrQ6JTgFstJ1LV/8XWasSMNwPuOTuUW8uTV5mRpswtX7q3pFTxkQHTVc2FD/g6NY9n16Yze1Rv7ps+yOPHF0Lw64viiBxzJX0acrjvv8sprW5GVsURaspVX5xXp0JBBsx+CW5fAz2GeW7SHsCwxlbtFnNVu/WKpGu0KeCpVyStjr3LVfC3JXeLZcDdfFFgBDXlqoAs4XLPHtfccCl/H8RO9uyxHSVnh+okeIHNZqmGsy+3lN9+nMLIPl155rqRDmdoucLQC+bCricZXvETq1KmcvOEfi3vUFetVJpPHYOSLDiVpVJ6M9er7aN/ATP+z6dxpZbQhsTTNFW1WxkSIVQ2kDYkrQspVXxk4HToHNH8OHPAPTcFRl1v3HxyU1SfdU/GR0ClpHYIhZM+XBGnfqpqYzxtJB2goLyGu95NJjQ4kNdvcS1Dyym690dGxHPFqT08kZzFzaNCTxuHkiyTwcg+bTQqrHv6CVWHFhEH172tpHJaMdqQeJpyU0WrtSEBFSc5vN6789G0TPY29aWe9kjL48wBd6Mzt5oC7WM8e1whfJs5KKVSMx50EXQMsz/eg9TUN3DP+9sprKhh2d2T6BHqgdocBxBxlzB6y8t8kH8dPF115osBwcpL0TVaFTGG9TU9j1FxutA+4B/olXl6Am1IPI1ZGsE6RgLqi7zrI6W7Fex+pojGA+xZpr7Ujlwl906Enf9TAXejerjnJKs0zpZWR64SmaAk8n1B9jbVJfSix716Wiklj67YS/LRYl66cTQjor34vUu6g7riHFakVtKrXzwXT0w6bSg6R/o808qT6GC7pylrYUUSYfKtFxzw3nw0zdNQr4K/cZdAcKj98d4IuGdv97xby0zUEFMKeoExx2+J1BXg3wEGX+rV0765MZNl27P5zUVxXDGyt1fPTfhAOtzwDlsG/4mHci+gdvBsiB6rZEvOISMC2pB4nqYViQ3hN5251bo4skH1jxgx17HxRle4e1Lx1xa+kkppbFRurbiLHTPYHmLjgXz+sWYfl43oyW8uivPaea2ZlxRDYUUt3++3joOcO2hD4mnK81Svb1saSd1i1VWZNiStgz2fqAB03CWOjbcMuBtBznZ1b+SKBLz/+cv6WRlILxYhllTW8eCyXQyK7MJzc0fh5+e7FcDUuAh6hHZgWXKWz+ZgNNqQeBpbNSRm/PxVFobO3PI9ddWqV0PCFY4LIzYF3A0yJNkeVPy1RUgv6NDV+yuS1E9VHMqsjOsF/vp5KoXltfx7XiKdgnwbCg7w92POmGjWpZ/kRKmHChRbGdqQeBpb8iiWRA7WhqQ1cPAbqCmFES0UIdqid6KS+TCiwj1nO/Qc7hnFX1sIoepJvLkiaWyAtJVq1dfh7GZRRvDV3lxW7Mzh/gsHeTe43gJzx0bTKOHTHTm+noohGGpIhBCzhBDpQoiDQgibVUhCiHlCiDQhRKoQ4kPTtkQhxBbTtt1CiOstxr8jhMgUQqSYbsZ3bXEGu4YkQaWb1lZ4b06as9mzHDpFQP9pzu1nVMDdrPhrlFvLTGSCWpF4q+3z0c2qQNdLbq2C8hr+vGIvw/uEGlK57ioDIrswLrYby5KzzuyqeI5gmCERQvgDi4BLgaHAfCHEUKsxccDDwGQp5TDgt6aXKoFbTNtmAS8IISyTz/8gpUw03bzcuq4FmqtqtyRyMCB15pYvqSmDjK/Uj5u/k24PowLu+elK8deoQLuZqCFQVaSSDLxB6goI7OQVt5Y51besup5/z0sk0L91OVzmJsVwuKCC7UeLfT0Vj2PkX3o8cFBKeVhKWQssAaz7ai4AFkkpiwGklCdN9xlSygOmx8eBk0CkgXP1DFVFqt93czESOJ0CrN1bvmP/l1BfDSNsSMbbw6iAe44Bir+28GbmVkO9ikPFz4SgzoafbmXKcb5KzeP3l8QT38M7bjRnuHxELzoF+bP0HAy6G2lI+gCWf7Fs0zZL4oF4IcQmIcRPQohZ1gcRQowHgoBDFpufNLm8nhdC2GwkIIRYKIRIFkIk5+d76eqrpRoSM90HKPVTrQLsO/Ysh659IXq88/v6B6g4hqdXJNnJqkjVk4q/tvBm5tbRH9XKxwudEPNKqnl85V7G9uvGXVPtt8v1BZ07BHDFyF58uTuXipp6X0/HoxhpSGzl21k7BwOAOGAaMB9409KFJYToBbwP3C6lbDRtfhhIAMYB3YE/2Tq5lPJ1KWWSlDIpMtJLixlHDElAEHQfqFckvqKiEA6vg+FzVMMnV+g9GvI8LCmfs93zir+26NJDSdQ7uCJxy5+fsVZla8Vd7PoxHEBKyZ8+2U1tQyPPzR2Fvw9Tfe0xLymGitoGVu/J9fVUPIqRhiQbsGzuEA0ctzFmpZSyTkqZCaSjDAtCiFDgS+BRKeVP5h2klLlSUQMsRrnQWgct6WxZEhmva0l8RdpnSlTTFbeWmV6JKp7hqYC7WfHXaLcWmDK3htj9/NU1NPLQJ7uZ/NT3FJTXuHauzI0Qcx4EdnRtfwdZsi2L9Rn5PHzpEPpHGO9Cc4ex/boxIKIzy5KzfT0Vj2KkIdkGxAkh+gshgoAbgFVWYz4DpgMIISJQrq7DpvErgPeklMssdzCtUhBKA/pqYK+B78E5ykxXGS3FSED5qYsyod7FL6jGdfYsV3GOHsNdP4anA+5mxV+jA+1m7GRulVbXcfvibSzZlkVeaTXPf5Ph/DkqCuHEHuh/vpuTbZmsokr+/kUakwaG8wt7Uu2tACEEc5Ni2HqkiMP55b6ejscwzJBIKeuB+4G1wD5gqZQyVQjxhBBitmnYWqBQCJEGrENlYxUC84DzgdtspPn+TwixB9gDRAB/N+o9OE3ZCeU2sFcHEJkAsgEKD7U8TuNZSrJVH+0Rc91zIXk64N5U0e6hHu32iBqien2XnzjrpdySKua9uoWfDhfy7HUjuWViLB9tPcb+vFLnznFko7rvf4EHJmybxkbJH5bvQgjBM9eN9Gn1ujNcO6YP/n6C5dvPnVWJoSWfUsrVwGqrbY9bPJbAA6ab5ZgPgA+aOeaFnp+phyjLte/WgjM1t3oMbXmsxnPs/VTdD3cz+OvpgHu2gYq/trDM3LL4vKYeL+GOd7ZRWdPAO7ePZ0pcBDMqalmxM4e/f7GP9+8c73gzqMwNENTl9OrNAN7dcoSfDhfxzLUjie7WybDzeJqo0GCmxUfyyY5sHrg4noBWlqbsCm3/HbQm7NWQmAkfBAgdcPc2e5ZB7zGeyYzqlWgKuDfaH2uPHAMVf21hI3NrfUY+817dgr8QLLt3IlPilFHr1jmI386I48eDBc6JDh7ZCP0mGdZT41B+OU+t2c+FCVHMTYo25BxGMjcpmhOlNWw84AMlZgPQhsSTtKSzZUlgR3UFeq6nACe/DSvu8fUsFAUH1A+/O0F2S3qP9kzAvTRXtVL1llsLVC+Mjt2bMreWbD3GHe9so194Z1bcN5mEnmcq9N48oR8DIjvz5Jf7qK13wHCW5qr+4gbFR+obGnlw2S6CA/15as4IQ1vmGsWFCT3o3jnonKkp0YbEU0hpXx7FksiEc39FkrZStbH1xFW7u+xZDgjP1TQ0Bdzd7JhoLkT0VqAdmjK3ZP5+nl27n4c+3cOUQREsvWeize6Bgf5+PHr5EA4XVPDBT0ftH98cH4md6uGJK17feJidx07xt6uHE+WlboeeJijAj2tG9+HbfScodDUrrhWhDYmnqDRVtYf0cmx8ZLy6Sm44twqTziA/HRpqT6dF+wopYe9yiJ0CoQ7+f+zhqYB7k+LvSM/My0EaIgZTlbOXResOMn98X966NYkuHZoPmU4fHMXUuAhe+DaD4oralg+euV4lnRigYrw/r5Tnv8ng8hG9uHKkh/6XPmJeUgx1DZLPUqyrItoe2pB4iqYaEhsNrWwRmaAMT3GmcXM6kaaCnr6guuR0OnSxA1exRpKbolxQnnJrgecC7kYr/tqgpLKOdw4E06mxgv++hCZjAAAgAElEQVSb3p1/XDPcbsBXCMFjVwylvKaeF761kw6cuVEZbQ+3I66tb+SBj3fRtWMgf7t6eJt0aVkyuGcIo6K7nhNCjtqQeArzj6bDKxIvaG59+QB8ssC447eEpSjlqWO+mYOZPcvVVf+Q2fbHOoO7AXdvKf5akFVUyZxXNrGuKByAWwdWOfyDHN8jhBvP68sHPx/jwIky24OKj8Cpo4ak/b70/QHSckv555yRdO8c5PHj+4K5STHszytjb46T6dWtDG1IPEVLLXZtERGv7o2qcK8oUJ3pyvOU283bWBrIUz5ckTQ2KgXaQTOgU3fPHtvdgLtZ8ddLgfbd2ae45uVNFJTX8rsbTUbVyc/f72bE0ynInydXNyOxkmmuH/FsfGRX1ikW/XCIa8dEc/FQB79jbYArR/WmQ4Bfmw+6a0PiKRzR2bKkQwiERhu3IjnwtaqWBt8E9fP3g3+QyhDypSE5tkVlRXnSrWXG3YC7FwPt36ad4PrXfiI40J9P7p3E2KHxqh+LkyrA4V068JuL4vghPZ916TbSgTM3qP+5uVbFA1TXNfD7ZbuICunA41eeW3VXXTsGcunwnqxMyaG6zoBmaV7CriERQtwvhOjmjcm0acrylHqrM7pCkYONSwFOX60KwgDyvdxaFVT6Z/gg6NbftzGSPctUP4zBl3r+2O4G3M2Kv92NVfx9b8sRFr6fTHyPLqz45WQGRZk+Fw5obtnilomxxIZ34skv91HXYOHWk1JlbPU/36Pik//6Op2DJ8t5+tqRdO1oTF2KL5mXFENpdT1rU32clOIGjqxIegLbhBBLTR0P23aEyyjK8xyPj5iJTID8DM+nx9ZVw8HvlRRIUBc46QOByPx0ZSi79fNdjKShTqUgD77UmH4Y7gbcc3Yot5arKsR2aGyUPPllGo+vTOXChB58tHACkSEWXRfMKehOBnqDAvx45LIhHDxZzoc/W/xvCw+qWKEH60e2Zhbx5o+Z3DyhL+fHt/6WRK4wYUA40d06tmkhR7ufYCnloyhF3reA24ADQoh/CCEMbpzQxijLczw+YiYyHuqroMTDP7RHNqp2sAmXq1iMt5WG66qUOytiMIT1VRpXvkhzPrRONRsbMde4c7gacK+tgJOphgba//7lPt7YmMltk2J57Rdj6RRkld4blaD61pc630f84qE9mDQwnOe/zaCksk5tzFyv7j1UP1JRU8+Dy3YR060TD186xCPHbI34+Qnmjo1h06ECsooqfT0dl3DoUsikiZVnutUD3YDlQohnDJxb26LshGsrEvB8DCN9NQR2Vl9oF90XblF4UMVnIuMhrJ8SqCzzQa78gbUQFAIDLzLuHL1dlJQ/bqzi71d783h7kzIif7lyqO0eHVGmeIMLK1ZzOnBpVR0vfmfK0MvcqOJ+3d1vLFVYXsNti7eSVVzJc3NH0bmFGpdzgWvHqp5/n+xom6sSR2IkvxZCbAeeATYBI6SU9wJjgWsNnl/bQEqTa8vJFUlT5pYHDYmUkL4GBl2oahMiE5QGmDczt8zvx7wiAd/ESQoPQUScaiZmFL1Hq3tn4yRNrXU9n7GVVVTJH5bvYlR0Vx65bEjz6b1NFzKuxdCG9Arl+nF9eW/LEQ6dLPVYfGR/XimzX9rE7uwS/nPDaMb393C2XSskulsnJg+MYFlyNo2Nba+mxJEVSQQwR0o5U0q5TEpZB2DqWHiFobNrK1QVqwpuZ1cknbord5gnDUluivJTD75MPfdma1UzBRkg/EzBdlOPCF/ESYoOQ/f+xp7DHHB3NnMrO1mt1jys+Ftb38j9H+4A4KUbxxAU0MJX3Pz5cyOG9sDF8QQH+vP+yjVQWeh22u+3aSe49uXN1DU0svTuiVw5qrdbx2tLzE2KJudUFVsOF/p6Kk7jiCFZDTRdzgohQoQQ5wFIKX2QDtQKaWpo5UJ+u6djGOlr1I943CXquaVkvbfI369EKQODlasD4f0U4IY6FZvpZrAhcTXgnrPdELfWP9fsY1d2Cc9eN4qY7g5Iq0cmuJXVFxnSgfsvHISfm/paUkpeXX+IBe8nMyCyC6vun8KomDD7O55DzBzWk9DgAJa1wZoSRwzJK4BlK68K0zaNmaYaEhe0f1zMnGmW9NWqvan5SrdrjPczt/Iz1JU6KLdSaB/vr0hOHVOxGQ/46+3ibMC9SfHXs4bkq715LN50hNsmxTJruIP1TFFD1GfDjczB2yfHcmFwOjl+vagP6eP0/jX1DTy4bDdPrdnPZSN6sfTuifTs2jbFGN0hONCfqxL7sGZvHiVVdb6ejlM4YkiEtBCCMbm0zu3Il7OUOamzZUnkYKgtO72qcYdTWZC358yaCSHUObxVS9JQrwLPkfGnt4X19X6MxKxhZrRrC5wPuJs7InpwRZJVVMkfl+9iZHRXHr7MiWLAyASV4Vfi+lVwByE5T6SxvnYIS7Y5d5yC8hpufONnPtmRzW9nxPHS/NF0DPKsRldbYl5SDDX1jXy+q20JOTpiSA6bAu6BpttvgMOOHNxUd5IuhDgohHiomTHzhBBpQohUIcSHFttvFUIcMN1utdg+Vgixx3TM/7SKuhazYKMjvUis8aTrKeMrdW+OjzSdY4j3ViTFR5QYpWVlsy9qSYpMhsRo1xaoFQk4HnDPSQa/AI8p/prjIhJ4af4YOgQ48UPsiRha3i4C68vJjxjPv7/JoLTasavpfbmlXPXSJlKPl7DoxjH8dkZ8mxdidJfhfUJJ6BnS5txbjhiSe4BJQA6QDZwHLLS3kxDCH1gEXAoMBeYLIYZajYkDHgYmSymHAb81be8O/MV0rvHAXyyq618xnT/OdJvlwHswlrI86NAVglxo9+nJFOD01SrAHRFndY7BUHHSO5lb5h8ks2sL1IqkNAfq7ciPe5KiTBUEd1Syxh0iEyAg2PE4SXYy9PCc4u9Ta/ab4iIj6Rvu5GfQsu2uq5gUpi+5fC7FlbW89L39ldnXqXlc+8pm6hsbWXb3JC5v45LwnkIIwbykGHZll7A/r+0IOTpSkHhSSnmDlDJKStlDSnmjlNKRnpvjgYNSysNSylpgCXCV1ZgFwCIpZbH5XKbtM4FvpJRFpte+AWYJIXoBoVLKLSZ323vA1Q69UyNxpqGVNZ0joWM39w1JdanK47clBeLNzC2z5IulMQvrB0go9WKOfHGmCvi7cYWbWVDBip3Z9iW+/QNU7w1HMrfMir8ecmutTT1dLzJruAs/xh3DVGzPnc9G5kaIHMKQuEHMHRvN4k2ZHCmosDlUSsmidQe5+4PtxEWpoPqI6K6un/sc5OrRfQj0F22q0t2ROpJgIcR9QoiXhRBvm28OHLsPYLk+yzZtsyQeiBdCbBJC/CSEmGVn3z6mxy0d0/uUuVBDYkYIz3RLPPSdcilZu7XAM1edjpKfoYLrwRbtWn1RS1KU6Xag/cFlu/jdx7t4+YdD9gc7GnAvyDAp/rpvSLKKKvnDMhfiItZEJrj+2aivVcKYprTfBy8ZTJC/H/+woQ5cXdfAA0t38ezadK4Y2ZuP77bdkbG9071zEBcP7cGKnTmOtTZuBTji2nofpbc1E1gPRAPNNCM4A1uXgtaXdgEo99Q0YD7wphAirIV9HTmmOrkQC4UQyUKI5Pz8fAem6wau6GxZEhGvguHuZG6lr1F9uKPHn/1a12iVueWtFUlE/JnbmmpJvGRIGhtVrMaNQPu2I0VsP1pMv/BOPLs2nSVb7cR4HA24Z3tG8detuIg1UUOUgXMlcytnO9RVNulrRYUG88vpg/g67QSbDxU0DTtZVs38N35ixc4cfn9xPP+5IZHgwPYbVLfH3LExFFXU8v3+E76eikM4YkgGSSkfAyqklO8ClwOO9NDMBmIsnkcD1qkI2cBKKWWdlDITSEcZlub2zTY9bumYAEgpX5dSJkkpkyIjDRR7M/dqd6WGxExkgipqrCiwP9YWDfWQsRbiZyo3izVNmVsGG5LGRrUiiRx85vaQ3iD8vRdwL89TGmbdYl0+xKs/HKJ75yA+/9UUpg2O5JEVe/hqbwvqrI4G3HM8o/jrVlzEmsgEZQxcMfRHNgIC+k1u2nTnlP70CevI377YR0OjZG9OCVe/tIn9uWW8ctMYfnVRXLsPqttjalwEPUI7sLSNuLccMSTmFIxTQojhQFcg1oH9tgFxQoj+Qogg4AZgldWYz4DpAEKICJSr6zCwFrhECNHNFGS/BFgrpcwFyoQQE0zZWrcAKx2Yi3G4WtVuifmH11VJ+ayfoPpUy1Lp3sjcKs1RqaTWKxL/ALUq8pZrq8i91N/0vDK+23+SWyfGEhocyMs3jWFUTBi/XrKTLYeaqTp2NOCevR16j3FL8dftuIg17sTQMjdAr5FnNA0LDvTn4csS2Jdbyh+X72buq1uQwLJ7JnLpCB1Ud4QAfz+uHRPND+kn+fc3Ga2+rsSRT/Prph/zR1GGIA142t5OUsp64H6UUdgHLJVSpgohnhBCmHuergUKhRBpwDrgD1LKQillEfA3lDHaBjxh2gZwL/AmcBA4BKxx7K0ahDs1JGbcTQFOX6OaSA28sPkxUQnGZ26ZDaGtpkbeTAEudi/197X1h+gY6M8tE5VLrlNQAItvG0e/7p1Y8F4ye3NKzt7JHHBvaUViVvx1w61ljouM6ONmXMQS8+fP2ThJXZXqwmmjmv3yEb1I6teNT3ZkM7hnCCvvm8zwPjqo7gwLzx/AzGE9+c93B5jy9Pe8+O0Bh1OrvU2LhYVCCD+g1JQ5tQFwKnoppVyNklix3Pa4xWMJPGC6We/7NnBWUF9KmQwMd2YehmKuIXFnRRLaxxTDcGFFIiXs/1L5qDuEND+uKc14P/Sb5No87WGev7VrC1TA/cA3xpzXmqJM5UozB/mdIOdUFat2HecXE/vRzaIveFinIN67czzXvryZ2xZvZfk9k4iNsOpx0isRdn2kXHy2VhxmxV8XA+219Y3c/9FOpIRFN7oZF7EkuKv6DDp7IZP1s1qN2+jPLoTgX/NGsXpPHrdPjtXxEBcI6xTEKzePJe14KS98m8Hz32bw9qZMFp4/gFsnxdKlFSkit7giMVWx3++lubRNnO3Vbgt3YhgFGeoK3F4HQG9kbuWnq4C/LSHCsFilQlxXZdz5zRRnQlgM+DvfTe/NjarW9q6pZ18z9erakffuPI+GRsktb2/lZGn1mQPsBdzdrGh/+qv97Mo6xTOeiItY40rmVuZGZbD7TbT5cr/wztw7baA2Im4ytHcor9+SxOf3TyGpXzeeXZvO1Ke/55UfDlFR44M+PzZwxLX1jRDiQSFEjBCiu/lm+MzaCs72am8Oc7dEZ0k3Lfji7RiSrtGqN4eRAfcCG4F2M+bVwSkvVOwWHXbJrVVcUcuSrVnMTuxNnzDbLZMHRXVh8e3jKSiv4dbF2870XdsLuOe4rvj7dWoeb/2o4iKGxBmaMrec6BueuQH6jGl5JazxGCOiu/LWbeP47L7JjIoJ4+mv9nP+M+t4Y8Nhqmp92+/dEUNyB3AfyrW13XRLNnJSbYqmqnY3W7lGxCs3WVWxc/ulr4Feo6CrnXIa86rHiatOKSUNjvZGkFIZqeYMiTfl5IsyXQq0v7flKFV1DdxzQcsZVYkxYbz2i7EcPFnGgveSqa4zfYntBdyzXVP8zSqq5EFPx0WsiUyA+mqVNu0INWVqheXBtroax0iMCeOd28fzyb2TGNo7lCdX72PqM+t468fM059FL+NIZXt/GzcvSKq2EVxpaGWLphiGE6uS8nzI2mq7CLG5czgYhymuqOXGN37m4n+vp6C8xv4OFQXKCEbYW5EccWyurlJVrDLYnFyRVNbW887mTC5KiCK+h/0r7Klxkfx7XiLbjhTxq492Ut/Q2HLAvSxPVfY72cjKsLiINc5mbh3dotSVtSHxGWP7deP9O89j2T0Tie/Rhb99kcb5z6zj3c1HvG5QHKlsv8XWzRuTaxO4I49iiSspwAfWAtJ+fMSMg5lbh/LLueblTWw/VkzOqSoWWl51N0dTxla87de79FSZZUavSJpSf5271lm6LYviyjrumeZ4fceVo3rz1yuH8U3aCR5ZsUdJqfRKhNxdZxf3mQsRnQy0GxoXscTZzK0jG9T/M+Y84+akcYhxsd35cMEEPlowgdiIzvxlVSrTn/uB9386Sk29dwyKI66tcRa3qcBfgdkt7dCuKMtzTfXXmrC+yi3iTOZW+hqVbeOoimyk6aqzhR+LzYcKmPPyZsqq6/lowXm8cH0iO7NO8ftlu1puAZrfQuovqCymrjHG15K4IB9f19DIGxszSerXjXGxzoX/bp0Uy68vimNpcjbPrE1vPuBuVvzt5dj/6nB+OU9/td/YuIglHULU/8fRFUnmBqWiEGg7lqTxPhMHhvPxwgn8767z6B3Wkcc+28uFz61nX67x4o9288eklL+yfC6E6IqSTdGYq9o9sSLx81dCh45+keuq4ND3kHij48KEURY9umMnn/Xy0m1ZPLJiD/0jOvP2beOaOuw9fGkC/1i9n37dO/HHWc0YioIMlcIc2kKsxslakv15pRwrrOSSYU78fYtMHQ6cqGr/cncuOaeq+L/Zwxw/jwW/mxFHYXkNr/xwiLjzI5gDyr1luTrL2W5S/G3+h/dkWTVf7MplZUoOu7JLEAJmDuthXFzEmsgEx4pWK4sgdzdMe9j4OWmcQgjB5EERTBoYzsYDBby7+Qix4W7Gbx3AlUTkSpSMiaaqGBpqPCdVHpkAx35ybGzmBiVr4ahbC0z1KiFnrXoaGyXPrE3n1fWHmBoXwaKbxhAafDp1dsHUAWQWVPLyD4eIDe/MvHEx1kdWBjAirmWjFtZXuX0cYPOhAu56N5nK2gYW3zaO6QlRDu1H0RGViu1g8oO5xWtcVBcudPQcVggheOKq4RRX1vKHDTlc1akD/sdTYOQ8NaCxAXJ2wqjrz9q3vKaetXvz+Cwlh00HC2iUMKx3KH++bAhXjurt3U6BUQnqc9XYoC5smuPoZkDq+EgrRgjB+fGRnB9voDyUBXYNiRDic04LI/qheossNXJSbYZyk6CaxwzJYNizDGrKoUOXlsemr1YrAGd6ZNvI3KqqbeB3H6fwVWoeN53Xl7/OHkagv5/VboInrhpGdnElj6zYQ59uHZk8yCqFNT/D/g9LWD+oLLT7/r5NO8EvP9xBbHgn/ITggaUpfPnrqfRuJiX3DIoznQq0/5Cez/68Mp6bOwo/P9f1n/z9BM9fn8jtlXXszooh9tBWzA10lOJvWVN8pLa+kQ0Z+XyWksO3+05QXddITPeO/HLaIK4e3ZtBUT5Kp40coi6MijIhYlDz4zI3QGAnpxMHNOcujqxInrN4XA8clVK2DSUxozG3x/VEjAROZzwVZKj8/OZobIT0r2DQRRDQwblzRCUogUfgZGk1d72XzJ6cEh67Yih3TI5tVkwv0N+PRTeNYe4rW7jng+18eu8k4szZTdWlUHa8+dRfM02ZW8egx1CbQ1am5PD7pbsY1juUd24fz6mqOq74z0Z+9dFOliyccJaRO4uiTBgwreUxFryy/hC9ugYze1Rvh/dpjg4B/rx+SxI//DuBuJPfsf1IAWNjI5oC7XsZxJLP9vDl7lyKK+vo1imQuWNjuHp0b8b07eZ7IUNL16c9Q9J3AgQENT9G065wJNh+DPhZSrleSrkJpY0Va+is2gplnl6RONgtMXenSjt2NO33jHMMgYp80g8f4apFmzh4spw3fpHEnVP62/0hCw0O5O3bxxEc6M/t72wjv8yUFlxgSlm2Z0jMcYtm4iQf/nyM336cwth+3fjfggl06xxE/4jO/PPakWw/Wsy/vraTGl1XpQyag4H2HceK2ZpZxF1TBxAU4LqIoiVdOgRwwbSL6SKq+L93Pue7fSfY9dO3lNGJK5fksXx7NlPjInn7tiS2/nkGf7t6OGP7dfe9EYHTFzItxUnKTypDo91aGgsc+fYsAyxzGRtM2zTmFYmnDEn3/uAXaD8FOH0NCD+Iu8T5c5iM1d/f+RRQiqwzhjpeB9MnrCNv3ZpEQXnN6WI8s+FrrobETNOK5OzMrdc3HOKRFXuYPjiKd+8Yf4aO0OxRvbnpvL68uv4Q6/a30JzTXEznoGvr1R8O0bVjIDfYivm4QUh/5cIa5Z/Jne8mE5C3kyPBCfz7+tFsf/Ri/jN/NBcm9LC/uvI2Hbqo/1F+CynARzaqe21INBY48kkOMLXKBcD0WK9pQcVIOoS6X9Vuxj8QwgfaX5Gkr4G+E8+Q7nYEKSVLjqq5TgzJ57P7JjOst/OKrCOjw3jh+tHsyj7FA0tTkPnpqqbAXqZU50jVR91iRSKl5F9fp/OP1fu5YmQvXr15rE1tpseuGMqQXqE8sDSF46ea0etyQj7+4Mlyvtl3glsn9qOzp8XvTBXuDw6v4unZgxjqn82I8Rdxzehoz5/L09hrN5C5QX3me47y3pw0rR5HDEm+hew7QoirABc7MJ1jlOW6J9ZoC3vijcVH4cRe57K1gPqGRh5buZeHvi2kyq8zCxJq3GpzOmt4T/582RBW78njYNoOCB9ku6mWJUKoK17TyqGxUfJ/n6fx3+8PcsO4GF68YXSzLqbgQH8W3Tia2vpGfvXRTuoabHTzK3a8GPH1DYfoEODHrZNi7Y51Gv8A6DGcrqdSub5PIUI2eKS1rleISoDCA6pZmi0yN6gmVvb+15p2hSOG5B7gESHEMSHEMeBPwN3GTquNUHbCc24tM5EJ6oe2rtr26xlfqXsn4iOl1XXc/s42PvjpGHdfMJDgXkMJLHRBINKKO6f05+YJfQksyuCYX7T9HaCplqS+oZE/frKbdzYf4a4p/fnnnBH428maGhDZhX/MGdF8vKQoU+medex29msW5JZUsWJnDvOSYgjv4mSygqP0TlS1Fllb1fO2kuEUOURJw5vrcSwpyVbbtVtLY4UjWluHpJQTUGm/w6SUk6SUdhpTtxPKcg0wJINVz4rmpMjTVyuBx3DHpDyyiiq59uXNbDlUyNPXjuDhS4cgojzTdlcIwV8vHUhfv3w+y+nCxgP59ncK64s8dZRfL9nJ8u3Z/G5GPH++fIjDwearEvtwY3PxkqLD0D3WboHm2z9m0ihVfYxh9B6tUn73LFOrsC7eyed3G8vMLWsyzfERJ1LONe0CR7S2/iGECJNSlkspy0ztb//ujcm1aqRUMRJPG5KIFrolVpfAkR8ddmulZJ3i6kWbOFFazXt3jOf6caZgtylzi4pm2sY6QUDxYfxopCJkIL/8YAcZJ8paHF8XEoOoLuHHPYd47Iqh/GaG8/27H28uXuJADUlJZR0f/nyMK0b2aqrcNwSzpPyJvW3HrQWmz5+wHSfJ3KD6zUS5pgCgOXdxxLV1qZTylPmJqVuiC3mn5xjVp5TstqdqSMyED1IZWbYC7ge/hcZ6h9xauSVV3PnONjp18GfFfZOZZFlA2NJVp7OYMszuvOZSOgb5c/tii7RgK0qr6/jPDpW38eyMMO6c4lorXJvxkoZ6FcS3E2j/4OejVNQ2cPf5joszuoRZUh7caq3rdYI6Kfej9WdDSmVI+k91q9+85tzEkU+EvxCiyZEshOgIOORYFkLMEkKkCyEOCiEesvH6bUKIfCFEiul2l2n7dIttKUKIaiHE1abX3hFCZFq8lujYW/Uwnq4hMRMYrK6qba1I0tdAp3CIHtfiIWrqG7j3gx1U1zWw+LbxDIy0qiL3ZLfE/HQQfkTFDuOtW8dRVFHLXe8ln9Vop6iilhvf+IkN+WoVMLOPA9L0LXBWvKQ0WxnZFgLt1XUNLN6UyQXxkQztHerW+e1iCrgDbWtFAhA19OwVSXGm+hvr+IjGBo4Ykg+A74QQdwoh7gS+Ad61t5MQwh9YBFyKiq/MF0LYKmf+WEqZaLq9CSClXGfeBlyI0vf62mKfP1js00wXIYPxdA2JJZGDTxf5mWmogwNfQ/yslnWQgL99kUZK1imemzuKQVE2pEhC+6gUTld6xFuTn66kTwKDGRHdlRdvSGS3KS3YrBacV1LN9a9t4cCJch6cZ6p98YCcvGW8JGXXTrWxBdfWsu3ZFJTXcq8TUvFuEZ0E/h0cVvxtNUQmqBhdg0X3x8wN6j5WGxLN2TgSbH8G+DswBGUQvgL6OXDs8cBBKeVhU+3JEuAqF+Z4HbBGSlnpwr7G0aSzZYC8d+Tgs7/Ix7aoGImd+Mjy7dkqO+v8Ac1Lj7vTI96agowzpOMvGdaTRy8fypq9eTy9dj/HCiuZ+9pmjp+q4t07xjN1ZJwSjvSQnLw5XvLl+k1qQzOurfqGRt7YcJjEmDDO6++lTtHn/xFuX9P2pNajhkBjHRQeOr0tc4Ny40ZovVbN2Tjq7MxDVbdfC1wEOOIT6QNYNujONm2z5lohxG4hxHIhhK0S4xuAj6y2PWna53lLt5tXadLZ8nAdCagf5sb6M1Mw09eoq9sB05vdbW9OCX9esYeJA8L5w0w7VeaRCe67thrqoeDAWc2s7pgcyy0T+/Ha+sNc8d+NlFXX8+GCCUwYEK6MmJNy8i1hjpf0asyjlkDqO9teIa7Zm8exokruuWCg9+RIOodDdBtJ+7Uk0iqGJqXK2Op/vuMtCzTtimYNiRAiXgjxuBBiH/ASyigIKeV0KeVLDhzb1ifOujPS50CslHIk8C1WLjMhRC9gBLDWYvPDQAKq0VZ3VF2LrfkvFEIkCyGS8/MdSEt1lrIT6srankqvK5g1q8yuJylh/5cw4IJmz3eqspZ7/7ed7p2D+O+NowmwJ78RmQCVBapFrqsUH1FXrlbSKEIIHr9iKDOG9KBTUAAfL5zIqJiw0wPC+tqUSXGVAZFdmNW7imONkfzr27PTps1S8QMiO3OJE3Iw7ZaIeJXwYY6T5Kerzpo67VfTDC392uxHrT6ulFJOkVL+F6Wz5SjZgOUKIxo4bjlASlkopTRHXd8ArC/f5gErpJR1FvvkSkUNsBjlQjsLKaSRzJEAABskSURBVOXrUsokKWVSZKQBOfxluZ7p1W6LCNMVvtmQ5O9XP7zNuLUaGyW/WZLCiZIaXr5pDBGOFNk1ZW654d5qaq979uonwN+PN24Zy4Y/TmdwTytZ9DDTikS20HHRSXo35lHXNZZXfjjEuvQz60t+PFhA6vFS7j5/gFtS8e0Gc8LHyTT13Bwf0YF2TTO0ZEiuRbm01gkh3hBCXITtVUZzbAPihBD9hRBBKBfVKssBphWHmdmc7TKbj5Vby7yPUP6Jq4G9TszJc5SfMCY+Akq7q2vf0z/y6avVffwsm8Nf+O4A6zPy+cvsoYzu23JVdxMOtN21S5NYo+0+7UII25InYX1VO1o7veMdRkooyiQuYQQJPUN44OMUcktO15e8uv4QPUI7cPXoFro3as4kasjpz1/mevU/c6LrpKZ90awhkVKukFJej3Ij/QD8DughhHhFCGFXdlZKWQ/cj3JL7QOWSilThRBPWGh3/VoIkSqE2AX8GrjNvL9Jqj4GWG916P8JIfYAe4AIVCKA9zFCZ8uSyMGnf6jT16hK6dCze2Z8t+8E//nuANeNjebG8X0dP35ob1Pmlhsrkvx0COkNwU6m0nYz5Wp4yr1VfhLqKgiIGMiim8ao+pIPd1Lf0Mju7FNsOljInVP60yGg5Ww3jQWRCSrYXlelimD1akTTAo70bK8A/of6Ae8OzAUe4sx03Ob2XQ2sttr2uMXjh1ExD1v7HsFGcF5KeaG98xqOlMbobFkSOVhJdpfmqsZI0x85a8jRwgp+93EKw3qH8verhzsXRG7K3HIjBbgg/axAu0NYysm31MDLUcxijd36M9BUX/KbJSn865sMjhZWEBIcwHxnjKxGrUhkA6R+popvddqvpgWckvCUUhYBr5lu7ZfqEqivMs61BepHvr4atr4OyLPiI1W1Ddz9/naEEM1Kr9s/R4Ja7biClCpjK/Em5/e17JToCazk469K7MNPh4t45YdDCAH3XjCQEIse9BoHMGdubTV91XWgXdMCWuvAFTzdq90W5i/ytrega8zpKmlUFtIjK/aQfqKMF29IdF0zKmqI65lbpTkqzmGvK6ItgrtCcJjHakkozlRZRmGnVx1/uXIoCT1DCPL34/bJrkmxtGsi4kD4w/GdEB5n062q0ZjRTQVcwciqdjPmAHZNCYy6/oz8/fe2HGXFzhweuDieaYOjXD+HpVSKs1ec5tiKK4YEPFpLQlEmhEaf0b8+ONCfJQsncKK0hsgQ35QatWkCOii5mcIDejWisYtekbiCWWfL04KNlnQMO318C7fW9qNF/O2LNGYMieL+6YPcO0ekGynA+SYJF3vtdZvDk7UkZvl461N0Cjo79VjjOOYUcR1o19hBGxJXaFqRGFzcFjlYFT32mwLAybJq7v1gB326deRf8xLdr4lwJ3OrIF1JineOsD/WFp6sJXFAPl7jAj1HKvdWrF6RaFpGu7ZcoSwPgrpAB4Ovdi98VPUNCQiirqGR+z/cSWl1He/eMZ6uHT0QPBbCJJXiyookXRk6VyUzwvqpZILyk+4Z5OpSqCx0qE+7xkkm3AuDZrh+saBpN+gViSuU5xkbHzETMx4SLgfgqTX72ZpZxFNzRjKklwcl0KMSXOtLkp/ebCGiQzTVkrgZJ3GiT7vGSTqEeCY9W3POow2JK5TlGRsfsWLVruO89WMmt02K9Xx1dmSCuqJ3JnOrogCqilwPtMOZtSTuYBa21K4tjcZnaEPiCmVeWpEAGSfK+NPy3ST168Yjlw3x/AlcaXKV37zGlsOYDUnxEdePAWfVkGg0Gu+jDYmzSOk1Q1JaXcfd72+nS3AAi24aY1u3yl2iTMbJmYC7eayrGVug9MQ6RXjGtdUpwvh4lUajaRYdbHeWmlJTVbtxhqS+oZEv9+Ty0vcHySqq5MMFE+gRGmzMyUJ6qcwtZ1YkBRkQ2Bm6Rrt37m79PODaytTxEY3Gx2hD4ixleeregBhJdV0Dy7Zn8/qGQ2QVVREX1YVXbh7LeCM7+pkzt5zR3MpPN1U+u5l+HNYPct3slFx8BPpNcu8YGo3GLbQhcRazIfHgiqS0uo7//XSMt37MpKC8hsSYMB67XDWG8kr/jKgE1TjLUQoyPFNbENYX9n0OjQ12+9DbpL4GSrJ1oF2j8THakDiLBw1JflkNizdl8v6Wo5TV1DM1LoJfThvNhAHdvdcOFlRvkh3vQXk+dLHTBKy6VOlsuaL6a023fqrDYlkedHUhG634KCB1oF2j8THakDhLufuGJKuoktc3HGZpcha1DY1cOrwn914wiBHRXT00SSdpau27374hKTig7t0JtJuxTAF2yZCclo/XaDS+QxsSZynLU4FmF7KE0vPKeHX9IVbtOo6fgDmjo7n7ggEMiDSg77szWGZu2RPoa6G9rtOExar7U8dci3MU6WJEjaY1oA2Js7iQ+rv9aDGv/HCQb/edpFOQP7dPiuXOqf3p1bWjQZN0kpBe0KGrY5lb+fvBL9AzqwBz1percvLFmUqqRkt4aDQ+RRsSZ3HAkEgpyS6uIvloER9tzWJrZhFhnQL57Yw4bp0YS7fOQV6arIMIYZJKcaCWJD8DwgeBvwc+OoHByoi5WktSdFgZNG/GkzQazVkYakiEELOAFwF/4E0p5VNWr98GPAvkmDa9JKV80/RaA6ovO8AxKeVs0/b+wBKgO7AD+IWUstbI93EG5Xmqf7oF9Q2N7MstY9uRIrYfLSb5aBEnSmsA6NU1mMeuGMr88TF0CmrFdjtysGOZWwXp0HOE587rjpx8UeZpqXONRuMzDPtlE0L4A4uAi4FsYJsQYpWUMs1q6MdSyvttHKJKSploY/vTwPNSyiVCiFeBO4FXPDn3ZjFVtdd2jGRLRj7bjxSRfLSYlKxTVNY2ANAnrCPn9Q9nXGw3xvbrzuCeIfh7I4XXXRzJ3KqrVnUbI+Z67rxh/SDrJ+f3a2xQBsiqBbFGo/E+Rl4ijwcOSikPAwghlgBXAdaGxGGEyom9ELjRtOld4K8YbEhyTlWRfKSIPYeyebSukue2lPL6xq34CRjSK5R5STGM7deNpNhurSfu4SzmK/v8fc0bksKDIBvdU/21Jqwv7P0EGuqdc5eVHoeGWh1o12haAUYakj5AlsXzbOA8G+OuFUKcD2QAv5NSmvcJFkIkA/XAU1LKz4Bw4JSUst7imDbzRoUQC4GFAH379rU1xC7/XL2PVbuOk1tSDcDwoDzwg9FDE/hg3Hkk9g2jS4dW7K5yhkhT5tbJ/c13xPNkxpaZbv1ANqjaFLO0vCMUa7FGjaa1YOSvoC1/jnU7vM+Bj6SUNUKIe1ArjAtNr/WVUh4XQgwAvhdC7AFKHTim2ijl68DrAElJSS614fPzEyTFdiepXzfG9uvGkOoUeB8unTga+p9jmUIhPVXmVksB9/wMQKhgu6ewrCVxxpBo+XiNptVgpCHJBmIsnkcDxy0HSCkLLZ6+gYp/mF87bro/LIT4ARgNfAKECSECTKuSs47pSf40yyqQu9vUqz2kl1Gn9B2OZG79f3v3HiNXeZ9x/Pt4fQ1gdo0v5WabtFYJSCkFx6WkRVHSEoMikxYUQJECJClKWotEVSNAqUhEmz9o1YtoUCoINJDQhoY2xWlJgdCoVRVuTmRuAWPHJrWDbdasbdYGbAy//vG+xxyPZ3bHnjkzh93nI43mzDnvmXnnzMz+9r1vXwtDi2FaF6vvBo9wgauRjakbcqcTR5pZx6qcRv5xYImkUyRNBy4FVpUTSCr/RV4BPJv3D0makbfnAu8HfhoRAfwQuDifczlwb4Xv4WAHJmyseK32fpl3ahpL0mod9WJ53W469iTQlMMfS7JjYyrNHMkcXWbWVZUFklxiWAncTwoQ/xwRz0i6QdKKnOxqSc9IegK4Grgi738PsDrv/yGpjaRopL8G+GNJ60ltJrdV9R4O0cGo9neE+e9JKx/uGT702Jv7U2N7NxvaAQamwewTj6xE4oZ2s1qotKU4Iu4D7mvYd31p+zrguibn/QhoOlgh9wJb1t2ctmn3VjhmwcQdAHfQnFvzDz628+epl1S3SyRw+GNJIlI35IVndz8vZnbYvELi4RjdOjHbRwrlnluNiraTeRUMABxcdHglkldfTguMuaHdrBYcSA7H6NaJ2z4CqefWzGPTWJJGxcJXc5d0/3UHF6ZxIfv3tpfe67Sb1YoDyeGY6CWSYrXEZiWS7c+n9z6zgqnuhxYBkRapaoenjzerFQeSdu0dhTf2pDaSiWzeqalE0thzq4oeW4XyWJJ2jGwElLoim1nfOZC068DKiBO4RAK559aOg3tuRaQSSTcWs2qmGEvSbhfgkQ0w+4Q0e7CZ9Z0DSbtGt6T7idxGAm83ppfXJnnlF7Bvd3eW121m9gkwZWr7De47Nrpay6xGHEjaNTqBR7WXFYGkaFwvb1dVIpkykAYmHk7V1pzF1eTFzA6bA0m7ihLJRG8jadZzqwgkVXT9LbTbBXjvbtjzkkskZjXiQNKu3dtg2rtgxux+56RaUhpPUu65tX0tzBqqdknbwYXttZHseCHde1S7WW04kLRrdEtqH5moo9rL5jf03BrODe1VvvehRamk8cZrY6crZv31GBKz2nAgadfotonfPlKYd+rBPbe2r62uob3Q7izAHkNiVjsOJO0a3TLx20cK5Z5be7anKUmqbB+B9gPJyMZUzTZrsNr8mFnbJsjyfj2wexKVSObnObeGn0vdcqG6HluFYlBi0QbSyg7P+mtWNw4k7dg7msZRTPQxJIWjF8DMwVQiGZiW9lVdtXX0AhiY0V6J5KT3VZsXMzssrtpqx2QZQ1Io5twaXpsa2qcdBbMrXolwyhQYPHnssST798GuTW5oN6sZB5J2TJYxJGVFz63h59KMv1N68FUZbyzJrk0Qb7mh3axmHEjasXuSlUggjSV5bQdsfry6yRobjTeWxNPHm9WSA0k7Jss8W2Xzcy+tfbu7v7xuK0OL0lK/e0ebHy+6/rqx3axWKg0kkpZLWitpvaRrmxy/QtKwpDX59um8/wxJD+f13J+UdEnpnG9I2lg654wq3wOQZv6dOquatTjqqtzdt+quv4UD08m3qN4a2ZhmF5hMAd3sHaCyXluSBoCbgd8FNgOPS1oVET9tSHp3RKxs2Pcq8ImIWCfpBODHku6PiJ35+Bci4p6q8n6I0Qm+VnszRc+t13f2sGprcbrf+X+w4PRDj49sSGuQTKbPwewdoMoSyTJgfURsiIh9wLeBC9s5MSKej4h1eftF4CVgXmU5Hc9kGkNSkNJ4kinTete4fWAsSYt2Ek8fb1ZLVQaSE4FNpceb875GF+Xqq3skndx4UNIyYDrws9Lur+Rz/kbSjGYvLukqSaslrR4eHm6WpH2jW9KsuJPNqR+B0y6EgR4NNzpqbqq6atYF+K230mBFN7Sb1U6VgaRZ/UPD+q18D1gcEe8FfgDccdATSMcD3wSujIi38u7rgFOB9wFzgGuavXhE3BIRSyNi6bx5HRZmRrfB0ZMwkJyzEi6+rXevJ6VSSbM2kt1bYf/rDiRmNVRlINkMlEsYJwEvlhNExMsRsTc/vBU4qzgmaTbwH8CfRsQjpXO2RLIX+AdSFVp19u6GfaOTs0TSD4OLmldtFbP+umrLrHaqDCSPA0sknSJpOnApsKqcIJc4CiuAZ/P+6cB3gTsj4jvNzpEk4KPA05W9AyiNIXEg6YmhFoMSPYbErLYqq/yOiP2SVgL3AwPA7RHxjKQbgNURsQq4WtIKYD8wAlyRT/8YcC5wnKRi3xURsQa4S9I8UtXZGuAzVb0HoDSq3YGkJwYXwt5daTDkrKG39+/YCBqAYw9pRjOzPqu0FTUi7gPua9h3fWn7OlKbR+N53wK+1eI5P9jlbI5tdGu6n4xtJP1Qnk6+HEhGNqa5uIpJJM2sNjyyfTxFIHGJpDdadQH29PFmteVAMp7dW2HqzMk1qr2fhloscDWywQ3tZjXlQDKe0a2pNOLR1L0xcxBmzD54LMmrI/D6Lje0m9WUA8l4Rre6faSXpEOnk/c67Wa15kAynqJEYr3TOJ28u/6a1ZoDyXgcSHqvGEsSeSKEAyWSxX3Lkpm15kAyFo9q74/BhfDGHnj15fR4ZGOqXpx+VH/zZWZNOZCMpRjV7jaS3jowliRXb41sdLWWWY05kIzFY0j6o3EsiaePN6s1B5KxeHqU/iivlPjGa+lz8GBEs9pyIBmLJ2zsj5mz0/QoO3+e1iABV22Z1ZgDyVhGt8DAjDRIznqrGEvi6ePNas+BZCyj2zyqvV+KsSQeQ2JWew4kY9m3Z/Kt1V4XQ4tg16ZUIplx7MEzAZtZrfRoMe53qMv+Ed56s9+5mJwGF6WldTc9lkojLhWa1ZZLJOOZMtDvHExOxViSbU+5Wsus5hxIrJ6KLsDghnazmqs0kEhaLmmtpPWSrm1y/ApJw5LW5NunS8cul7Qu3y4v7T9L0lP5OW/Ka7fbRFMOJC6RmNVaZYFE0gBwM3A+cBpwmaTTmiS9OyLOyLev53PnAF8CfgNYBnxJUtHa+jXgKmBJvi2v6j1YH01/Fxw1P227RGJWa1WWSJYB6yNiQ0TsA74NXNjmuR8GHoyIkYjYATwILJd0PDA7Ih6OiADuBD5aReatBopSiUe1m9ValYHkRGBT6fHmvK/RRZKelHSPpJPHOffEvD3ec9pEMLQoDQh1F2yzWqsykDRru4iGx98DFkfEe4EfAHeMc247z5meQLpK0mpJq4eHh9vMstXKsqvgw1+BKe4TYlZnVf5CNwMnlx6fBLxYThARL0fE3vzwVuCscc7dnLdbPmfpuW+JiKURsXTevHlH/CasjxaeDcv+oN+5MLNxVBlIHgeWSDpF0nTgUmBVOUFu8yisAJ7N2/cD50kayo3s5wH3R8QWYFTS2bm31ieAeyt8D2ZmNo7KRrZHxH5JK0lBYQC4PSKekXQDsDoiVgFXS1oB7AdGgCvyuSOS/owUjABuiIiRvP1Z4BvALOD7+WZmZn2iiKZNDBPK0qVLY/Xq1f3OhpnZO4qkH0fE0vHSuRXTzMw64kBiZmYdcSAxM7OOOJCYmVlHHEjMzKwjk6LXlqRh4OdHePpcYHsXs9Ntzl9nnL/OOH+dqXv+FkXEuCO6J0Ug6YSk1e10f+sX568zzl9nnL/O1D1/7XLVlpmZdcSBxMzMOuJAMr5b+p2BcTh/nXH+OuP8dabu+WuL20jMzKwjLpGYmVlHHEgyScslrZW0XtK1TY7PkHR3Pv6opMU9zNvJkn4o6VlJz0j6XJM0H5C0S9KafLu+V/nLr/+CpKfyax8yQ6aSm/L1e1LSmT3M26+WrssaSa9I+nxDmp5eP0m3S3pJ0tOlfXMkPShpXb4fanHu5TnNOkmX9zB/fynpufz5fVfSYItzx/wuVJi/L0v6RekzvKDFuWP+1ivM392lvL0gaU2Lcyu/fl0XEZP+Rprm/mfAu4HpwBPAaQ1p/hD4+7x9KXB3D/N3PHBm3j4GeL5J/j4A/Hsfr+ELwNwxjl9AmvJfwNnAo338rLeS+sf37foB5wJnAk+X9v0FcG3evha4scl5c4AN+X4obw/1KH/nAVPz9o3N8tfOd6HC/H0Z+JM2Pv8xf+tV5a/h+F8B1/fr+nX75hJJsgxYHxEbImIf8G3gwoY0F/L2UsD3AB/Ki2tVLiK2RMRP8vYoaQGwd9pa9RcCd0byCDDYsLBZr3wI+FlEHOkA1a6IiP8hrcFTVv6O3QF8tMmpHwYejIiRiNgBPAgs70X+IuKBiNifHz7CwauV9lSL69eOdn7rHRsrf/nvxseAf+r26/aLA0lyIrCp9Hgzh/6hPpAm/5h2Acf1JHcluUrt14FHmxz+TUlPSPq+pNN7mjEI4AFJP5Z0VZPj7VzjXriU1j/gfl4/gAWRVgEl389vkqYu1/GTtF5UbrzvQpVW5qq321tUDdbh+v02sC0i1rU43s/rd0QcSJJmJYvG7mztpKmUpKOBfwE+HxGvNBz+Cam65teAvwP+rZd5A94fEWcC5wN/JOnchuN1uH7TSUs6f6fJ4X5fv3bV4Tp+kbSq6V0tkoz3XajK14BfBs4AtpCqjxr1/foBlzF2aaRf1++IOZAkm4GTS49PAl5slUbSVOBYjqxofUQkTSMFkbsi4l8bj0fEKxGxO2/fB0yTNLdX+YuIF/P9S8B3SVUIZe1c46qdD/wkIrY1Huj39cu2FdV9+f6lJmn6eh1z4/5HgI9HrtBv1MZ3oRIRsS0i3oyIt4BbW7xuv6/fVOD3gbtbpenX9euEA0nyOLBE0in5v9ZLgVUNaVYBRQ+Zi4H/avVD6rZcp3ob8GxE/HWLNL9UtNlIWkb6bF/uUf6OknRMsU1qlH26Idkq4BO599bZwK6iGqeHWv4n2M/rV1L+jl0O3Nskzf3AeZKGctXNeXlf5SQtB64BVkTEqy3StPNdqCp/5Ta332vxuu381qv0O8BzEbG52cF+Xr+O9Lu1vy43Uq+i50k9Or6Y991A+tEAzCRViawHHgPe3cO8/Rap+P0ksCbfLgA+A3wmp1kJPEPqhfIIcE4P8/fu/LpP5DwU16+cPwE35+v7FLC0x5/vu0iB4djSvr5dP1JA2wK8Qfov+VOkNreHgHX5fk5OuxT4euncT+bv4Xrgyh7mbz2pfaH4Dha9GE8A7hvru9Cj/H0zf7eeJAWH4xvzlx8f8lvvRf7y/m8U37lS2p5fv27fPLLdzMw64qotMzPriAOJmZl1xIHEzMw64kBiZmYdcSAxM7OOOJCYdYGkNxtmGO7arLKSFpdnkTWrm6n9zoDZBPFaRJzR70yY9YNLJGYVymtL3CjpsXz7lbx/kaSH8gSDD0lamPcvyGt9PJFv5+SnGpB0q9J6NA9ImtW3N2XWwIHErDtmNVRtXVI69kpELAO+Cvxt3vdV0rT67yVNfnhT3n8T8N+RJo88kzS6GWAJcHNEnA7sBC6q+P2Ytc0j2826QNLuiDi6yf4XgA9GxIY88ebWiDhO0nbSFB5v5P1bImKupGHgpIjYW3qOxaQ1SJbkx9cA0yLiz6t/Z2bjc4nErHrRYrtVmmb2lrbfxO2bViMOJGbVu6R0/3De/hFp5lmAjwP/m7cfAj4LIGlA0uxeZdLsSPm/GrPumCVpTenxf0ZE0QV4hqRHSf+4XZb3XQ3cLukLwDBwZd7/OeAWSZ8ilTw+S5pF1qy23EZiVqHcRrI0Irb3Oy9mVXHVlpmZdcQlEjMz64hLJGZm1hEHEjMz64gDiZmZdcSBxMzMOuJAYmZmHXEgMTOzjvw/k+0U9rNc44gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the history of this model\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'])\n",
    "maxValAcc = max(history2.history['val_acc'])\n",
    "trainAcc = history2.history['acc'][history2.history['val_acc'].index(maxValAcc)]\n",
    "plt.savefig(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.png\")\n",
    "model2.save_weights(f\"Architecture10-{epochs}epochs-{colName}--trainAcc-{trainAcc}--valAcc-{maxValAcc}.hdf5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
